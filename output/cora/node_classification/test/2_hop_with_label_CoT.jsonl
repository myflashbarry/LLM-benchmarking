{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1958\nTitle: Title: Automatic Generation of Adaptive Programs Automatic Generation of Adaptive Programs. In From Animals to Animats\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2226\nTitle: Title: Simultaneous Evolution of Programs and their Control Structures Simultaneous Evolution of Programs and their Control\nLabel: Genetic Algorithms\n\nPaper id: 2220\nTitle: Title: The Automatic Programming of Agents that Learn Mental Models and Create Simple Plans of Action  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1940\nTitle: Title: A Comparison of Crossover and Mutation in Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 2600\nTitle: Title: Evolution of Iteration in Genetic Programming D a v d A The solution to many\nLabel: Genetic Algorithms\n\nPaper id: 129\nTitle: Title: Evolving Networks: Using the Genetic Algorithm with Connectionist Learning  \nLabel: Genetic Algorithms\n\nPaper id: 2563\nTitle: Title: Analysis of Neurocontrollers Designed by Simulated Evolution  \nLabel: Genetic Algorithms\n\nPaper id: 2139\nTitle: Title: Evolving Teamwork and Coordination with Genetic Programming  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1923\nTitle: Title: EM Algorithms for PCA and SPCA  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1928\nTitle: Title: Mixtures of Probabilistic Principal Component Analysers  \nLabel: Neural Networks\n\nPaper id: 2227\nTitle: Title: The EM Algorithm for Mixtures of Factor Analyzers  \nLabel: Neural Networks\n\nPaper id: 71\nTitle: Title: Supervised learning from incomplete data via an EM approach  \nLabel: Probabilistic Methods\n\nPaper id: 2114\nTitle: Title: Probabilistic Principal Component Analysis  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 74\nTitle: Title: Hierarchical Mixtures of Experts and the EM Algorithm  \nLabel: Probabilistic Methods\n\nPaper id: 661\nTitle: Title: A Statistical Approach to Decision Tree Modeling  \nLabel: Probabilistic Methods\n\nPaper id: 1559\nTitle: Title: In  Active Learning with Statistical Models  \nLabel: Neural Networks\n\nPaper id: 677\nTitle: Title: Recurrent Neural Networks for Missing or Asynchronous Data  \nLabel: Neural Networks\n\nPaper id: 2570\nTitle: Title: In  Fast Non-Linear Dimension Reduction  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1438\nTitle: Title: Learning from undiscounted delayed rewards  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 294\nTitle: Title: References elements that can solve difficult learning control problems. on Simulation of Adaptive Behavior, pages\nLabel: Reinforcement Learning\n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n\nPaper id: 807\nTitle: Title: Designing Neural Networks for Adaptive Control  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 566\nTitle: Title: Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming  \nLabel: Reinforcement Learning\n\nPaper id: 305\nTitle: Title: Solving Combinatorial Optimization Tasks by Reinforcement Learning: A General Methodology Applied to Resource-Constrained Scheduling  \nLabel: Reinforcement Learning\n\nPaper id: 842\nTitle: Title: Metrics for Temporal Difference Learning  \nLabel: Reinforcement Learning\n\nPaper id: 1672\nTitle: Title: Learning Controllers for Industrial Robots  \nLabel: Neural Networks\n\nPaper id: 2\nTitle: Title: Submitted to NIPS96, Section: Applications. Preference: Oral presentation Reinforcement Learning for Dynamic Channel Allocation in\nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2648\nTitle: Title: The Task Rehearsal Method of Sequential Learning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1889\nTitle: Title: The Functional Transfer of Knowledge for Coronary Artery Disease Diagnosis  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 562\nTitle: Title: Transfer of Learning by Composing Solutions of Elemental Sequential Tasks  \n\nPaper id: 730\nTitle: Title: Learning Sequential Tasks by Incrementally Adding Higher Orders  \nLabel: Neural Networks\n\nPaper id: 2586\nTitle: Title: Learning One More Thing  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2631\nTitle: Title: Nonlinear Resonance in Neuron Dynamics  in Statistical Mechanics and Complex Systems  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2601\nTitle: Title: Stability and Chaos in an Inertial Two Neuron System  in Statistical Mechanics and Complex Systems  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 851\nTitle: Title: Bayesian Probability Theory A General Method for Machine Learning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1491\nTitle: Title: Discovery as Autonomous Learning from the Environment  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 903\nTitle: Title: Learning Concepts from Sensor Data of a Mobile Robot  \nLabel: Theory\n\nPaper id: 1390\nTitle: Title: Learning Finite Automata Using Local Distinguishing Experiments  \n\nPaper id: 1605\nTitle: Title: Learning from the Environment by Experimentation: The Need for Few and Informative Examples  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 698\nTitle: Title: Learning to Predict Reading Frames in E. coli DNA Sequences  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n\nPaper id: 1431\nTitle: Title: Learning to Represent Codons: A Challenge Problem for Constructive Induction  \nLabel: Neural Networks\n\nPaper id: 360\nTitle: Title: Investigating the Value of a Good Input Representation  \nLabel: Neural Networks\n\nPaper id: 474\nTitle: Title: Protein Structure Prediction: Selecting Salient Features from Large Candidate Pools  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 587\nTitle: Title: NONPARAMETRIC SELECTION OF INPUT VARIABLES FOR CONNECTIONIST LEARNING  \nLabel: Neural Networks\n\nPaper id: 18\nTitle: Title: Topography And Ocular Dominance: A Model Exploring Positive Correlations  \nLabel: Neural Networks\n\nPaper id: 1766\nTitle: Title: Computational Models of Sensorimotor Integration  Computational Maps and Motor Control.  \nLabel: Neural Networks\n\nPaper id: 202\nTitle: Title: Dyslexic and Category-Specific Aphasic Impairments in a Self-Organizing Feature Map Model of the Lexicon  \n\nPaper id: 2044\nTitle: Title: Neural Networks and Statistical Models Proceedings of the Nineteenth Annual SAS Users Group International Conference,\nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2041\nTitle: Title: Natural Language Grammatical Inference with Recurrent Neural Networks  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1744\nTitle: Title: Simple Synchrony Networks: Learning Generalisations across Syntactic Constituents  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1152\nTitle: Title: Fish and Shrink. A next step towards e-cient case retrieval in large scaled case bases  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1453\nTitle: Title: Automatic Indexing, Retrieval and Reuse of Topologies in Architectual Layouts  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 539\nTitle: Title: Structural Similarity as Guidance in Case-Based Design  \nLabel: Case Based\n\nPaper id: 1210\nTitle: Title: Structural Similarity and Adaptation  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 616\nTitle: Title: A Decision Tree System for Finding Genes in DNA  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 438\nTitle: Title: A System for Induction of Oblique Decision Trees  \nLabel: Theory\n\nPaper id: 2046\nTitle: Title: A Method for Identifying Splice Sites and Translational Start Sites in  \nLabel: Neural Networks\n\nPaper id: 268\nTitle: Title: Finding Genes in DNA with a Hidden Markov Model  \n\nPaper id: 613\nTitle: Title: A Generalized Hidden Markov Model for the Recognition of Human Genes in DNA  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 14\nTitle: Title: Hidden Markov Models in Computational Biology: Applications to Protein Modeling UCSC-CRL-93-32 Keywords: Hidden Markov Models,\nLabel: Neural Networks\n\nPaper id: 21\nTitle: Title: Decision Tree Function Approximation in Reinforcement Learning  \n\nPaper id: 232\nTitle: Title: Stochastic Decomposition of DNA Sequences Using Hidden Markov Models  \nLabel: Neural Networks\n\nPaper id: 2496\nTitle: Title: Gene Structure Prediction by Linguistic Methods  \nLabel: Neural Networks\n\nPaper id: 692\nTitle: Title: Decision Tree Induction: How Effective is the Greedy Heuristic?  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 732\nTitle: Title: Statistical Queries and Faulty PAC Oracles  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 267\nTitle: Title: On Learning from Noisy and Incomplete Examples  \nLabel: Theory\n\nPaper id: 1897\nTitle: Title: On Learning Visual Concepts and DNF Formulae  \nLabel: Theory\n\nPaper id: 20\nTitle: Title: 25 Learning in Hybrid Noise Environments Using Statistical Queries  \nLabel: Theory\n\nPaper id: 640\nTitle: Title: Learning in the Presence of Malicious Errors  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2146\nTitle: Title: On Learning Read-k-Satisfy-j DNF  \n\nPaper id: 2182\nTitle: Title: Weakly Learning DNF and Characterizing Statistical Query Learning Using Fourier Analysis  \n\nPaper id: 459\nTitle: Title: Pac Learning, Noise, and Geometry  \n\nPaper id: 130\nTitle: Title: PAC-Learning PROLOG clauses with or without errors  \n\nPaper id: 574\nTitle: Title: On the Learnability of Discrete Distributions (extended abstract)  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 580\nTitle: Title: Learning to Improve Case Adaptation by Introspective Reasoning and CBR  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 581\nTitle: Title: Representing Self-knowledge for Introspection about Memory Search  \nLabel: Case Based\n\nPaper id: 922\nTitle: Title: Towards Improving Case Adaptability with a Genetic Algorithm  \nLabel: Case Based\n\nPaper id: 1497\nTitle: Title: Combining Rules and Cases to Learn Case Adaptation  \nLabel: Case Based\n\nPaper id: 1126\nTitle: Title: Towards A Computer Model of Memory Search Strategy Learning  \n\nPaper id: 1215\nTitle: Title: Supporting Combined Human and Machine Planning: An Interface for Planning by Analogical Reasoning  \n\nPaper id: 1212\nTitle: Title: Acquiring Case Adaptation Knowledge: A Hybrid Approach  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 901\nTitle: Title: Evaluating Computational Assistance for Crisis Response  \nLabel: Case Based\n\nPaper id: 1416\nTitle: Title: Synergy and Commonality in Case-Based and Constraint-Based Reasoning  \n\nPaper id: 825\nTitle: Title: Towards Mixed-Initiative Rationale-Supported Planning  \n\nPaper id: 819\nTitle: Title: A Case Study of Case-Based CBR  \nLabel: Case Based\n\nPaper id: 49\nTitle: Title: Abstract  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2684\nTitle: Title: INVERSION IN TIME  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2523\nTitle: Title: ADAPTIVE LOOK-AHEAD PLANNING problem of finding good initial plans is solved by the use of\nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 504\nTitle: Title: MANIAC: A Next Generation Neurally Based Autonomous Road Follower  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 702\nTitle: Title: Automated Highway System  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 600\nTitle: Title: Separating hippocampal maps  Spatial Functions of the Hippocampal Formation and the  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 745\nTitle: Title: References \"Using Neural Networks to Identify Jets\", Kohonen, \"Self Organized Formation of Topologically Correct Feature\nLabel: Neural Networks\n\nPaper id: 1052\nTitle: Title: Representation of spatial orientation by the intrinsic dynamics of the head-direction cell ensemble: A theory  \nLabel: Neural Networks\n\nPaper id: 205\nTitle: Title: Beyond the Cognitive Map: Contributions to a Computational Neuroscience Theory of Rodent Navigation for the\nLabel: Neural Networks\n\nPaper id: 747\nTitle: Title: Cholinergic suppression of transmission may allow combined associative memory function and self-organization in the neocortex.  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n\nPaper id: 355\nTitle: Title: Generalization and Exclusive Allocation of Credit in Unsupervised Category Learning  \nLabel: Neural Networks\n\nPaper id: 542\nTitle: Title: Comparison of Bayesian and Neural Net Unsupervised Classification Techniques  \nLabel: Neural Networks\n\nPaper id: 572\nTitle: Title: Avoiding Overfitting with BP-SOM  \nLabel: Neural Networks\n\nPaper id: 695\nTitle: Title: There is No Free Lunch but the Starter is Cheap: Generalisation from First Principles  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 658\nTitle: Title: Hill Climbing with Learning (An Abstraction of Genetic Algorithm)  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n\nPaper id: 1577\nTitle: Title: Fast Probabilistic Modeling for Combinatorial Optimization  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2563\nTitle: Title: Analysis of Neurocontrollers Designed by Simulated Evolution  \nLabel: Genetic Algorithms\n\nPaper id: 765\nTitle: Title: A Classifier System plays a simple board game Getting down to the Basics of Machine Learning?  \nLabel: Genetic Algorithms\n\nPaper id: 188\nTitle: Title: Coevolving High-Level Representations  \nLabel: Genetic Algorithms\n\nPaper id: 1872\nTitle: Title: Modeling Building-Block Interdependency  Dynamical and Evolutionary Machine Organization Group  \nLabel: Genetic Algorithms\n\nPaper id: 219\nTitle: Title: Issues in Evolutionary Robotics  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2613\nTitle: Title: Genetic Algorithms for Automated Tuning of Fuzzy Controllers: A Transportation Application  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1756\nTitle: Title: Soft Computing: the Convergence of Emerging Reasoning Technologies  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 745\nTitle: Title: References \"Using Neural Networks to Identify Jets\", Kohonen, \"Self Organized Formation of Topologically Correct Feature\nLabel: Neural Networks\n\nPaper id: 2603\nTitle: Title: Pointer Adaptation and Pruning of Min-Max Fuzzy Inference and Estimation  \nLabel: Neural Networks\n\nPaper id: 1663\nTitle: Title: Evolution of the Topology and the Weights of Neural Networks using Genetic Programming with a\n\nPaper id: 168\nTitle: Title: Dynamic Control of Genetic Algorithms using Fuzzy Logic Techniques  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1257\nTitle: Title: The Schema Theorem and Price's Theorem  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 380\nTitle: Title: Fitness Landscapes and Difficulty in Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 2087\nTitle: Title: Price's Theorem and the MAX Problem  \nLabel: Genetic Algorithms\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 2259\nTitle: Title: An Experimental Analysis of Schema Creation, Propagation and Disruption in Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 1153\nTitle: Title: Evolution in Time and Space The Parallel Genetic Algorithm  \n\nPaper id: 1872\nTitle: Title: Modeling Building-Block Interdependency  Dynamical and Evolutionary Machine Organization Group  \nLabel: Genetic Algorithms\n\nPaper id: 1719\nTitle: Title: An Analysis of the MAX Problem in Genetic Programming hold only in some cases, in\nLabel: Genetic Algorithms\n\nPaper id: 2175\nTitle: Title: The Troubling Aspects of a Building Block Hypothesis for Genetic Programming  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1110\nTitle: Title: On The State of Evolutionary Computation  \nLabel: Genetic Algorithms\n\nPaper id: 1650\nTitle: Title: Genetic Algorithms For Vertex Splitting in DAGs 1  \nLabel: Genetic Algorithms\n\nPaper id: 346\nTitle: Title: PERCEPTION OF TIME AS PHASE: TOWARD AN ADAPTIVE-OSCILLATOR MODEL OF RHYTHMIC PATTERN PROCESSING 1  \nLabel: Neural Networks\n\nPaper id: 1971\nTitle: Title: Voting for Schemata  \nLabel: Genetic Algorithms\n\nPaper id: 2251\nTitle: Title: A PARALLEL ISLAND MODEL GENETIC ALGORITHM FOR THE MULTIPROCESSOR SCHEDULING PROBLEM  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1066\nTitle: Title: The Rectified Gaussian Distribution  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1052\nTitle: Title: Representation of spatial orientation by the intrinsic dynamics of the head-direction cell ensemble: A theory  \nLabel: Neural Networks\n\nPaper id: 36\nTitle: Title: Generative Models for Discovering Sparse Distributed Representations  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2390\nTitle: Title: A HIERARCHICAL COMMUNITY OF EXPERTS  \nLabel: Neural Networks\n\nPaper id: 2072\nTitle: Title: Data Mining for Association Rules with Unsupervised Neural Networks  \nLabel: Neural Networks\n\nPaper id: 257\nTitle: Title: Factor Analysis Using Delta-Rule Wake-Sleep Learning  \nLabel: Neural Networks\n\nPaper id: 1974\nTitle: Title: Data Mining for Association Rules with Unsupervised Neural Networks  \n\nPaper id: 1591\nTitle: Title: Unsupervised Learning by Convex and Conic Coding  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1092\nTitle: Title: Pruning Adaptive Boosting ICML-97 Final Draft  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 569\nTitle: Title: A decision-theoretic generalization of on-line learning and an application to boosting how the weight-update rule\n\nPaper id: 1484\nTitle: Title: Experiments with a New Boosting Algorithm  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 767\nTitle: Title: Learning to Order Things  \nLabel: Theory\n\nPaper id: 1237\nTitle: Title: An Empirical Evaluation of Bagging and Boosting  \nLabel: Theory\n\nPaper id: 1430\nTitle: Title: Adaptive Boosting of Neural Networks for Character Recognition  \nLabel: Neural Networks\n\nPaper id: 1986\nTitle: Title: BOOSTING AND NAIVE BAYESIAN LEARNING  \n\nPaper id: 1500\nTitle: Title: On the Induction of Intelligible Ensembles  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2269\nTitle: Title: Some Steps Towards a Form of Parallel Distributed Genetic Programming  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2277\nTitle: Title: Discovery of Symbolic, Neuro-Symbolic and Neural Networks with Parallel Distributed Genetic Programming  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1931\nTitle: Title: AUTOMATED TOPOLOGY AND SIZING OF ANALOG CIRCUITS AUTOMATED DESIGN OF BOTH THE TOPOLOGY AND SIZING\n\nPaper id: 2624\nTitle: Title: A Comparison between Cellular Encoding and Direct Encoding for Genetic Neural Networks  \nLabel: Genetic Algorithms\n\nPaper id: 1277\nTitle: Title: Evolution of Pseudo-colouring Algorithms for Image Enhancement with Interactive Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 2252\nTitle: Title: Neural Programming and an Internal Reinforcement Policy  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 395\nTitle: Title: Evolving Graphs and Networks with Edge Encoding: Preliminary Report  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 189\nTitle: Title: An Evolutionary Algorithm that Constructs Recurrent Neural Networks  \n\nPaper id: 191\nTitle: Title: USING MARKER-BASED GENETIC ENCODING OF NEURAL NETWORKS TO EVOLVE FINITE-STATE BEHAVIOUR  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2518\nTitle: Title: Tracing the Behavior of Genetic Algorithms Using Expected Values of Bit and Walsh Products  \nLabel: Genetic Algorithms\n\nPaper id: 2274\nTitle: Title: Specialization in Populations of Artificial Neural Networks  \n\nPaper id: 1575\nTitle: Title: A Comparative Study of Genetic Search  \nLabel: Genetic Algorithms\n\nPaper id: 1971\nTitle: Title: Voting for Schemata  \nLabel: Genetic Algorithms\n\nPaper id: 2248\nTitle: Title: Heuristic for Improved Genetic Bin Packing  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1492\nTitle: Title: Predicting Time Series with Support Vector Machines  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1724\nTitle: Title: Annealed Competition of Experts for a Segmentation and Classification of Switching Dynamics  \nLabel: Neural Networks\n\nPaper id: 1050\nTitle: Title: Extracting Support Data for a Given Task  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1591\nTitle: Title: Unsupervised Learning by Convex and Conic Coding  \nLabel: Neural Networks\n\nPaper id: 1171\nTitle: Title: Nonlinear Component Analysis as a Kernel Eigenvalue Problem  \nLabel: Neural Networks\n\nPaper id: 1508\nTitle: Title: Segmenting Time Series using Gated Experts with Simulated Annealing  \nLabel: Neural Networks\n\nPaper id: 1079\nTitle: Title: Nonlinear Prediction of Chaotic Time Series Using Support Vector Machines  \nLabel: Neural Networks\n\nPaper id: 1538\nTitle: Title: Analysis of Drifting Dynamics with Neural Network Hidden Markov Models  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 399\nTitle: Title: Representing and Learning Visual Schemas in Neural Networks for Scene Analysis  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n\nPaper id: 1251\nTitle: Title: VISOR: Schema-based Scene Analysis with Structured Neural Networks  \nLabel: Neural Networks\n\nPaper id: 15\nTitle: Title: Back Propagation is Sensitive to Initial Conditions  \nLabel: Neural Networks\n\nPaper id: 1250\nTitle: Title: Priming, Perceptual Reversal, and Circular Reaction in a Neural Network Model of Schema-Based Vision  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 696\nTitle: Title: GAL: Networks that grow when they learn and shrink when they forget  \nLabel: Neural Networks\n\nPaper id: 18\nTitle: Title: Topography And Ocular Dominance: A Model Exploring Positive Correlations  \nLabel: Neural Networks\n\nPaper id: 698\nTitle: Title: Learning to Predict Reading Frames in E. coli DNA Sequences  \n\nPaper id: 254\nTitle: Title: Scaling-up RAAMs  \nLabel: Neural Networks\n\nPaper id: 250\nTitle: Title: Mean Field Theory for Sigmoid Belief Networks  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2101\nTitle: Title: Evolving Control Structures with Automatically Defined Macros  Evolving Control Structures with Automatically Defined Macros.  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2470\nTitle: Title: Induction and Recapitulation of Deep Musical Structure  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2643\nTitle: Title: GP-Music: An Interactive Genetic Programming System for Music Generation with Automated Fitness Raters  \nLabel: Genetic Algorithms\n\nPaper id: 1277\nTitle: Title: Evolution of Pseudo-colouring Algorithms for Image Enhancement with Interactive Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 1230\nTitle: Title: Entailment for Specification Refinement  \nLabel: Genetic Algorithms\n\nPaper id: 2646\nTitle: Title: Automated Fitness Raters for the GP-Music System  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 103\nTitle: Title: NEUROCONTROL BY REINFORCEMENT LEARNING  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 294\nTitle: Title: References elements that can solve difficult learning control problems. on Simulation of Adaptive Behavior, pages\nLabel: Reinforcement Learning\n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n\nPaper id: 465\nTitle: Title: Strategy Learning with Multilayer Connectionist Representations 1  \nLabel: Reinforcement Learning\n\nPaper id: 128\nTitle: Title: Optimal Attitude Control of Satellites by Artificial Neural Networks: a Pilot Study  \nLabel: Reinforcement Learning\n\nPaper id: 471\nTitle: Title: In  Improving Elevator Performance Using Reinforcement Learning  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1540\nTitle: Title: MultiPlayer Residual Advantage Learning With General Function Approximation  \n\nPaper id: 333\nTitle: Title: A Comparison of Action Selection Learning Methods  \nLabel: Reinforcement Learning\n\nPaper id: 1632\nTitle: Title: Learning Team Strategies With Multiple Policy-Sharing Agents: A Soccer Case Study  \nLabel: Reinforcement Learning\n\nPaper id: 1672\nTitle: Title: Learning Controllers for Industrial Robots  \nLabel: Neural Networks\n\nPaper id: 2\nTitle: Title: Submitted to NIPS96, Section: Applications. Preference: Oral presentation Reinforcement Learning for Dynamic Channel Allocation in\nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1038\nTitle: Title: Brief Papers Computing Second Derivatives in Feed-Forward Networks: A Review  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 157\nTitle: Title: A Practical Bayesian Framework for Backprop Networks  \nLabel: Theory\n\nPaper id: 916\nTitle: Title: A comparison of some error estimates for neural network models  Summary  \nLabel: Neural Networks\n\nPaper id: 1196\nTitle: Title: The Free Speech  Phoneme Probability Estimation with Dynamic Sparsely Connected Artificial Neural Networks  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2680\nTitle: Title: Least Absolute Shrinkage is Equivalent to Quadratic Penalization  \nLabel: Neural Networks\n\nPaper id: 1289\nTitle: Title: 5 Bayesian estimation 5.1 Introduction  \nLabel: Neural Networks\n\nPaper id: 2373\nTitle: Title: Evaluating Neural Network Predictors by Bootstrapping  \nLabel: Neural Networks\n\nPaper id: 1375\nTitle: Title: Priors for Infinite Networks  \nLabel: Probabilistic Methods\n\nPaper id: 740\nTitle: Title: Information-based objective functions for active data selection  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1683\nTitle: Title: An Algorithm for Active Data Collection for Learning Feasibility Study with Neural Networks.  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1198\nTitle: Title: Query by Committee  \nLabel: Theory\n\nPaper id: 1697\nTitle: Title: Neural Network Exploration Using Optimal Experiment Design  \nLabel: Neural Networks\n\nPaper id: 740\nTitle: Title: Information-based objective functions for active data selection  \n\nPaper id: 1559\nTitle: Title: In  Active Learning with Statistical Models  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 16\nTitle: Title: Exploration in Active Learning  \n\nPaper id: 2658\nTitle: Title: Control Systems Magazine, 14, 1, pp.57-71. Robot Juggling: An Implementation of Memory-based Learning  \n\nPaper id: 1703\nTitle: Title: REINFORCEMENT DRIVEN INFORMATION ACQUISITION IN NON-DETERMINISTIC ENVIRONMENTS  \nLabel: Reinforcement Learning\n\nPaper id: 71\nTitle: Title: Supervised learning from incomplete data via an EM approach  \nLabel: Probabilistic Methods\n\nPaper id: 859\nTitle: Title: On-Site Learning  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 972\nTitle: Title: On Genetic Programming of Fuzzy Rule-Based Systems for Intelligent Control  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 953\nTitle: Title: Behavior Hierarchy for Autonomous Mobile Robots: Fuzzy-behavior modulation and evolution  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1751\nTitle: Title: Global self organization of all known protein sequences reveals inherent biological signatures self organization method\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2691\nTitle: Title: A map of the protein space An automatic hierarchical classification of all protein sequences  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2499\nTitle: Title: Objective Function Formulation of the BCM Theory of Visual Cortical Plasticity: Statistical Connections, Stability Conditions  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 203\nTitle: Title: Theory of Synaptic Plasticity in Visual Cortex  \nLabel: Neural Networks\n\nPaper id: 2357\nTitle: Keyword: Running Title: Local Multivariate Binary Processors  \nLabel: Neural Networks\n\nPaper id: 2500\nTitle: Title: Face Recognition using a Hybrid Supervised/Unsupervised Neural Network  \nLabel: Neural Networks\n\nPaper id: 359\nTitle: Title: Feature Extraction Using an Unsupervised Neural Network  \nLabel: Neural Networks\n\nPaper id: 2147\nTitle: Title: Extraction of Facial Features for Recognition using Neural Networks  \nLabel: Neural Networks\n\nPaper id: 1787\nTitle: Title: An integrated approach to the study of object features in visual recognition  \n\nPaper id: 2376\nTitle: Title: Multimodality Exploration in Training an Unsupervised Projection Pursuit Neural Network  \nLabel: Neural Networks\n\nPaper id: 1068\nTitle: Title: Neuronal Goals: Efficient Coding and Coincidence Detection  \nLabel: Neural Networks\n\nPaper id: 2498\nTitle: Title: Combining Exploratory Projection Pursuit And Projection Pursuit Regression With Application To Neural Networks  \nLabel: Neural Networks\n\nPaper id: 2505\nTitle: Title: Three-Dimensional Object Recognition Using an Unsupervised BCM Network: The Usefulness of Distinguishing Features  \nLabel: Neural Networks\n\nPaper id: 2422\nTitle: Title: Classification of Underwater Mammals using Feature Extraction Based on Time-Frequency Analysis and BCM Theory  \nLabel: Neural Networks\n\nPaper id: 863\nTitle: Title: Empirical Entropy Manipulation for Real-World Problems  \n\nPaper id: 2322\nTitle: Title: PHONETIC CLASSIFICATION OF TIMIT SEGMENTS PREPROCESSED WITH LYON'S COCHLEAR MODEL USING A SUPERVISED/UNSUPERVISED HYBRID NEURAL NETWORK  \nLabel: Neural Networks\n\nPaper id: 1871\nTitle: Title: 3D Object Recognition Using Unsupervised Feature Extraction  \nLabel: Neural Networks\n\nPaper id: 1418\nTitle: Title: BCM Network develops Orientation Selectivity and Ocular Dominance in Natural Scene Environment.  \nLabel: Neural Networks\n\nPaper id: 2385\nTitle: Title: Receptive Fields for Vision: from Hyperacuity to Object Recognition  \n\nPaper id: 1935\nTitle: Title: Observations on Cortical Mechanisms for Object Recognition and Learning  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 330\nTitle: Title: Local Feature Analysis: A general statistical theory for object representation  \n\nPaper id: 576\nTitle: Title: An information-maximisation approach to blind separation and blind deconvolution  \nLabel: Neural Networks\n\nPaper id: 808\nTitle: Title: Unsupervised Discrimination of Clustered Data via Optimization of Binary Information Gain  \nLabel: Neural Networks\n\nPaper id: 726\nTitle: Title: Natural image statistics and efficient coding  \nLabel: Neural Networks\n\nPaper id: 2676\nTitle: Title: Models of perceptual learning in vernier hyperacuity  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2074\nTitle: Title: The Management of Context-Sensitive Features: A Review of Strategies  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1647\nTitle: Title: Recognition and Exploitation of Contextual Clues via Incremental Meta-Learning (Extended Version)  \nLabel: Theory\n\nPaper id: 2615\nTitle: Title: A Patient-Adaptive Neural Network ECG Patient Monitoring Algorithm  \nLabel: Neural Networks\n\nPaper id: 1636\nTitle: Title: Context-Sensitive Feature Selection for Lazy Learners  \n\nPaper id: 2607\nTitle: Title: Concept Learning and Flexible Weighting  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1073\nTitle: Title: An adaptation of Relief for attribute estimation in regression  \nLabel: Rule Learning\n\nPaper id: 2369\nTitle: Title: Case-Based Sonogram Classification  \nLabel: Case Based\n\nPaper id: 245\nTitle: Title: ICML-96 Workshop \"Learning in context-sensitive domains\" Bari, Italy. Dynamically Adjusting Concepts to Accommodate Changing Contexts  \n\nPaper id: 2310\nTitle: Title: Machine Learning: An Annotated Bibliography for the 1995 AI Statistics Tutorial on Machine Learning (Version 1)  \nLabel: Case Based\n\nPaper id: 1908\nTitle: Title: Induction of Selective Bayesian Classifiers  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2065\nTitle: Title: Performance Enhanced Genetic Programming  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2086\nTitle: Title: ABSTRACT In general, the machine learning process can be accelerated through the use of additional\nLabel: Genetic Algorithms\n\nPaper id: 1985\nTitle: Title: ABSTRACT  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 995\nTitle: Title: Evolving a Team  \n\nPaper id: 1231\nTitle: Title: Type Inheritance in Strongly Typed Genetic Programming  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1781\nTitle: Title: Learning Singly-Recursive Relations from Small Datasets  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2663\nTitle: Title: Inverting Implication with Small Training Sets  \nLabel: Rule Learning\n\nPaper id: 1819\nTitle: Title: The Difficulties of Learning Logic Programs with Cut  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2229\nTitle: Title: Bottom-up induction of logic programs with more than one recursive clause  \nLabel: Rule Learning\n\nPaper id: 2580\nTitle: Title: The Challenge of Revising an Impure Theory  \nLabel: Theory\n\nPaper id: 224\nTitle: Title: on Inductive Logic Programming (ILP-95) Inducing Logic Programs without Explicit Negative Examples  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1527\nTitle: Title: A THEORY OF INFERRED CAUSATION perceive causal relationships in uncon trolled observations. 2. the task\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 211\nTitle: Title: Using Path Diagrams as a Structural Equation Modelling Tool  \nLabel: Probabilistic Methods\n\nPaper id: 971\nTitle: Title: Decision-Theoretic Foundations for Causal Reasoning  \n\nPaper id: 2076\nTitle: Title: Automated Discovery of Linear Feedback Models 1  \n\nPaper id: 260\nTitle: Title: ASPECTS OF GRAPHICAL MODELS CONNECTED WITH CAUSALITY  \nLabel: Probabilistic Methods\n\nPaper id: 1543\nTitle: Title: Belief Networks Revisited  \nLabel: Probabilistic Methods\n\nPaper id: 2524\nTitle: Title: ADAPTIVE LOOK-AHEAD PLANNING problem of finding good initial plans is solved by the use of\nLabel: Probabilistic Methods\n\nPaper id: 827\nTitle: Title: Two Algorithms for Inducing Structural Equation Models from Data  \nLabel: Probabilistic Methods\n\nPaper id: 2166\nTitle: Title: Probabilistic evaluation of counterfactual queries  \nLabel: Probabilistic Methods\n\nPaper id: 2420\nTitle: Title: A Parallel Learning Algorithm for Bayesian Inference Networks  \n\nPaper id: 2525\nTitle: Title: Bayesian Networks  \nLabel: Probabilistic Methods\n\nPaper id: 419\nTitle: Title: On the Testability of Causal Models with Latent and Instrumental Variables  \nLabel: Probabilistic Methods\n\nPaper id: 1747\nTitle: Title: FROM BAYESIAN NETWORKS TO CAUSAL NETWORKS  \nLabel: Probabilistic Methods\n\nPaper id: 2561\nTitle: Title: MDL Learning of Probabilistic Neural Networks for Discrete Problem Domains  \n\nPaper id: 909\nTitle: Title: Regression Can Build Predictive Causal Models  \nLabel: Probabilistic Methods\n\nPaper id: 2088\nTitle: Title: A Probabilistic Calculus of Actions  \n\nPaper id: 1240\nTitle: Title: Model Selection and Accounting for Model Uncertainty in Linear Regression Models  \nLabel: Probabilistic Methods\n\nPaper id: 1894\nTitle: Title: Causal inference, path analysis, and recursive struc-tural equations models. In C. Clogg, editor, Sociological Methodology,\nLabel: Probabilistic Methods\n\nPaper id: 2221\nTitle: Title: Reasoning about Time and Probability  \nLabel: Probabilistic Methods\n\nPaper id: 1086\nTitle: Title: An Algorithm for the Construction of Bayesian Network Structures from Data  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2167\nTitle: Title: Counterfactuals and Policy Analysis in Structural Models  \nLabel: Probabilistic Methods\n\nPaper id: 1241\nTitle: Title: Bayesian Graphical Models for Discrete Data  \nLabel: Probabilistic Methods\n\nPaper id: 1324\nTitle: Title: [6] D. Geiger. Graphoids: a qualitative framework for probabilistic inference. An introduction to algorithms for\n\nPaper id: 2559\nTitle: Title: \"Linear Dependencies Represented by Chain Graphs,\" \"Graphical Modelling With MIM,\" Manual. \"Identifying Independence in Bayesian\n\nPaper id: 1908\nTitle: Title: Induction of Selective Bayesian Classifiers  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2085\nTitle: Title: Modeling dynamic receptive field changes produced by intracortical microstimulation  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1093\nTitle: Title: The role of afferent excitatory and lateral inhibitory synaptic plasticity in visual cortical ocular dominance\nLabel: Neural Networks\n\nPaper id: 1094\nTitle: Title: Plasticity in cortical neuron properties: Modeling the effects of an NMDA antagonist and a GABA\nLabel: Neural Networks\n\nPaper id: 2228\nTitle: Title: Modeling dynamic receptive field changes in primary visual cortex using inhibitory learning  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 127\nTitle: Title: Self-Organization and Functional Role of Lateral Connections and Multisize Receptive Fields in the Primary Visual Cortex  \n\nPaper id: 2068\nTitle: Title: Rearrangement of receptive field topography after intracortical and peripheral stimulation: The role of plasticity in\n\nPaper id: 355\nTitle: Title: Generalization and Exclusive Allocation of Credit in Unsupervised Category Learning  \nLabel: Neural Networks\n\nPaper id: 122\nTitle: Title: Tilt Aftereffects in a Self-Organizing Model of the Primary Visual Cortex  \n\nPaper id: 1659\nTitle: Title: In  Unsmearing Visual Motion: Development of Long-Range Horizontal Intrinsic Connections  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1282\nTitle: Title: Global Stabilization of Linear Discrete-Time Systems with Bounded Feedback  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1471\nTitle: Title: New Characterizations of Input to State Stability  \nLabel: Neural Networks\n\nPaper id: 948\nTitle: Title: An Optimal Weighting Criterion of Case Indexing for Both Numeric and Symbolic Attributes  \nLabel: Neural Networks\n\nPaper id: 1281\nTitle: Title: On Finite Gain Stabilizability of Linear Systems Subject to Input Saturation  \nLabel: Neural Networks\n\nPaper id: 1272\nTitle: Title: Input-Output Analysis of Feedback Loops with Saturation Nonlinearities  \nLabel: Neural Networks\n\nPaper id: 1022\nTitle: Title: j  \nLabel: Neural Networks\n\nPaper id: 1494\nTitle: Title: Avoiding Saturation By Trajectory Reparameterization  \nLabel: Neural Networks\n\nPaper id: 1446\nTitle: Title: STABILIZATION WITH SATURATED ACTUATORS, A WORKED EXAMPLE:F-8 LONGITUDINAL FLIGHT CONTROL  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1451\nTitle: Title: On the Computation of the Induced L 2 Norm of Single Input Linear Systems with Saturation  \nLabel: Neural Networks\n\nPaper id: 447\nTitle: Title: A Smooth Converse Lyapunov Theorem for Robust Stability  \nLabel: Neural Networks\n\nPaper id: 693\nTitle: Title: FURTHER FACTS ABOUT INPUT TO STATE STABILIZATION \"Further facts about input to state stabilization\", IEEE\nLabel: Neural Networks\n\nPaper id: 1633\nTitle: Title: Changing Supply Functions in Input/State Stable Systems  \nLabel: Neural Networks\n\nPaper id: 1604\nTitle: Title: Analytic Comparison of Nonlinear H 1 -Norm Bounding Techniques for Low Order Systems with Saturation  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2264\nTitle: Title: Evolutionary Computation in Air Traffic Control Planning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2519\nTitle: Title: An Evolutionary Approach to Time Constrained Routing Problems  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2308\nTitle: Title: Problem Formulation, Program Synthesis and Program Transformation Techniques for Simulation, Optimization and Constraint Satisfaction (Research Statement)  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2652\nTitle: Title: Knowledge-Based Re-engineering of Legacy Programs for Robustness in Automated Design  \n\nPaper id: 240\nTitle: Title: A Transformation System for Interactive Reformulation of Design Optimization Strategies  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 61\nTitle: Title: Program Synthesis and Transformation Techniques for Simpuation, Optimization and Constraint Satisfaction Deductive Synthesis of Numerical\nLabel: Case Based\n\nPaper id: 2637\nTitle: Title: A Computational Environment for Exhaust Nozzle Design  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 750\nTitle: Title: Machine Learning,  Creating Advice-Taking Reinforcement Learners  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 244\nTitle: Title: Building Intelligent Agents for Web-Based Tasks: A Theory-Refinement Approach  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 136\nTitle: Title: Theory Refinement Combining Analytical and Empirical Methods  \nLabel: Rule Learning\n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1810\nTitle: Title: Computation and Psychophysics of Sensorimotor Integration  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1766\nTitle: Title: Computational Models of Sensorimotor Integration  Computational Maps and Motor Control.  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 477\nTitle: Title: Forward models: Supervised learning with a distal teacher  \nLabel: Reinforcement Learning\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 641\nTitle: Title: Comparing Bayesian Model Class Selection Criteria by Discrete Finite Mixtures  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 376\nTitle: Title: Bayesian Finite Mixtures for Nonlinear Modeling of Educational data  \nLabel: Probabilistic Methods\n\nPaper id: 484\nTitle: Title: Comparing Predictive Inference Methods for Discrete Domains  \nLabel: Probabilistic Methods\n\nPaper id: 1739\nTitle: Title: Model Selection based on Minimum Description Length  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 642\nTitle: Title: Constructing Bayesian finite mixture models by the EM algorithm  \nLabel: Probabilistic Methods\n\nPaper id: 1574\nTitle: Title: Probabilistic Instance-Based Learning  \nLabel: Case Based\n\nPaper id: 558\nTitle: Title: A Tutorial on Learning With Bayesian Networks  \nLabel: Probabilistic Methods\n\nPaper id: 848\nTitle: Title: An Experimental and Theoretical Comparison of Model Selection Methods on simple model selection problems, the\nLabel: Theory\n\nPaper id: 704\nTitle: Title: EXPERIMENTING WITH THE CHEESEMAN-STUTZ EVIDENCE APPROXIMATION FOR PREDICTIVE MODELING AND DATA MINING  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2363\nTitle: Title: Modeling the Evolution of Motivation  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 2165\nTitle: Title: Auto-teaching: networks that develop their own teaching input  \nLabel: Genetic Algorithms\n\nPaper id: 1719\nTitle: Title: An Analysis of the MAX Problem in Genetic Programming hold only in some cases, in\nLabel: Genetic Algorithms\n\nPaper id: 129\nTitle: Title: Evolving Networks: Using the Genetic Algorithm with Connectionist Learning  \nLabel: Genetic Algorithms\n\nPaper id: 1969\nTitle: Title: Generalization and scaling in reinforcement learning  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 402\nTitle: Title: The Evolutionary Cost of Learning  \nLabel: Genetic Algorithms\n\nPaper id: 769\nTitle: Title: On the Relations Between Search and Evolutionary Algorithms  \n\nPaper id: 2251\nTitle: Title: A PARALLEL ISLAND MODEL GENETIC ALGORITHM FOR THE MULTIPROCESSOR SCHEDULING PROBLEM  \nLabel: Genetic Algorithms\n\nPaper id: 1216\nTitle: Title: Evolutionary Programming and Evolution Strategies: Similarities and Differences  \nLabel: Genetic Algorithms\n\nPaper id: 2193\nTitle: Title: Growing neural networks  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2109\nTitle: Title: Local quartet splits of a binary tree infer all quartet splits via one dyadic inference\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2185\nTitle: Title: of nucleotide sites needed to accurately reconstruct large evolutionary trees 1  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1930\nTitle: Title: A NEW METHODOLOGY FOR REDUCING BRITTLENESS IN GENETIC PROGRAMMING optimized maneuvers for an extended two-dimensional\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2512\nTitle: Title: A Methodology for Strategy Optimization Under Uncertainty in the Extended Two-Dimensional Pursuer/Evader Problem  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 234\nTitle: Title: Multiassociative Memory  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 747\nTitle: Title: Cholinergic suppression of transmission may allow combined associative memory function and self-organization in the neocortex.  \n\nPaper id: 15\nTitle: Title: Back Propagation is Sensitive to Initial Conditions  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 254\nTitle: Title: Scaling-up RAAMs  \nLabel: Neural Networks\n\nPaper id: 18\nTitle: Title: Topography And Ocular Dominance: A Model Exploring Positive Correlations  \nLabel: Neural Networks\n\nPaper id: 203\nTitle: Title: Theory of Synaptic Plasticity in Visual Cortex  \nLabel: Neural Networks\n\nPaper id: 283\nTitle: Title: A Local Learning Algorithm for Dynamic Feedforward and Recurrent Networks  \nLabel: Neural Networks\n\nPaper id: 175\nTitle: Title: SARDNET: A Self-Organizing Feature Map for Sequences  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1579\nTitle: Title: A Radial Basis Function Approach to Financial Time Series Analysis  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1103\nTitle: Reference: [39] <author> Yoda, M. </author> <year> (1994). </year> <title> Predicting the Tokyo stock market. </title> <editor> In Deboeck, G.J. (Ed.) </editor> <year> (1994). </year> <title> Trading on the Edge. </title> <address> New York: </address> <publisher> Wiley., </publisher> <pages> 66-79. </pages> <institution> VITA Graduate School Southern Illinois University Daniel Nikolaev Nikovski Date of Birth: </institution> <address> April 13, 1969 606 West College Street, Apt.4, Rm. 6, Carbondale, Illinois 62901 150 Hristo Botev Boulevard, Apt. </address> <month> 54, </month> <title> 4004 Plovdiv, Bulgaria Technical University - Sofia, Bulgaria Engineer of Computer Systems and Control Thesis Title: Adaptive Computation Techniques for Time Series Analysis Major Professor: </title> <journal> Dr. Mehdi Zargham </journal>\nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n\nPaper id: 1079\nTitle: Title: Nonlinear Prediction of Chaotic Time Series Using Support Vector Machines  \nLabel: Neural Networks\n\nPaper id: 74\nTitle: Title: Hierarchical Mixtures of Experts and the EM Algorithm  \nLabel: Probabilistic Methods\n\nPaper id: 611\nTitle: Title: Learning networks for face analysis and synthesis  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2205\nTitle: Title: A Genetic Local Search Approach to the Quadratic Assignment Problem  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1799\nTitle: Title: On the Effectiveness of Evolutionary Search in High-Dimensional NK-Landscapes  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 727\nTitle: Title: Using Problem Generators to Explore the Effects of Epistasis  \nLabel: Genetic Algorithms\n\nPaper id: 1424\nTitle: Title: Multi-parent's niche: n-ary crossovers on NK-landscapes  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2687\nTitle: Title: ALECSYS and the AutonoMouse: Learning to Control a Real Robot by Distributed Classifier Systems  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 636\nTitle: Title: Robot Shaping: Developing Situated Agents through Learning  \nLabel: Reinforcement Learning\n\nPaper id: 764\nTitle: Title: GENETIC AND NON GENETIC OPERATORS IN ALECSYS  \nLabel: Genetic Algorithms\n\nPaper id: 2174\nTitle: Title: The Role of the Trainer in Reinforcement Learning  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2173\nTitle: Title: Adapting Control Strategies for Situated Autonomous Agents  \nLabel: Genetic Algorithms\n\nPaper id: 2233\nTitle: Title: An unsupervised neural network for low-level control of a wheeled mobile robot: noise resistance, stability,\n\nPaper id: 118\nTitle: Title: Learning to Race: Experiments with a Simulated Race Car  \nLabel: Reinforcement Learning\n\nPaper id: 769\nTitle: Title: On the Relations Between Search and Evolutionary Algorithms  \n\nPaper id: 1311\nTitle: Title: ROBO-SHEPHERD: LEARNING COMPLEX ROBOTIC BEHAVIORS  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1704\nTitle: Title: LBG-U method for vector quantization an improvement over LBG inspired from neural networks  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 687\nTitle: Title: Growing Cell Structures A Self-organizing Network for Unsupervised and Supervised Learning  \nLabel: Neural Networks\n\nPaper id: 745\nTitle: Title: References \"Using Neural Networks to Identify Jets\", Kohonen, \"Self Organized Formation of Topologically Correct Feature\nLabel: Neural Networks\n\nPaper id: 1157\nTitle: Title: Some Competitive Learning Methods  (Some additions and refinements are planned for  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 666\nTitle: Title: NeuroPipe a neural network based system for pipeline inspec-  \nLabel: Neural Networks\n\nPaper id: 1564\nTitle: Title: GROWING RADIAL BASIS FUNCTION NETWORKS  \nLabel: Neural Networks\n\nPaper id: 2162\nTitle: Title: Incremental Class Learning approach and its application to Handwritten Digit Recognition  \nLabel: Neural Networks\n\nPaper id: 1932\nTitle: Title: Constrained Optimization for Neural Map Formation: A Unifying Framework for Weight Growth and Normalization  \nLabel: Neural Networks\n\nPaper id: 355\nTitle: Title: Generalization and Exclusive Allocation of Credit in Unsupervised Category Learning  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1015\nTitle: Title: Bayesian curve fitting using multivariate normal mixtures  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 852\nTitle: Title: Bayesian Models for Non-Linear Autoregressions  \nLabel: Probabilistic Methods\n\nPaper id: 996\nTitle: Title: Reparameterisation Issues in Mixture Modelling and their bearing on MCMC algorithms  \n\nPaper id: 1338\nTitle: Title: Computing Nonparametric Hierarchical Models  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 161\nTitle: Title: On Bayesian analysis of mixtures with an unknown number of components  Summary  \n\nPaper id: 855\nTitle: Title: Hierarchical priors and mixture models, with application in regression and density estimation  \nLabel: Probabilistic Methods\n\nPaper id: 917\nTitle: Title: Practical Bayesian Inference Using Mixtures of Mixtures  \nLabel: Probabilistic Methods\n\nPaper id: 784\nTitle: Title: Studies of Neurological Transmission Analysis using Hierarchical Bayesian Mixture Models  \n\nPaper id: 1654\nTitle: Title: Hyperparameter estimation in Dirichlet process mixture models  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1275\nTitle: Title: Fossil: A Robust Relational Learner  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 378\nTitle: Title: Mingers, 1989 J. Mingers. An empirical comparison of pruning methods for decision tree induction. Machine\n\nPaper id: 2290\nTitle: Title: A Comparison of Pruning Methods for Relational Concept Learning  \nLabel: Rule Learning\n\nPaper id: 344\nTitle: Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In\nLabel: Rule Learning\n\nPaper id: 2617\nTitle: Title: Predicting Ordinal Classes in ILP  \n\nPaper id: 426\nTitle: Title: Rule Induction with CN2: Some Recent Improvements  \nLabel: Rule Learning\n\nPaper id: 1234\nTitle: Title: Concept Learning and the Problem of Small  \nLabel: Rule Learning\n\nPaper id: 585\nTitle: Title: An investigation of noise-tolerant relational concept learning algorithms  \nLabel: Rule Learning\n\nPaper id: 2291\nTitle: Title: Top-Down Pruning in Relational Learning  \nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 963\nTitle: Title: Cooperation of Data-driven and Model-based Induction Methods for Relational Learning  \nLabel: Rule Learning\n\nPaper id: 1\nTitle: Title: Applications of machine learning: a medical follow up study  \n\nPaper id: 1678\nTitle: Title: Induction of One-Level Decision Trees  \n\nPaper id: 218\nTitle: Title: Learning Classification Trees  \nLabel: Probabilistic Methods\n\nPaper id: 2091\nTitle: Title: The Utility of Knowledge in Inductive Learning  Running Head: Knowledge in Inductive Learning  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 656\nTitle: Title: Reinforcement Learning: A Survey  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 650\nTitle: Title: Learning to Use Selective Attention and Short-Term Memory in Sequential Tasks  \nLabel: Reinforcement Learning\n\nPaper id: 773\nTitle: Title: Reinforcement Learning with Imitation in Heterogeneous Multi-Agent Systems  \n\nPaper id: 148\nTitle: Title: Multiagent Reinforcement Learning: Theoretical Framework and an Algorithm  \nLabel: Reinforcement Learning\n\nPaper id: 657\nTitle: Title: Adding Memory to XCS  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 210\nTitle: Title: A Unified Analysis of Value-Function-Based Reinforcement-Learning Algorithms  \nLabel: Reinforcement Learning\n\nPaper id: 460\nTitle: Title: Learning Roles: Behavioral Diversity in Robot Teams  \nLabel: Reinforcement Learning\n\nPaper id: 1006\nTitle: Title: Learning Probabilistic Automata with Variable Memory Length  \nLabel: Theory\n\nPaper id: 483\nTitle: Title: The Parti-game Algorithm for Variable Resolution Reinforcement Learning in Multidimensional State-spaces  \nLabel: Reinforcement Learning\n\nPaper id: 1687\nTitle: Title: Markov games as a framework for multi-agent reinforcement learning  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2676\nTitle: Title: Models of perceptual learning in vernier hyperacuity  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 611\nTitle: Title: Learning networks for face analysis and synthesis  \nLabel: Neural Networks\n\nPaper id: 1787\nTitle: Title: An integrated approach to the study of object features in visual recognition  \n\nPaper id: 2385\nTitle: Title: Receptive Fields for Vision: from Hyperacuity to Object Recognition  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2540\nTitle: Title: Efficient Implementation of Gaussian Processes  \nLabel: Neural Networks\n\nPaper id: 2499\nTitle: Title: Objective Function Formulation of the BCM Theory of Visual Cortical Plasticity: Statistical Connections, Stability Conditions  \n\nPaper id: 511\nTitle: Title: Learning from incomplete data  \nLabel: Probabilistic Methods\n\nPaper id: 716\nTitle: Title: Covariate Selection in Hierarchical Models of Hospital Admission Counts: A Bayes Factor Approach 1  \nLabel: Neural Networks\n\nPaper id: 1488\nTitle: Title: Identification and Control of Nonlinear Systems Using Neural Network Models: Design and Stability Analysis  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1890\nTitle: Title: Genetic Algorithms for Adaptive Planning of Path and Trajectory of a Mobile Robot in 2D Terrains  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 1060\nTitle: Title: An Overview of Genetic Algorithms Part 1, Fundamentals  \n\nPaper id: 2039\nTitle: Title: A Case Study on Tuning of Genetic Algorithms by Using Performance Evaluation Based on Experimental Design  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 402\nTitle: Title: The Evolutionary Cost of Learning  \nLabel: Genetic Algorithms\n\nPaper id: 793\nTitle: Title: A Survey of Evolution Strategies  \nLabel: Genetic Algorithms\n\nPaper id: 2518\nTitle: Title: Tracing the Behavior of Genetic Algorithms Using Expected Values of Bit and Walsh Products  \nLabel: Genetic Algorithms\n\nPaper id: 1689\nTitle: Title: Selection for Wandering Behavior in a Small Robot  \nLabel: Genetic Algorithms\n\nPaper id: 2295\nTitle: Title: Diplomarbeit A Genetic Algorithm for the Topological Optimization of Neural Networks  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2579\nTitle: Title: SPERT-II: A Vector Microprocessor System and its Application to Large Problems in Backpropagation Training  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2336\nTitle: Title: A Fast Kohonen Net Implementation for  \n\nPaper id: 2279\nTitle: Title: Quicknet on MultiSpert: Fast Parallel Neural Network Training  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 745\nTitle: Title: References \"Using Neural Networks to Identify Jets\", Kohonen, \"Self Organized Formation of Topologically Correct Feature\nLabel: Neural Networks\n\nPaper id: 1806\nTitle: Title: MBP on T0: mixing floating- and fixed-point formats in BP learning  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1218\nTitle: Title: Genetic algorithms with multi-parent recombination  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1299\nTitle: Title: Multi-parent Recombination  \nLabel: Genetic Algorithms\n\nPaper id: 145\nTitle: Title: LIBGA: A USER-FRIENDLY WORKBENCH FOR ORDER-BASED GENETIC ALGORITHM RESEARCH  \nLabel: Genetic Algorithms\n\nPaper id: 1571\nTitle: Title: Average-Case Analysis of a Nearest Neighbor Algorithm  \n\nPaper id: 1670\nTitle: Title: Raising GA Performance by Simultaneous Tuning of Selective Pressure and Recombination Disruptiveness  \nLabel: Genetic Algorithms\n\nPaper id: 714\nTitle: Title: Orgy in the Computer: Multi-Parent Reproduction in Genetic Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 1530\nTitle: Title: Performance of Multi-Parent Crossover Operators on Numerical Function Optimization Problems  \nLabel: Genetic Algorithms\n\nPaper id: 1035\nTitle: Title: An Empirical Investigation of Multi-Parent Recombination Operators in Evolution Strategies  \nLabel: Genetic Algorithms\n\nPaper id: 1516\nTitle: Title: Solving 3-SAT by GAs Adapting Constraint Weights  \n\nPaper id: 833\nTitle: Title: Graph Coloring with Adaptive Evolutionary Algorithms  \n\nPaper id: 1424\nTitle: Title: Multi-parent's niche: n-ary crossovers on NK-landscapes  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2361\nTitle: Title: Program Search with a Hierarchical Variable Length Representation: Genetic Programming, Simulated Annealing and Hill Climbing  \nLabel: Genetic Algorithms\n\nPaper id: 2248\nTitle: Title: Heuristic for Improved Genetic Bin Packing  \nLabel: Genetic Algorithms\n\nPaper id: 1573\nTitle: Title: Genetics-based Machine Learning and Behaviour Based Robotics: A New Synthesis complexity grows, the learning task\nLabel: Reinforcement Learning\n\nPaper id: 1890\nTitle: Title: Genetic Algorithms for Adaptive Planning of Path and Trajectory of a Mobile Robot in 2D Terrains  \n\nPaper id: 2200\nTitle: Title: Adaptation in constant utility non-stationary environments  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2558\nTitle: Title: Using Bayesian networks for incorporating probabilistic a priori knowledge into Boltzmann machines  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2514\nTitle: Title: Learning Bayesian Prototype Trees by Simulated Annealing  \nLabel: Probabilistic Methods\n\nPaper id: 450\nTitle: Title: Mapping Bayesian Networks to Boltzmann Machines  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 485\nTitle: Title: Bayesian Case-Based Reasoning with Neural Networks  \nLabel: Probabilistic Methods\n\nPaper id: 646\nTitle: Title: Constructing Computationally Efficient Bayesian Models via Unsupervised Clustering  Probabilistic Reasoning and Bayesian Belief Networks,  \n\nPaper id: 2380\nTitle: Title: Massively Parallel Case-Based Reasoning with Probabilistic Similarity Metrics  \nLabel: Probabilistic Methods\n\nPaper id: 954\nTitle: Title: Unsupervised learning of distributions on binary vectors using two layer networks  \n\nPaper id: 1908\nTitle: Title: Induction of Selective Bayesian Classifiers  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 702\nTitle: Title: Automated Highway System  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 504\nTitle: Title: MANIAC: A Next Generation Neurally Based Autonomous Road Follower  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2583\nTitle: Title: Dynamic Automatic Model Selection  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 102\nTitle: Title: Multivariate versus Univariate Decision Trees  \nLabel: Neural Networks\n\nPaper id: 378\nTitle: Title: Mingers, 1989 J. Mingers. An empirical comparison of pruning methods for decision tree induction. Machine\n\nPaper id: 2310\nTitle: Title: Machine Learning: An Annotated Bibliography for the 1995 AI Statistics Tutorial on Machine Learning (Version 1)  \nLabel: Case Based\n\nPaper id: 1173\nTitle: Title: Dynamical Selection of Learning Algorithms  \nLabel: Theory\n\nPaper id: 2135\nTitle: Title: Learning Polynomial Functions by Feature Construction  \n\nPaper id: 1423\nTitle: Title: Comparison of Regression Methods, Symbolic Induction Methods and Neural Networks in Morbidity Diagnosis and Mortality\nLabel: Neural Networks\n\nPaper id: 2333\nTitle: Title: Recursive Automatic Algorithm Selection for Inductive Learning  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2607\nTitle: Title: Concept Learning and Flexible Weighting  \nLabel: Case Based\n\nPaper id: 1027\nTitle: Title: Pessimistic decision tree pruning based on tree size  \nLabel: Theory\n\nPaper id: 1963\nTitle: Title: Learning Problem-Oriented Decision Structures from Decision Rules: The AQDT-2 System  \nLabel: Rule Learning\n\nPaper id: 2042\nTitle: Title: Fast Bounded Smooth Regression with Lazy Neural Trees  \nLabel: Neural Networks\n\nPaper id: 1238\nTitle: Title: On Pruning and Averaging Decision Trees  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 492\nTitle: Title: Approximating Optimal Policies for Partially Observable Stochastic Domains  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2323\nTitle: Title: PHONETIC CLASSIFICATION OF TIMIT SEGMENTS PREPROCESSED WITH LYON'S COCHLEAR MODEL USING A SUPERVISED/UNSUPERVISED HYBRID NEURAL NETWORK  \n\nPaper id: 213\nTitle: Title: Incremental methods for computing bounds in partially observable Markov decision processes  \nLabel: Reinforcement Learning\n\nPaper id: 1186\nTitle: Title: Rationality and Intelligence  \nLabel: Probabilistic Methods\n\nPaper id: 45\nTitle: Title: Acting under Uncertainty: Discrete Bayesian Models for Mobile-Robot Navigation  \nLabel: Reinforcement Learning\n\nPaper id: 2419\nTitle: Title: Adaptive probabilistic networks  \nLabel: Probabilistic Methods\n\nPaper id: 490\nTitle: Title: Learning policies for partially observable environments: Scaling up  \nLabel: Reinforcement Learning\n\nPaper id: 734\nTitle: Title: Efficient dynamic-programming updates in partially observable Markov decision processes  \nLabel: Reinforcement Learning\n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n\nPaper id: 1741\nTitle: Title: Reinforcement Learning Algorithm for Partially Observable Markov Decision Problems  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2472\nTitle: Title: Toward an Ideal Trainer*  \nLabel: Reinforcement Learning\n\nPaper id: 2\nTitle: Title: Submitted to NIPS96, Section: Applications. Preference: Oral presentation Reinforcement Learning for Dynamic Channel Allocation in\nLabel: Reinforcement Learning\n\nPaper id: 1727\nTitle: Title: Machine Learning, 22(1/2/3):95-121, 1996. On the Worst-case Analysis of Temporal-difference Learning Algorithms  \nLabel: Theory\n\nPaper id: 367\nTitle: Title: Machine Learning,  Explanation-Based Learning and Reinforcement Learning: A Unified View  \nLabel: Reinforcement Learning\n\nPaper id: 173\nTitle: Title: An Upper Bound on the Loss from Approximate Optimal-Value Functions  \nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 975\nTitle: Title: State Reconstruction for Determining Predictability in Driven Nonlinear Acoustical Systems  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1079\nTitle: Title: Nonlinear Prediction of Chaotic Time Series Using Support Vector Machines  \nLabel: Neural Networks\n\nPaper id: 668\nTitle: Title: Nonlinear gated experts for time series: discovering regimes and avoiding overfitting  \nLabel: Neural Networks\n\nPaper id: 74\nTitle: Title: Hierarchical Mixtures of Experts and the EM Algorithm  \nLabel: Probabilistic Methods\n\nPaper id: 76\nTitle: Title: A VIEW OF THE EM ALGORITHM THAT JUSTIFIES INCREMENTAL, SPARSE, AND OTHER VARIANTS  \nLabel: Probabilistic Methods\n\nPaper id: 608\nTitle: Title: Regularization Theory and Neural Networks Architectures  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 622\nTitle: Title: CLASSIFICATION USING HIERARCHICAL MIXTURES OF EXPERTS  \nLabel: Neural Networks\n\nPaper id: 19\nTitle: Title: Validation of Average Error Rate Over Classifiers  \n\nPaper id: 1928\nTitle: Title: Mixtures of Probabilistic Principal Component Analysers  \nLabel: Neural Networks\n\nPaper id: 154\nTitle: Title: Data-driven Modeling and Synthesis of Acoustical Instruments  \n\nPaper id: 2284\nTitle: Title: Performance of On-Line Learning Methods in Predicting Multiprocessor Memory Access Patterns  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2473\nTitle: Title: A Heuristic Approach to the Discovery of Macro-operators. Machine Learning, 3, 285-317. L e a\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 551\nTitle: Title: Utilization Filtering a method for reducing the inherent harmfulness of deductively learned knowledge field of\nLabel: Reinforcement Learning\n\nPaper id: 434\nTitle: Title: Computational Learning in Humans and Machines  \nLabel: Case Based\n\nPaper id: 2551\nTitle: Title: The Role of Forgetting in Learning  \nLabel: Reinforcement Learning\n\nPaper id: 1192\nTitle: Title: Roles of Macro-Actions in Accelerating Reinforcement Learning  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1339\nTitle: Title: An Analysis of Bayesian Classifiers (1988), involves the formulation of average-case models for specific algorithms\nLabel: Theory\n\nPaper id: 321\nTitle: Title: Planning with Closed-Loop Macro Actions  \nLabel: Reinforcement Learning\n\nPaper id: 597\nTitle: Title: Learning Semantic Grammars with Constructive Inductive Logic Programming  \nLabel: Rule Learning\n\nPaper id: 2215\nTitle: Title: Learning Approximate Control Rules Of High Utility  \nLabel: Case Based\n\nPaper id: 482\nTitle: Title: Simple Selection of Utile Control Rules in Speedup Learning  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1479\nTitle: Title: Revising Bayesian Network Parameters Using Backpropagation  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1102\nTitle: Title: Automated Refinement of First-Order Horn-Clause Domain Theories  \nLabel: Rule Learning\n\nPaper id: 2543\nTitle: Title: Combining Connectionist and Symbolic Learning to Refine Certainty-Factor Rule Bases  \nLabel: Probabilistic Methods\n\nPaper id: 136\nTitle: Title: Theory Refinement Combining Analytical and Empirical Methods  \nLabel: Rule Learning\n\nPaper id: 2017\nTitle: Title: 28 Learning Bayesian Networks Using Feature Selection  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2231\nTitle: Title: Explaining Anomalies as a Basis for Knowledge Base Refinement  \nLabel: Case Based\n\nPaper id: 2399\nTitle: Title: Abduction, Experience, and Goals: A Model of Everyday Abductive Explanation*  \nLabel: Case Based\n\nPaper id: 1174\nTitle: Title: LEARNING CONCEPTS BY ASKING QUESTIONS  \nLabel: Theory\n\nPaper id: 2440\nTitle: Title: Modifying Network Architectures for Certainty-Factor Rule-Base Revision  \nLabel: Neural Networks\n\nPaper id: 1370\nTitle: Title: From Theory Refinement to KB Maintenance: a Position Statement  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2235\nTitle: Title: EXACT SIMULATION USING MARKOV CHAINS  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2208\nTitle: Title: Extensions of Fill's algorithm for perfect simulation  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1761\nTitle: Title: An extension of Fill's exact sampling algorithm to non-monotone chains*  \nLabel: Probabilistic Methods\n\nPaper id: 2313\nTitle: Title: PERFECT SIMULATION OF CONDITIONALLY SPECIFIED MODELS  \nLabel: Probabilistic Methods\n\nPaper id: 126\nTitle: Title: Perfect Simulation of some Point Processes for the Impatient User  \nLabel: Probabilistic Methods\n\nPaper id: 2234\nTitle: Title: Perfect Sampling of Harris Recurrent Markov Chains  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1217\nTitle: Title: A game theoretic approach to moving horizon control  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1349\nTitle: Title: Robust performance and adaptation using receding horizon H 1 control of time varying systems.  \nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1695\nTitle: Title: Analogical Problem Solving by Adaptation of Schemes  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1354\nTitle: Title: The Structure-Mapping Engine: Algorithm and Examples  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 75\nTitle: Title: A Memory Model for Case Retrieval by Activation Passing  \n\nPaper id: 1176\nTitle: Title: Distributed Representations and Nested Compositional Structure  \nLabel: Neural Networks\n\nPaper id: 1039\nTitle: Title: Functional Programming by Analogy  \nLabel: Case Based\n\nPaper id: 313\nTitle: Title: The Case for Graph-Structured Representations  \nLabel: Case Based\n\nPaper id: 1304\nTitle: Title: Concept Sharing: A Means to Improve Multi-Concept Learning  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 19\nTitle: Title: Validation of Average Error Rate Over Classifiers  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 571\nTitle: Title: The Central Classifier Bound ANew Error Bound for the Classifier Chosen by Early Stopping Key\nLabel: Theory\n\nPaper id: 74\nTitle: Title: Hierarchical Mixtures of Experts and the EM Algorithm  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2421\nTitle: Title: On Convergence of the EM Algorithm and the Gibbs Sampler  SUMMARY  \nLabel: Probabilistic Methods\n\nPaper id: 1024\nTitle: Title: On learning hierarchical classifications  \nLabel: Theory\n\nPaper id: 1103\nTitle: Reference: [39] <author> Yoda, M. </author> <year> (1994). </year> <title> Predicting the Tokyo stock market. </title> <editor> In Deboeck, G.J. (Ed.) </editor> <year> (1994). </year> <title> Trading on the Edge. </title> <address> New York: </address> <publisher> Wiley., </publisher> <pages> 66-79. </pages> <institution> VITA Graduate School Southern Illinois University Daniel Nikolaev Nikovski Date of Birth: </institution> <address> April 13, 1969 606 West College Street, Apt.4, Rm. 6, Carbondale, Illinois 62901 150 Hristo Botev Boulevard, Apt. </address> <month> 54, </month> <title> 4004 Plovdiv, Bulgaria Technical University - Sofia, Bulgaria Engineer of Computer Systems and Control Thesis Title: Adaptive Computation Techniques for Time Series Analysis Major Professor: </title> <journal> Dr. Mehdi Zargham </journal>\nLabel: Neural Networks\n\nPaper id: 2694\nTitle: Title: Partition-Based Uniform Error Bounds  \nLabel: Theory\n\nPaper id: 2284\nTitle: Title: Performance of On-Line Learning Methods in Predicting Multiprocessor Memory Access Patterns  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1635\nTitle: Title: Redesigning control knowledge of knowledge-based systems: machine learning meets knowledge engineering  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1706\nTitle: Title: A Performance Model for Knowledge-based Systems  \nLabel: Case Based\n\nPaper id: 1214\nTitle: Title: Learning Problem-Solving Concepts by Reflecting on Problem Solving  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 583\nTitle: Title: Introspective reasoning using meta-explanations for multistrategy learning  \nLabel: Case Based\n\nPaper id: 799\nTitle: Title: A utility-based approach to learning in a mixed Case-Based and Model-Based Reasoning architecture  \nLabel: Case Based\n\nPaper id: 523\nTitle: Title: Some studies in machine learning using the game of checkers. IBM Journal, 3(3):211-229, 1959. Some\nLabel: Genetic Algorithms\n\nPaper id: 1385\nTitle: Title: Learning Control Knowledge in Models of Expertise ECML'95 Workshop on Knowledge-Level Modelling and Machine Learning  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1141\nTitle: Title: Bayesian Graphical Modeling for Intelligent Tutoring Systems  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1172\nTitle: Title: Introduction to the Special Section on Knowledge-Based Construction of Probabilistic and Decision Models (IEEE Transactions\nLabel: Probabilistic Methods\n\nPaper id: 1240\nTitle: Title: Model Selection and Accounting for Model Uncertainty in Linear Regression Models  \nLabel: Probabilistic Methods\n\nPaper id: 1241\nTitle: Title: Bayesian Graphical Models for Discrete Data  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 84\nTitle: Title: Approximate Bayes Factors and Accounting for Model Uncertainty in Generalized Linear Models  \nLabel: Probabilistic Methods\n\nPaper id: 2108\nTitle: Title: The Automated Mapping of Plans for Plan Recognition  \nLabel: Probabilistic Methods\n\nPaper id: 1347\nTitle: Title: Markov Chain Monte Carlo Model Determination for Hierarchical and Graphical Log-linear Models  \nLabel: Probabilistic Methods\n\nPaper id: 623\nTitle: Title: State-Space Abstraction for Anytime Evaluation of Probabilistic Networks  \n\nPaper id: 950\nTitle: Title: Model Selection for Generalized Linear Models via GLIB, with Application to Epidemiology 1  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 400\nTitle: Title: Learning Algorithms with Applications to Robot Navigation and Protein Folding  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 258\nTitle: Title: Using Dirichlet Mixture Priors to Derive Hidden Markov Models for Protein Families  \nLabel: Neural Networks\n\nPaper id: 2360\nTitle: Title: Efficient Learning of Typical Finite Automata from Random Walks (Extended Abstract)  \nLabel: Theory\n\nPaper id: 14\nTitle: Title: Hidden Markov Models in Computational Biology: Applications to Protein Modeling UCSC-CRL-93-32 Keywords: Hidden Markov Models,\nLabel: Neural Networks\n\nPaper id: 2354\nTitle: Title: The Power of Team Exploration: Two Robots Can Learn Unlabeled Directed Graphs  \nLabel: Theory\n\nPaper id: 555\nTitle: Title: Exactly Learning Automata with Small Cover Time  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2273\nTitle: Title: Learning Harmonic Progression Using Markov Models EECS545 Project  \nLabel: Theory\n\nPaper id: 574\nTitle: Title: On the Learnability of Discrete Distributions (extended abstract)  \n\nPaper id: 1111\nTitle: Title: Towards a Better Understanding of Memory-Based Reasoning Systems  \nLabel: Case Based\n\nPaper id: 615\nTitle: Title: Efficient Algorithms for Learning to Play Repeated Games Against Computationally Bounded Adversaries  \nLabel: Theory\n\nPaper id: 393\nTitle: Title: Density Networks and their Application to Protein Modelling  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1816\nTitle: Title: Generalized Prioritized Sweeping  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 559\nTitle: Title: Scaling Up Average Reward Reinforcement Learning by Approximating the Domain Models and the Value Function  \n\nPaper id: 2485\nTitle: Title: Tight Performance Bounds on Greedy Policies Based on Imperfect Value Functions  \nLabel: Reinforcement Learning\n\nPaper id: 566\nTitle: Title: Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming  \nLabel: Reinforcement Learning\n\nPaper id: 558\nTitle: Title: A Tutorial on Learning With Bayesian Networks  \nLabel: Probabilistic Methods\n\nPaper id: 1934\nTitle: Title: Sequential Update of Bayesian Network Structure  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1137\nTitle: Title: Learning Conventions in Multiagent Stochastic Domains using Likelihood Estimates  \nLabel: Reinforcement Learning\n\nPaper id: 186\nTitle: Title: Adaptive state space quantisation: adding and removing neurons  \n\nPaper id: 1378\nTitle: Title: Generalization in Reinforcement Learning: Safely Approximating the Value Function  \nLabel: Reinforcement Learning\n\nPaper id: 465\nTitle: Title: Strategy Learning with Multilayer Connectionist Representations 1  \nLabel: Reinforcement Learning\n\nPaper id: 557\nTitle: Title: On the Sample Complexity of Learning Bayesian Networks  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2559\nTitle: Title: \"Linear Dependencies Represented by Chain Graphs,\" \"Graphical Modelling With MIM,\" Manual. \"Identifying Independence in Bayesian\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 51\nTitle: Title: An Alternative Markov Property for Chain Graphs  \nLabel: Probabilistic Methods\n\nPaper id: 260\nTitle: Title: ASPECTS OF GRAPHICAL MODELS CONNECTED WITH CAUSALITY  \nLabel: Probabilistic Methods\n\nPaper id: 2076\nTitle: Title: Automated Discovery of Linear Feedback Models 1  \n\nPaper id: 841\nTitle: Title: Bayesian inference for nondecomposable graphical Gaussian models  \nLabel: Probabilistic Methods\n\nPaper id: 1747\nTitle: Title: FROM BAYESIAN NETWORKS TO CAUSAL NETWORKS  \nLabel: Probabilistic Methods\n\nPaper id: 1241\nTitle: Title: Bayesian Graphical Models for Discrete Data  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 998\nTitle: Title: Accounting for Model Uncertainty in Survival Analysis Improves Predictive Performance  \nLabel: Probabilistic Methods\n\nPaper id: 2069\nTitle: Title: A Note on Testing Exogeneity of Instrumental Variables (DRAFT PAPER)  \nLabel: Probabilistic Methods\n\nPaper id: 84\nTitle: Title: Approximate Bayes Factors and Accounting for Model Uncertainty in Generalized Linear Models  \nLabel: Probabilistic Methods\n\nPaper id: 2434\nTitle: Title: Causal Inference from Indirect Experiments  \nLabel: Probabilistic Methods\n\nPaper id: 1240\nTitle: Title: Model Selection and Accounting for Model Uncertainty in Linear Regression Models  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1130\nTitle: Title: Dynamic Hill Climbing: Overcoming the limita- tions of optimization techniques  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 959\nTitle: Title: Numerical techniques for efficient sonar bearing and range searching in the near field using genetic algorithms  \n\nPaper id: 1334\nTitle: Title: THE OPTIONS DESIGN EXPLORATION SYSTEM Reference Manual and User Guide Version B2.1  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1575\nTitle: Title: A Comparative Study of Genetic Search  \nLabel: Genetic Algorithms\n\nPaper id: 1689\nTitle: Title: Selection for Wandering Behavior in a Small Robot  \nLabel: Genetic Algorithms\n\nPaper id: 1257\nTitle: Title: The Schema Theorem and Price's Theorem  \n\nPaper id: 1069\nTitle: Title: Extended Selection Mechanisms in Genetic Algorithms  \n\nPaper id: 1571\nTitle: Title: Average-Case Analysis of a Nearest Neighbor Algorithm  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 640\nTitle: Title: Learning in the Presence of Malicious Errors  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 635\nTitle: Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features  \n\nPaper id: 1363\nTitle: Title: Exact Identification of Read-once Formulas Using Fixed Points of Amplification Functions  \n\nPaper id: 20\nTitle: Title: 25 Learning in Hybrid Noise Environments Using Statistical Queries  \nLabel: Theory\n\nPaper id: 2054\nTitle: Title: Tracking Drifting Concepts By Minimizing Disagreements  \nLabel: Theory\n\nPaper id: 459\nTitle: Title: Pac Learning, Noise, and Geometry  \n\nPaper id: 591\nTitle: Title: Toward Efficient Agnostic Learning  \nLabel: Theory\n\nPaper id: 130\nTitle: Title: PAC-Learning PROLOG clauses with or without errors  \n\nPaper id: 109\nTitle: Title: A General Lower Bound on the Number of Examples Needed for Learning  \nLabel: Theory\n\nPaper id: 2475\nTitle: Title: Learning polynomials with queries: The highly noisy case  task for the case when F  \nLabel: Theory\n\nPaper id: 287\nTitle: Title: Learning Switching Concepts  \nLabel: Theory\n\nPaper id: 574\nTitle: Title: On the Learnability of Discrete Distributions (extended abstract)  \n\nPaper id: 732\nTitle: Title: Statistical Queries and Faulty PAC Oracles  \n\nPaper id: 1897\nTitle: Title: On Learning Visual Concepts and DNF Formulae  \nLabel: Theory\n\nPaper id: 199\nTitle: Title: On Learning Conjunctions with Malicious Noise  \nLabel: Theory\n\nPaper id: 549\nTitle: Title: Efficient Distribution-free Learning of Probabilistic Concepts  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2685\nTitle: Title: Learning under persistent drift  \nLabel: Theory\n\nPaper id: 2246\nTitle: Title: Learning to model sequences generated by switching distributions  \nLabel: Theory\n\nPaper id: 25\nTitle: Title: General Bounds on Statistical Query Learning and PAC Learning with Noise via Hypothesis Boosting  \nLabel: Theory\n\nPaper id: 1343\nTitle: Title: Randomly Fallible Teachers: Learning Monotone DNF with an Incomplete Membership Oracle  \nLabel: Theory\n\nPaper id: 208\nTitle: Title: Feature Subset Selection as Search with Probabilistic Estimates  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1045\nTitle: Title: Spurious Solutions to the Bellman Equation  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1540\nTitle: Title: MultiPlayer Residual Advantage Learning With General Function Approximation  \n\nPaper id: 471\nTitle: Title: In  Improving Elevator Performance Using Reinforcement Learning  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1459\nTitle: Title: Generalized Markov Decision Processes: Dynamic-programming and Reinforcement-learning Algorithms  \nLabel: Reinforcement Learning\n\nPaper id: 1859\nTitle: Title: Self-Improving Factory Simulation using Continuous-time Average-Reward Reinforcement Learning  \nLabel: Reinforcement Learning\n\nPaper id: 2\nTitle: Title: Submitted to NIPS96, Section: Applications. Preference: Oral presentation Reinforcement Learning for Dynamic Channel Allocation in\nLabel: Reinforcement Learning\n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n\nPaper id: 842\nTitle: Title: Metrics for Temporal Difference Learning  \nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2274\nTitle: Title: Specialization in Populations of Artificial Neural Networks  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2237\nTitle: Title: Specialization under Social Conditions in Shared Environments  \n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2200\nTitle: Title: Adaptation in constant utility non-stationary environments  \n\nPaper id: 658\nTitle: Title: Hill Climbing with Learning (An Abstraction of Genetic Algorithm)  \n\nPaper id: 1784\nTitle: Title: Genetic Programming and Redundancy  \nLabel: Genetic Algorithms\n\nPaper id: 624\nTitle: Title: Measuring the Difficulty of Specific Learning Problems  \nLabel: Theory\n\nPaper id: 2251\nTitle: Title: A PARALLEL ISLAND MODEL GENETIC ALGORITHM FOR THE MULTIPROCESSOR SCHEDULING PROBLEM  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2553\nTitle: Title: TURING COMPUTABILITY WITH NEURAL NETS  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1875\nTitle: Title: On the Effect of Analog Noise in Discrete-Time Analog Computations  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1891\nTitle: Title: Vapnik-Chervonenkis Dimension of Recurrent Neural Networks  \nLabel: Neural Networks\n\nPaper id: 2439\nTitle: Title: Analog Neural Nets with Gaussian or other Common Noise Distributions cannot Recognize Arbitrary Regular Languages  \nLabel: Neural Networks\n\nPaper id: 407\nTitle: Title: Constructing Deterministic Finite-State Automata in Recurrent Neural Networks  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2324\nTitle: Title: APPLICATION OF ESOP MINIMIZATION IN MACHINE LEARNING AND KNOWLEDGE DISCOVERY  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2326\nTitle: Title: Pattern Theoretic Feature Extraction and Constructive Induction  \nLabel: Theory\n\nPaper id: 1161\nTitle: Title: Inductive Learning by Selection of Minimal Complexity Representations  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 508\nTitle: Title: Machine Learning by Function Decomposition  \nLabel: Theory\n\nPaper id: 2423\nTitle: Title: Error-Correcting Output Codes: A General Method for Improving Multiclass Inductive Learning Programs  \nLabel: Theory\n\nPaper id: 317\nTitle: Title: A dataset decomposition approach to data mining and machine discovery  \n\nPaper id: 2657\nTitle: Title: Learning Complex Boolean Functions: Algorithms and Applications  \nLabel: Theory\n\nPaper id: 1560\nTitle: Title: DESIGN AND ANALYSIS OF EFFICIENT REINFORCEMENT LEARNING ALGORITHMS  \nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 499\nTitle: Title: IMPROVING THE MEAN FIELD APPROXIMATION VIA THE USE OF MIXTURE DISTRIBUTIONS  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 250\nTitle: Title: Mean Field Theory for Sigmoid Belief Networks  \nLabel: Probabilistic Methods\n\nPaper id: 1287\nTitle: Title: Factorial Hidden Markov Models  \nLabel: Probabilistic Methods\n\nPaper id: 1288\nTitle: Title: Exploiting Tractable Substructures in Intractable Networks  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 736\nTitle: Title: GIBBS-MARKOV MODELS  \nLabel: Neural Networks\n\nPaper id: 787\nTitle: Title: Hidden Markov decision trees  \nLabel: Probabilistic Methods\n\nPaper id: 1502\nTitle: Title: Belief Networks, Hidden Markov Models, and Markov Random Fields: a Unifying View  \nLabel: Probabilistic Methods\n\nPaper id: 905\nTitle: Title: Compositional Modeling With DPNs  \nLabel: Probabilistic Methods\n\nPaper id: 498\nTitle: Title: A variational approach to Bayesian logistic regression models and their extensions  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2568\nTitle: Title: Abstract  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 583\nTitle: Title: Introspective reasoning using meta-explanations for multistrategy learning  \nLabel: Case Based\n\nPaper id: 2544\nTitle: Title: Choosing Learning Strategies to Achieve Learning Goals  \nLabel: Case Based\n\nPaper id: 612\nTitle: Title: Indexing, Elaboration and Refinement: Incremental Learning of Explanatory Cases  \nLabel: Case Based\n\nPaper id: 289\nTitle: Title: A theory of questions and question asking  \nLabel: Case Based\n\nPaper id: 717\nTitle: Title: Information filtering: Selection mechanisms in learning systems. Machine Learning, 10:113-151, 1993. Generalization as search. Artificial\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1046\nTitle: Title: Model-Based Learning of Structural Indices to Design Cases  \nLabel: Case Based\n\nPaper id: 1535\nTitle: Title: Decision Models: A Theory of Volitional Explanation  \nLabel: Case Based\n\nPaper id: 50\nTitle: Title: Abstract  \n\nPaper id: 1877\nTitle: Title: Learning High Utility Rules by Incorporating Search Control  Guidance Committee  \nLabel: Case Based\n\nPaper id: 1214\nTitle: Title: Learning Problem-Solving Concepts by Reflecting on Problem Solving  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2638\nTitle: Title: An Evolutionary Heuristic for the Minimum Vertex Cover Problem  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 2202\nTitle: Title: An Evolutionary Approach to Combinatorial Optimization Problems  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2196\nTitle: Title: Effects of Occam's Razor in Evolving Sigma-Pi Neural Nets  \nLabel: Genetic Algorithms\n\nPaper id: 658\nTitle: Title: Hill Climbing with Learning (An Abstraction of Genetic Algorithm)  \n\nPaper id: 1784\nTitle: Title: Genetic Programming and Redundancy  \nLabel: Genetic Algorithms\n\nPaper id: 624\nTitle: Title: Measuring the Difficulty of Specific Learning Problems  \nLabel: Theory\n\nPaper id: 2251\nTitle: Title: A PARALLEL ISLAND MODEL GENETIC ALGORITHM FOR THE MULTIPROCESSOR SCHEDULING PROBLEM  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 330\nTitle: Title: Local Feature Analysis: A general statistical theory for object representation  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 359\nTitle: Title: Feature Extraction Using an Unsupervised Neural Network  \nLabel: Neural Networks\n\nPaper id: 747\nTitle: Title: Cholinergic suppression of transmission may allow combined associative memory function and self-organization in the neocortex.  \n\nPaper id: 576\nTitle: Title: An information-maximisation approach to blind separation and blind deconvolution  \nLabel: Neural Networks\n\nPaper id: 354\nTitle: Title: Principal and Independent Components in Neural Networks Recent Developments  \nLabel: Neural Networks\n\nPaper id: 731\nTitle: Title: LEARNING FACTORIAL CODES BY PREDICTABILITY MINIMIZATION (Neural Computation, 4(6):863-879, 1992)  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1932\nTitle: Title: Constrained Optimization for Neural Map Formation: A Unifying Framework for Weight Growth and Normalization  \nLabel: Neural Networks\n\nPaper id: 685\nTitle: Title: Performance of the GCel-512 and PowerXPlorer for parallel neural network simulations  \nLabel: Neural Networks\n\nPaper id: 293\nTitle: Title: Independent Component Analysis of Electroencephalographic Data  \n\nPaper id: 235\nTitle: Title: Development of triadic neural circuits for visual image stabilization under eye movements  \nLabel: Neural Networks\n\nPaper id: 386\nTitle: Title: Temporal Compositional Processing by a DSOM Hierarchical Model  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1806\nTitle: Title: MBP on T0: mixing floating- and fixed-point formats in BP learning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2570\nTitle: Title: In  Fast Non-Linear Dimension Reduction  \n\nPaper id: 2279\nTitle: Title: Quicknet on MultiSpert: Fast Parallel Neural Network Training  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 667\nTitle: Title: Recognizing Handwritten Digits Using Mixtures of Linear Models  \nLabel: Neural Networks\n\nPaper id: 1928\nTitle: Title: Mixtures of Probabilistic Principal Component Analysers  \nLabel: Neural Networks\n\nPaper id: 2579\nTitle: Title: SPERT-II: A Vector Microprocessor System and its Application to Large Problems in Backpropagation Training  \n\nPaper id: 480\nTitle: Title: Modelling the Manifolds of Images of Handwritten Digits  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 828\nTitle: Title: AN ANYTIME APPROACH TO CONNECTIONIST THEORY REFINEMENT: REFINING THE TOPOLOGIES OF KNOWLEDGE-BASED NEURAL NETWORKS  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1457\nTitle: Title: Actively Searching for an Effective Neural-Network Ensemble  \nLabel: Neural Networks\n\nPaper id: 1422\nTitle: Title: Generating Accurate and Diverse Members of a Neural-Network Ensemble  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 1657\nTitle: Title: Using Neural Networks to Automatically Refine Expert System Knowledge Bases: Experiments in the NYNEX MAX Domain  \nLabel: Neural Networks\n\nPaper id: 1462\nTitle: Title: Learning from Bad Data  \nLabel: Neural Networks\n\nPaper id: 1273\nTitle: Title: The Sources of Increased Accuracy for Two Proposed Boosting Algorithms  \nLabel: Theory\n\nPaper id: 826\nTitle: Title: Combining the Predictions of Multiple Classifiers: Using Competitive Learning to Initialize Neural Networks  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1785\nTitle: Title: A DISCUSSION ON SOME DESIGN PRINCIPLES FOR EFFICIENT CROSSOVER OPERATORS FOR GRAPH COLORING PROBLEMS  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2564\nTitle: Title: Embedding of a sequential procedure within an evolutionary algorithm for coloring problems in graphs  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 1159\nTitle: Title: An evolutionary tabu search algorithm and the NHL scheduling problem  \nLabel: Genetic Algorithms\n\nPaper id: 1558\nTitle: Title: How good are genetic algorithms at finding large cliques: an experimental study  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 190\nTitle: Title: Spline Smoothing For Bivariate Data With Applications To Association Between Hormones  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 356\nTitle: Title: A Flexible Model For Human Circadian Rhythms  \n\nPaper id: 519\nTitle: Title: Smoothing Spline ANOVA for Exponential Families, with Application to the Wisconsin Epidemiological Study of Diabetic\nLabel: Neural Networks\n\nPaper id: 2223\nTitle: Title: Smoothing Spline Models With Correlated Random Errors 1  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2549\nTitle: Title: A Generalized Approximate Cross Validation for Smoothing Splines with Non-Gaussian Data 1  \nLabel: Neural Networks\n\nPaper id: 2608\nTitle: Title: Testing the Generalized Linear Model Null Hypothesis versus `Smooth' Alternatives 1  \n\nPaper id: 10\nTitle: Title: GRKPACK: FITTING SMOOTHING SPLINE ANOVA MODELS FOR EXPONENTIAL FAMILIES  \nLabel: Neural Networks\n\nPaper id: 280\nTitle: Title: USING SMOOTHING SPLINE ANOVA TO EXAMINE THE RELATION OF RISK FACTORS TO THE INCIDENCE AND\nLabel: Probabilistic Methods\n\nPaper id: 510\nTitle: Title: The Bayesian Approach to Tree-Structured Regression  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1008\nTitle: Title: Induction of decision trees using RELIEFF  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1011\nTitle: Title: Discretization of continuous attributes using ReliefF  \nLabel: Rule Learning\n\nPaper id: 1486\nTitle: Title: Induction of decision trees and Bayesian classification applied to diagnosis of sport injuries  \nLabel: Rule Learning\n\nPaper id: 1569\nTitle: Title: Estimating Attributes: Analysis and Extensions of RELIEF  \nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 208\nTitle: Title: Feature Subset Selection as Search with Probabilistic Estimates  \nLabel: Theory\n\nPaper id: 426\nTitle: Title: Rule Induction with CN2: Some Recent Improvements  \nLabel: Rule Learning\n\nPaper id: 1073\nTitle: Title: An adaptation of Relief for attribute estimation in regression  \nLabel: Rule Learning\n\nPaper id: 877\nTitle: Title: Naive Bayesian classifier within ILP-R  \n\nPaper id: 1726\nTitle: Title: Prognosing the Survival Time of the Patients with the Anaplastic Thyroid Carcinoma with Machine Learning  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1400\nTitle: Title: Towards Robust Model Selection using Estimation and Approximation Error Bounds  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 967\nTitle: Title: Rigorous Learning Curve Bounds from Statistical Mechanics  \nLabel: Theory\n\nPaper id: 848\nTitle: Title: An Experimental and Theoretical Comparison of Model Selection Methods on simple model selection problems, the\nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 56\nTitle: Title: Self bounding learning algorithms  \nLabel: Theory\n\nPaper id: 57\nTitle: Title: Markov Decision Processes in Large State Spaces  \nLabel: Reinforcement Learning\n\nPaper id: 957\nTitle: Title: ANNEALED THEORIES OF LEARNING  \n\nPaper id: 591\nTitle: Title: Toward Efficient Agnostic Learning  \nLabel: Theory\n\nPaper id: 306\nTitle: Title: Learning Curve Bounds for Markov Decision Processes with Undiscounted Rewards  \nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1603\nTitle: Title: Evolving Complex Structures via Co- operative Coevolution  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1114\nTitle: Title: Using Genetic Algorithms to Explore Pattern Recognition in the Immune System  COMMENTS WELCOME  \nLabel: Genetic Algorithms\n\nPaper id: 1117\nTitle: Title: A Coevolutionary Approach to Learning Sequential Decision Rules  \nLabel: Genetic Algorithms\n\nPaper id: 2089\nTitle: Title: A Cooperative Coevolutionary Approach to Function Optimization  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 247\nTitle: Title: Machine Learning,  Efficient Reinforcement Learning through Symbiotic Evolution  \nLabel: Reinforcement Learning\n\nPaper id: 714\nTitle: Title: Orgy in the Computer: Multi-Parent Reproduction in Genetic Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 562\nTitle: Title: Transfer of Learning by Composing Solutions of Elemental Sequential Tasks  \n\nPaper id: 1588\nTitle: Title: Automatic Modularization by Speciation  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1794\nTitle: Title: NONLINEAR NONEQUILIBRIUM NONQUANTUM NONCHAOTIC STATISTICAL MECHANICS OF NEOCORTICAL INTERACTIONS  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1795\nTitle: Title: Application of statistical mechanics methodol- ogy to term-structure bond-pricing models, Mathl. Comput. Modelling Application of\nLabel: Neural Networks\n\nPaper id: 2178\nTitle: Title: Statistical Mechanics of Nonlinear Nonequilibrium Financial Markets: Applications to Optimized Trading  \nLabel: Neural Networks\n\nPaper id: 2545\nTitle: Title: Volatility of Volatility of Financial Markets  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2181\nTitle: Title: Statistical mechanics of neocortical interactions: Training and testing canonical momenta indicators of EEG  \nLabel: Neural Networks\n\nPaper id: 1773\nTitle: Title: Canonical Momenta Indicators of Financial Markets and Neocortical EEG  \n\nPaper id: 1793\nTitle: Title: STATISTICAL MECHANICS OF COMBAT WITH HUMAN FACTORS  \nLabel: Neural Networks\n\nPaper id: 1788\nTitle: Title: Path-integral evolution of chaos embedded in noise: Duffing neocortical analog  \nLabel: Neural Networks\n\nPaper id: 1775\nTitle: Title: GENETIC ALGORITHMS AND VERY FAST SIMULATED REANNEALING: A COMPARISON  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2233\nTitle: Title: An unsupervised neural network for low-level control of a wheeled mobile robot: noise resistance, stability,\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 636\nTitle: Title: Robot Shaping: Developing Situated Agents through Learning  \nLabel: Reinforcement Learning\n\nPaper id: 703\nTitle: Title: VECTOR ASSOCIATIVE MAPS: UNSUPERVISED REAL-TIME ERROR-BASED LEARNING AND CONTROL OF MOVEMENT TRAJECTORIES  \n\nPaper id: 2201\nTitle: Title: Neural competitive maps for reactive and adaptive navigation  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2204\nTitle: Title: University of Nevada Reno Design Strategies for Evolutionary Robotics  \nLabel: Genetic Algorithms\n\nPaper id: 2687\nTitle: Title: ALECSYS and the AutonoMouse: Learning to Control a Real Robot by Distributed Classifier Systems  \n\nPaper id: 118\nTitle: Title: Learning to Race: Experiments with a Simulated Race Car  \nLabel: Reinforcement Learning\n\nPaper id: 747\nTitle: Title: Cholinergic suppression of transmission may allow combined associative memory function and self-organization in the neocortex.  \n\nPaper id: 1573\nTitle: Title: Genetics-based Machine Learning and Behaviour Based Robotics: A New Synthesis complexity grows, the learning task\nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1853\nTitle: Title: 99-113. Construction of Phylogenetic Trees, Science, Fitting the Gene Lineage Into Its Species Lineage. A\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2320\nTitle: Title: Inserting the best known bounds for weighted bipar tite matching [11], with 1=2 p polynomial-time\nLabel: Theory\n\nPaper id: 1861\nTitle: Title: A Six-Point Condition for Ordinal Matrices  keywords: additive, algorithm, evolution, ordinal, phylogeny  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2511\nTitle: Title: A Faster Algorithm for the Perfect Phylogeny Problem when the number of Characters is Fixed TR94-05  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 559\nTitle: Title: Scaling Up Average Reward Reinforcement Learning by Approximating the Domain Models and the Value Function  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 34\nTitle: Title: Using a Case Base of Surfaces to Speed-Up Reinforcement Learning  \n\nPaper id: 167\nTitle: Title: Auto-exploratory Average Reward Reinforcement Learning  \nLabel: Reinforcement Learning\n\nPaper id: 2341\nTitle: Title: Dynamic Belief Networks for Discrete Monitoring  \nLabel: Probabilistic Methods\n\nPaper id: 552\nTitle: Title: Learning to Act using Real-Time Dynamic Programming  \nLabel: Reinforcement Learning\n\nPaper id: 1816\nTitle: Title: Generalized Prioritized Sweeping  \n\nPaper id: 1378\nTitle: Title: Generalization in Reinforcement Learning: Safely Approximating the Value Function  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2\nTitle: Title: Submitted to NIPS96, Section: Applications. Preference: Oral presentation Reinforcement Learning for Dynamic Channel Allocation in\nLabel: Reinforcement Learning\n\nPaper id: 60\nTitle: Title: The Efficient Learning of Multiple Task Sequences  \nLabel: Reinforcement Learning\n\nPaper id: 601\nTitle: Title: Active Gesture Recognition using Partially Observable Markov Decision Processes  \nLabel: Reinforcement Learning\n\nPaper id: 723\nTitle: Title: Exploiting Structure in Policy Construction  \nLabel: Probabilistic Methods\n\nPaper id: 239\nTitle: Title: Robust Value Function Approximation by Working Backwards Computing an accurate value function is the key\nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1996\nTitle: Title: A New Algorithm for DNA Sequence Assembly  Running Title: A New Algorithm for DNA Sequence Assembly  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1997\nTitle: Title: AMASS: A Structured Pattern Matching Approach to Shotgun Sequence Assembly  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 797\nTitle: Title: Regularities in a Random Mapping from Orthography to Semantics  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1645\nTitle: Title: Acquiring the mapping from meaning to sounds  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 477\nTitle: Title: Forward models: Supervised learning with a distal teacher  \nLabel: Reinforcement Learning\n\nPaper id: 204\nTitle: Title: Natural Language Processing with Subsymbolic Neural Networks  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2336\nTitle: Title: A Fast Kohonen Net Implementation for  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2579\nTitle: Title: SPERT-II: A Vector Microprocessor System and its Application to Large Problems in Backpropagation Training  \n\nPaper id: 745\nTitle: Title: References \"Using Neural Networks to Identify Jets\", Kohonen, \"Self Organized Formation of Topologically Correct Feature\nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1157\nTitle: Title: Some Competitive Learning Methods  (Some additions and refinements are planned for  \nLabel: Neural Networks\n\nPaper id: 666\nTitle: Title: NeuroPipe a neural network based system for pipeline inspec-  \nLabel: Neural Networks\n\nPaper id: 110\nTitle: Title: Data Exploration Using Self-Organizing Maps  \nLabel: Neural Networks\n\nPaper id: 600\nTitle: Title: Separating hippocampal maps  Spatial Functions of the Hippocampal Formation and the  \n\nPaper id: 2279\nTitle: Title: Quicknet on MultiSpert: Fast Parallel Neural Network Training  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2070\nTitle: Title: A Partial Memory Incremental Learning Methodology And Its Application To Computer Intrusion Detection  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2640\nTitle: Title: Learning Evolving Concepts Using Partial-Memory Approach  Machine Learning and Inference Laboratory  \nLabel: Rule Learning\n\nPaper id: 2602\nTitle: Title: A Method for Partial-Memory Incremental Learning and its Application to Computer Intrusion Detection Machine Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 245\nTitle: Title: ICML-96 Workshop \"Learning in context-sensitive domains\" Bari, Italy. Dynamically Adjusting Concepts to Accommodate Changing Contexts  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1636\nTitle: Title: Context-Sensitive Feature Selection for Lazy Learners  \n\nPaper id: 172\nTitle: Title: Efficient Feature Selection in Conceptual Clustering  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1684\nTitle: Title: Context-sensitive attribute estimation in regression  \nLabel: Rule Learning\n\nPaper id: 430\nTitle: Title: Irrelevant Features and the Subset Selection Problem  \nLabel: Theory\n\nPaper id: 983\nTitle: Title: Refining Conversational Case Libraries  \nLabel: Case Based\n\nPaper id: 928\nTitle: Title: Learning to Refine Case Libraries:  \n\nPaper id: 635\nTitle: Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2688\nTitle: Title: An Adverse Interaction between the Crossover Operator and a Restriction on Tree Depth of Crossover\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1839\nTitle: Title: Context Preserving Crossover in Genetic Programming.  \nLabel: Genetic Algorithms\n\nPaper id: 2216\nTitle: Title: Hybridized Crossover-Based Search Techniques for Program Discovery  \nLabel: Genetic Algorithms\n\nPaper id: 1784\nTitle: Title: Genetic Programming and Redundancy  \nLabel: Genetic Algorithms\n\nPaper id: 1840\nTitle: Title: Hierarchical Genetic Programming (HGP) extensions discover, modify, and exploit subroutines to accelerate the evolution of\nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2361\nTitle: Title: Program Search with a Hierarchical Variable Length Representation: Genetic Programming, Simulated Annealing and Hill Climbing  \nLabel: Genetic Algorithms\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 1184\nTitle: Title: Causality in Genetic Programming  \n\nPaper id: 55\nTitle: Title: A Comparison of Selection Schemes used in Genetic Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 2705\nTitle: Title: The MAX Problem for Genetic Programming Highlighting an Adverse Interaction between the Crossover Operator and\nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1682\nTitle: Title: WaveShrink: Shrinkage Functions and Thresholds  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1681\nTitle: Title: Understanding WaveShrink: Variance and Bias Estimation  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 392\nTitle: Title: DRAFT Cluster-Weighted Modeling for Time Series Prediction and Characterization  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 154\nTitle: Title: Data-driven Modeling and Synthesis of Acoustical Instruments  \n\nPaper id: 76\nTitle: Title: A VIEW OF THE EM ALGORITHM THAT JUSTIFIES INCREMENTAL, SPARSE, AND OTHER VARIANTS  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 74\nTitle: Title: Hierarchical Mixtures of Experts and the EM Algorithm  \nLabel: Probabilistic Methods\n\nPaper id: 131\nTitle: Title: The Expectation-Maximization Algorithm for MAP Estimation  \nLabel: Probabilistic Methods\n\nPaper id: 518\nTitle: Title: Developments in Probabilistic Modelling with Neural Networks|Ensemble Learning  \nLabel: Theory\n\nPaper id: 2532\nTitle: Title: Ensemble Learning for Hidden Markov Models  \n\nPaper id: 1548\nTitle: Title: Free energy coding  In  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1062\nTitle: Title: Exponentially many local minima for single neurons  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1254\nTitle: Title: BACKPROPAGATION SEPARATES WHERE PERCEPTRONS DO  \nLabel: Neural Networks\n\nPaper id: 2651\nTitle: Title: Relative Loss Bounds for Multidimensional Regression Problems  \nLabel: Theory\n\nPaper id: 930\nTitle: Title: BACKPROPAGATION CAN GIVE RISE TO SPURIOUS LOCAL MINIMA EVEN FOR NETWORKS WITHOUT HIDDEN LAYERS  \nLabel: Neural Networks\n\nPaper id: 1323\nTitle: Title: On the Distribution of Performance from Multiple Neural Network Trials, On the Distribution of Performance\nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1150\nTitle: Title: Lessons in Neural Network Training: Overfitting Lessons in Neural Network Training: Overfitting May be Harder\n\nPaper id: 805\nTitle: Title: Critical Points for Least-Squares Problems Involving Certain Analytic Functions, with Applications to Sigmoidal Nets  \nLabel: Neural Networks\n\nPaper id: 1145\nTitle: Title: A Unifying View of Some Training Algorithms for Multilayer Perceptrons with FIR Filter Synapses  \nLabel: Neural Networks\n\nPaper id: 2059\nTitle: Title: Challenges in Evolving Controllers for Physical Robots  \nLabel: Theory\n\nPaper id: 1464\nTitle: Title: LINEAR SYSTEMS WITH SIGN-OBSERVATIONS  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1687\nTitle: Title: Markov games as a framework for multi-agent reinforcement learning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1632\nTitle: Title: Learning Team Strategies With Multiple Policy-Sharing Agents: A Soccer Case Study  \nLabel: Reinforcement Learning\n\nPaper id: 1459\nTitle: Title: Generalized Markov Decision Processes: Dynamic-programming and Reinforcement-learning Algorithms  \nLabel: Reinforcement Learning\n\nPaper id: 54\nTitle: Title: A Competitive Approach to Game Learning  \nLabel: Theory\n\nPaper id: 1228\nTitle: Title: Team-Partitioned, Opaque-Transition Reinforcement Learning  \nLabel: Reinforcement Learning\n\nPaper id: 898\nTitle: Title: database  \nLabel: Probabilistic Methods\n\nPaper id: 523\nTitle: Title: Some studies in machine learning using the game of checkers. IBM Journal, 3(3):211-229, 1959. Some\nLabel: Genetic Algorithms\n\nPaper id: 148\nTitle: Title: Multiagent Reinforcement Learning: Theoretical Framework and an Algorithm  \nLabel: Reinforcement Learning\n\nPaper id: 1649\nTitle: Title: Multi-Agent Reinforcement Learning: Independent vs. Cooperative Agents  \n\nPaper id: 870\nTitle: Title: Learning to take risks  \n\nPaper id: 1189\nTitle: Title: Figure 3: Average model size accepted from a ran-dom prefix-closed samples of various size, and\nLabel: Theory\n\nPaper id: 1557\nTitle: Title: Using Communication to Reduce Locality in Distributed Multi-Agent Learning  \nLabel: Reinforcement Learning\n\nPaper id: 773\nTitle: Title: Reinforcement Learning with Imitation in Heterogeneous Multi-Agent Systems  \n\nPaper id: 1137\nTitle: Title: Learning Conventions in Multiagent Stochastic Domains using Likelihood Estimates  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2334\nTitle: Title: New Methods for Competitive Coevolution  \n\nPaper id: 2600\nTitle: Title: Evolution of Iteration in Genetic Programming D a v d A The solution to many\nLabel: Genetic Algorithms\n\nPaper id: 45\nTitle: Title: Acting under Uncertainty: Discrete Bayesian Models for Mobile-Robot Navigation  \nLabel: Reinforcement Learning\n\nPaper id: 1676\nTitle: Title: TD Learning of Game Evaluation Functions with Hierarchical Neural Architectures  \n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2608\nTitle: Title: Testing the Generalized Linear Model Null Hypothesis versus `Smooth' Alternatives 1  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2549\nTitle: Title: A Generalized Approximate Cross Validation for Smoothing Splines with Non-Gaussian Data 1  \nLabel: Neural Networks\n\nPaper id: 519\nTitle: Title: Smoothing Spline ANOVA for Exponential Families, with Application to the Wisconsin Epidemiological Study of Diabetic\nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 10\nTitle: Title: GRKPACK: FITTING SMOOTHING SPLINE ANOVA MODELS FOR EXPONENTIAL FAMILIES  \nLabel: Neural Networks\n\nPaper id: 510\nTitle: Title: The Bayesian Approach to Tree-Structured Regression  \n\nPaper id: 2448\nTitle: Title: Automatic Smoothing Spline Projection Pursuit  Automatic Smoothing Spline Projection Pursuit.  \nLabel: Neural Networks\n\nPaper id: 190\nTitle: Title: Spline Smoothing For Bivariate Data With Applications To Association Between Hormones  \n\nPaper id: 2223\nTitle: Title: Smoothing Spline Models With Correlated Random Errors 1  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 586\nTitle: Title: Neural Learning of Chaotic Dynamics: The Error Propagation Algorithm trains a neural network to identify\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 28\nTitle: Title: A Delay Damage Model Selection Algorithm for NARX Neural Networks  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 611\nTitle: Title: Learning networks for face analysis and synthesis  \nLabel: Neural Networks\n\nPaper id: 1606\nTitle: Title: Pruning Recurrent Neural Networks for Improved Generalization Performance  \nLabel: Neural Networks\n\nPaper id: 1718\nTitle: Title: PREDICTING SUNSPOTS AND EXCHANGE RATES WITH CONNECTIONIST NETWORKS  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1215\nTitle: Title: Supporting Combined Human and Machine Planning: An Interface for Planning by Analogical Reasoning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 824\nTitle: Title: Merge Strategies for Multiple Case Plan Replay  \nLabel: Case Based\n\nPaper id: 818\nTitle: Title: Learning to Integrate Multiple Knowledge Sources for Case-Based Reasoning  \nLabel: Case Based\n\nPaper id: 1209\nTitle: Title: S o l u t i o n Relevant A b s t r a\n\nPaper id: 580\nTitle: Title: Learning to Improve Case Adaptation by Introspective Reasoning and CBR  \n\nPaper id: 1707\nTitle: Title: Supporting Combined Human and Machine Planning: The Prodigy 4.0 User Interface Version 2.0*  \n\nPaper id: 819\nTitle: Title: A Case Study of Case-Based CBR  \nLabel: Case Based\n\nPaper id: 1699\nTitle: Title: On the Usefulness of Re-using Diagnostic Solutions  \nLabel: Case Based\n\nPaper id: 825\nTitle: Title: Towards Mixed-Initiative Rationale-Supported Planning  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1212\nTitle: Title: Acquiring Case Adaptation Knowledge: A Hybrid Approach  \n\nPaper id: 1621\nTitle: Title: Evaluating the Effectiveness of Derivation Replay in Partial-order vs State-space Planning  \nLabel: Case Based\n\nPaper id: 539\nTitle: Title: Structural Similarity as Guidance in Case-Based Design  \nLabel: Case Based\n\nPaper id: 799\nTitle: Title: A utility-based approach to learning in a mixed Case-Based and Model-Based Reasoning architecture  \nLabel: Case Based\n\nPaper id: 922\nTitle: Title: Towards Improving Case Adaptability with a Genetic Algorithm  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 116\nTitle: Title: Rate of Convergence of the Gibbs Sampler by Gaussian Approximation  SUMMARY  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 88\nTitle: Title: Hoeffding Races: Accelerating Model Selection Search for Classification and Function Approximation  \nLabel: Theory\n\nPaper id: 686\nTitle: Title: Prototype and Feature Selection by Sampling and Random Mutation Hill Climbing Algorithms  \nLabel: Case Based\n\nPaper id: 2428\nTitle: Title: Bumptrees for Efficient Function, Constraint, and Classification Learning  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 587\nTitle: Title: NONPARAMETRIC SELECTION OF INPUT VARIABLES FOR CONNECTIONIST LEARNING  \nLabel: Neural Networks\n\nPaper id: 119\nTitle: Title: Cost-sensitive feature reduction applied to a hybrid genetic algorithm  \n\nPaper id: 223\nTitle: Title: Automated model selection  \nLabel: Rule Learning\n\nPaper id: 1698\nTitle: Title: CBET: a Case Base Exploration Tool  \n\nPaper id: 1860\nTitle: Title: Efficient Locally Weighted Polynomial Regression Predictions  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 574\nTitle: Title: On the Learnability of Discrete Distributions (extended abstract)  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 672\nTitle: Title: Cryptographic Limitations on Learning Boolean Formulae and Finite Automata  \nLabel: Theory\n\nPaper id: 2475\nTitle: Title: Learning polynomials with queries: The highly noisy case  task for the case when F  \nLabel: Theory\n\nPaper id: 242\nTitle: Title: Learning Markov chains with variable memory length from noisy output  \nLabel: Theory\n\nPaper id: 2360\nTitle: Title: Efficient Learning of Typical Finite Automata from Random Walks (Extended Abstract)  \nLabel: Theory\n\nPaper id: 1827\nTitle: Title: Efficient Algorithms for Inverting Evolution  \n\nPaper id: 640\nTitle: Title: Learning in the Presence of Malicious Errors  \n\nPaper id: 549\nTitle: Title: Efficient Distribution-free Learning of Probabilistic Concepts  \nLabel: Theory\n\nPaper id: 1962\nTitle: Title: Learning Distributions from Random Walks  \nLabel: Theory\n\nPaper id: 1006\nTitle: Title: Learning Probabilistic Automata with Variable Memory Length  \nLabel: Theory\n\nPaper id: 2040\nTitle: Title: On the Learnability and Usage of Acyclic Probabilistic Finite Automata  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2246\nTitle: Title: Learning to model sequences generated by switching distributions  \nLabel: Theory\n\nPaper id: 1025\nTitle: Title: Machine Learning 27(1):51-68, 1997. Predicting nearly as well as the best pruning of a decision tree  \nLabel: Theory\n\nPaper id: 1293\nTitle: Title: Using Recurrent Neural Networks to Learn the Structure of Interconnection Networks  \nLabel: Neural Networks\n\nPaper id: 2224\nTitle: Title: Design of Optimization Criteria for Multiple Sequence Alignment  \n\nPaper id: 2083\nTitle: Title: TREE CONTRACTIONS AND EVOLUTIONARY TREES  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1841\nTitle: Title: Learning Without State-Estimation in Partially Observable Markovian Decision Processes  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1741\nTitle: Title: Reinforcement Learning Algorithm for Partially Observable Markov Decision Problems  \nLabel: Reinforcement Learning\n\nPaper id: 564\nTitle: Title: Reinforcement Learning with Soft State Aggregation  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 294\nTitle: Title: References elements that can solve difficult learning control problems. on Simulation of Adaptive Behavior, pages\nLabel: Reinforcement Learning\n\nPaper id: 463\nTitle: Title: A Cognitive Model of Learning to Navigate  \nLabel: Reinforcement Learning\n\nPaper id: 738\nTitle: Title: On the Convergence of Stochastic Iterative Dynamic Programming Algorithms  \nLabel: Reinforcement Learning\n\nPaper id: 492\nTitle: Title: Approximating Optimal Policies for Partially Observable Stochastic Domains  \n\nPaper id: 601\nTitle: Title: Active Gesture Recognition using Partially Observable Markov Decision Processes  \nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 412\nTitle: Title: The Influence of Domain Properties on the Performance of Real-Time Search Algorithms  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 688\nTitle: Title: Exploration and Model Building in Mobile Robot Domains  \nLabel: Reinforcement Learning\n\nPaper id: 552\nTitle: Title: Learning to Act using Real-Time Dynamic Programming  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 691\nTitle: Title: Reinforcement Learning in the Multi-Robot Domain  \nLabel: Reinforcement Learning\n\nPaper id: 472\nTitle: Title: Category: Control, Navigation and Planning. Key words: Reinforcement learning, Exploration, Hidden state. Prefer oral presentation.\nLabel: Reinforcement Learning\n\nPaper id: 473\nTitle: Title: Improving Policies without Measuring Merits  \nLabel: Reinforcement Learning\n\nPaper id: 1248\nTitle: Title: Lazy Acquisition of Place Knowledge  \nLabel: Case Based\n\nPaper id: 636\nTitle: Title: Robot Shaping: Developing Situated Agents through Learning  \nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2068\nTitle: Title: Rearrangement of receptive field topography after intracortical and peripheral stimulation: The role of plasticity in\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2228\nTitle: Title: Modeling dynamic receptive field changes in primary visual cortex using inhibitory learning  \nLabel: Neural Networks\n\nPaper id: 355\nTitle: Title: Generalization and Exclusive Allocation of Credit in Unsupervised Category Learning  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 127\nTitle: Title: Self-Organization and Functional Role of Lateral Connections and Multisize Receptive Fields in the Primary Visual Cortex  \n\nPaper id: 576\nTitle: Title: An information-maximisation approach to blind separation and blind deconvolution  \nLabel: Neural Networks\n\nPaper id: 1562\nTitle: Title: Using Sampling and Queries to Extract Rules from Trained Neural Networks  \nLabel: Neural Networks\n\nPaper id: 745\nTitle: Title: References \"Using Neural Networks to Identify Jets\", Kohonen, \"Self Organized Formation of Topologically Correct Feature\nLabel: Neural Networks\n\nPaper id: 1094\nTitle: Title: Plasticity in cortical neuron properties: Modeling the effects of an NMDA antagonist and a GABA\nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1722\nTitle: Title: BAYESIAN TIME SERIES: Models and Computations for the Analysis of Time Series in the Physical Sciences  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 99\nTitle: Title: Bayesian Forecasting of Multinomial Time Series through Conditionally Gaussian Dynamic Models  \nLabel: Probabilistic Methods\n\nPaper id: 1619\nTitle: Title: Exploratory Modelling of Multiple Non-Stationary Time Series: Latent Process Structure and Decompositions  \nLabel: Probabilistic Methods\n\nPaper id: 1723\nTitle: Title: Modelling and robustness issues in Bayesian time series analysis  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1852\nTitle: Title: On Sequential Simulation-Based Methods for Bayesian Filtering  \nLabel: Probabilistic Methods\n\nPaper id: 759\nTitle: Title: BAYESIAN STATISTICS 6, pp. 000--000  Exact sampling for Bayesian inference: towards general purpose algorithms  \nLabel: Probabilistic Methods\n\nPaper id: 1614\nTitle: Title: Bayesian Inference on Periodicities and Component Spectral Structure in Time Series  \nLabel: Probabilistic Methods\n\nPaper id: 2578\nTitle: Title: Analysis of hospital quality monitors using hierarchical time series models  \nLabel: Probabilistic Methods\n\nPaper id: 1613\nTitle: Title: Priors and Component Structures in Autoregressive Time Series Models  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1122\nTitle: Title: A Comparative Utility Analysis of Case-Based Reasoning and Control-Rule Learning Systems  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 594\nTitle: Title: Design and Implementation of a Replay Framework based on a Partial Order Planner  \nLabel: Case Based\n\nPaper id: 1534\nTitle: Title: The Use of Explicit Goals for Knowledge to Guide Inference and Learning  \n\nPaper id: 578\nTitle: Title: AN EMPIRICAL APPROACH TO SOLVING THE GENERAL UTILITY PROBLEM IN SPEEDUP LEARNING  \nLabel: Case Based\n\nPaper id: 799\nTitle: Title: A utility-based approach to learning in a mixed Case-Based and Model-Based Reasoning architecture  \nLabel: Case Based\n\nPaper id: 717\nTitle: Title: Information filtering: Selection mechanisms in learning systems. Machine Learning, 10:113-151, 1993. Generalization as search. Artificial\n\nPaper id: 1194\nTitle: Title: An Explanation-Based Approach to Improve Retrieval in Case-Based Planning  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 13\nTitle: Title: Unifying Empirical and Explanation-Based Learning by Modeling the Utility of Learned Knowledge  \nLabel: Case Based\n\nPaper id: 1597\nTitle: Title: an Opportunistic Enterprise  \n\nPaper id: 1163\nTitle: Title: Case-Based Planning to Learn  \nLabel: Case Based\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 1699\nTitle: Title: On the Usefulness of Re-using Diagnostic Solutions  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1324\nTitle: Title: [6] D. Geiger. Graphoids: a qualitative framework for probabilistic inference. An introduction to algorithms for\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1543\nTitle: Title: Belief Networks Revisited  \nLabel: Probabilistic Methods\n\nPaper id: 2076\nTitle: Title: Automated Discovery of Linear Feedback Models 1  \n\nPaper id: 260\nTitle: Title: ASPECTS OF GRAPHICAL MODELS CONNECTED WITH CAUSALITY  \nLabel: Probabilistic Methods\n\nPaper id: 1747\nTitle: Title: FROM BAYESIAN NETWORKS TO CAUSAL NETWORKS  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2166\nTitle: Title: Probabilistic evaluation of counterfactual queries  \nLabel: Probabilistic Methods\n\nPaper id: 619\nTitle: Title: MEDIATING INSTRUMENTAL VARIABLES  \nLabel: Probabilistic Methods\n\nPaper id: 2434\nTitle: Title: Causal Inference from Indirect Experiments  \nLabel: Probabilistic Methods\n\nPaper id: 2069\nTitle: Title: A Note on Testing Exogeneity of Instrumental Variables (DRAFT PAPER)  \nLabel: Probabilistic Methods\n\nPaper id: 211\nTitle: Title: Using Path Diagrams as a Structural Equation Modelling Tool  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1959\nTitle: Title: Evolution-based Discovery of Hierarchical Behaviors  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 120\nTitle: Title: Genetic Programming Exploratory Power and the Discovery of Functions  \nLabel: Genetic Algorithms\n\nPaper id: 177\nTitle: Title: Evaluation and Selection of Biases in Machine Learning  \nLabel: Theory\n\nPaper id: 2259\nTitle: Title: An Experimental Analysis of Schema Creation, Propagation and Disruption in Genetic Programming  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 911\nTitle: Title: Utilizing Prior Concepts for Learning  \nLabel: Theory\n\nPaper id: 2192\nTitle: Title: #1 Robust Feature Selection Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 188\nTitle: Title: Coevolving High-Level Representations  \nLabel: Genetic Algorithms\n\nPaper id: 1257\nTitle: Title: The Schema Theorem and Price's Theorem  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 502\nTitle: Title: Fast Online Q()  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n\nPaper id: 2536\nTitle: Title: Truncating Temporal Differences: On the Efficient Implementation of TD() for Reinforcement Learning  \nLabel: Reinforcement Learning\n\nPaper id: 567\nTitle: Title: Generalization in Reinforcement Learning: Successful Examples Using Sparse Coarse Coding  \nLabel: Reinforcement Learning\n\nPaper id: 294\nTitle: Title: References elements that can solve difficult learning control problems. on Simulation of Adaptive Behavior, pages\nLabel: Reinforcement Learning\n\nPaper id: 747\nTitle: Title: Cholinergic suppression of transmission may allow combined associative memory function and self-organization in the neocortex.  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2628\nTitle: Title: Generalizing in TD() learning  \nLabel: Reinforcement Learning\n\nPaper id: 700\nTitle: Title: Is Transfer Inductive?  \nLabel: Theory\n\nPaper id: 1378\nTitle: Title: Generalization in Reinforcement Learning: Safely Approximating the Value Function  \nLabel: Reinforcement Learning\n\nPaper id: 353\nTitle: Title: Application of Neural Networks for the Classification of Diffuse Liver Disease by Quantitative Echography  \nLabel: Neural Networks\n\nPaper id: 621\nTitle: Title: Reinforcement Learning Methods for Continuous-Time Markov Decision Problems  \nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 161\nTitle: Title: On Bayesian analysis of mixtures with an unknown number of components  Summary  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 95\nTitle: Title: Bayesian Detection of Clusters and Discontinuities in Disease Maps  \n\nPaper id: 684\nTitle: Title: Finding Overlapping Distributions with MML  \n\nPaper id: 1147\nTitle: Title: Decomposable graphical Gaussian model determination  \n\nPaper id: 713\nTitle: Title: FLEXIBLE PARAMETRIC MEASUREMENT ERROR MODELS  \n\nPaper id: 996\nTitle: Title: Reparameterisation Issues in Mixture Modelling and their bearing on MCMC algorithms  \n\nPaper id: 759\nTitle: Title: BAYESIAN STATISTICS 6, pp. 000--000  Exact sampling for Bayesian inference: towards general purpose algorithms  \nLabel: Probabilistic Methods\n\nPaper id: 2311\nTitle: Title: Bayesian MARS  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 23\nTitle: Title: Applications and extensions of MCMC in IRT: Multiple item types, missing data, and rated responses  \nLabel: Probabilistic Methods\n\nPaper id: 93\nTitle: Title: Blocking Gibbs Sampling for Linkage Analysis in Large Pedigrees with Many Loops  \nLabel: Probabilistic Methods\n\nPaper id: 779\nTitle: Title: Monte Carlo Comparison of Non-hierarchical Unsupervised Classifiers  \n\nPaper id: 358\nTitle: Title: Hierarchical Spatio-Temporal Mapping of Disease Rates  \nLabel: Probabilistic Methods\n\nPaper id: 292\nTitle: Title: An Approach to Diagnosing Total Variation Convergence of MCMC Algorithms  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1664\nTitle: Title: \"What is the best thing to do right now?\": getting beyond greedy exploration  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1697\nTitle: Title: Neural Network Exploration Using Optimal Experiment Design  \nLabel: Neural Networks\n\nPaper id: 740\nTitle: Title: Information-based objective functions for active data selection  \n\nPaper id: 804\nTitle: Title: Exploration Bonuses and Dual Control  \n\nPaper id: 1559\nTitle: Title: In  Active Learning with Statistical Models  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1459\nTitle: Title: Generalized Markov Decision Processes: Dynamic-programming and Reinforcement-learning Algorithms  \nLabel: Reinforcement Learning\n\nPaper id: 164\nTitle: Title: Improving Generalization with Active Learning  \nLabel: Theory\n\nPaper id: 1585\nTitle: Title: Q-Learning for Bandit Problems  \n\nPaper id: 1599\nTitle: Title: Finding Promising Exploration Regions by Weighting Expected Navigation Costs continuous environments, some first-order approximations to\nLabel: Reinforcement Learning\n\nPaper id: 1667\nTitle: Title: Advances in Neural Information Processing Systems 8 Active Learning in Multilayer Perceptrons  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1409\nTitle: Title: Evolution of Mapmaking: Learning, planning, and memory using Genetic Programming  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 129\nTitle: Title: Evolving Networks: Using the Genetic Algorithm with Connectionist Learning  \nLabel: Genetic Algorithms\n\nPaper id: 789\nTitle: Title: Stochastic Random or probabilistic but with some direction. For example the arrival of people at\nLabel: Genetic Algorithms\n\nPaper id: 2600\nTitle: Title: Evolution of Iteration in Genetic Programming D a v d A The solution to many\nLabel: Genetic Algorithms\n\nPaper id: 958\nTitle: Title: The Evolution of Memory and Mental Models Using Genetic Programming build internal representations of their\nLabel: Genetic Algorithms\n\nPaper id: 2220\nTitle: Title: The Automatic Programming of Agents that Learn Mental Models and Create Simple Plans of Action  \nLabel: Genetic Algorithms\n\nPaper id: 1797\nTitle: Title: Improving the Performance of Evolutionary Optimization by Dynamically Scaling the Evaluation Function  \nLabel: Genetic Algorithms\n\nPaper id: 2703\nTitle: Title: learning easier tasks. More work is necessary in order to determine more precisely the relationship\nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1206\nTitle: Title: Learning Monitoring Strategies: A Difficult Genetic Programming Application  \nLabel: Genetic Algorithms\n\nPaper id: 2478\nTitle: Title: Culture Enhances the Evolvability of Cognition  \nLabel: Genetic Algorithms\n\nPaper id: 1204\nTitle: Title: The Role of Development in Genetic Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 2252\nTitle: Title: Neural Programming and an Internal Reinforcement Policy  \nLabel: Genetic Algorithms\n\nPaper id: 15\nTitle: Title: Back Propagation is Sensitive to Initial Conditions  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1661\nTitle: Title: Simulating Access to Hidden Information while Learning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 453\nTitle: Title: How to Use Expert Advice (Extended Abstract)  \nLabel: Theory\n\nPaper id: 1469\nTitle: Title: Warning: missing six few referencesfixed in proceedings. Learning with Queries but Incomplete Information (Extended Abstract)  \nLabel: Theory\n\nPaper id: 791\nTitle: Title: Asking Questions to Minimize Errors  \n\nPaper id: 109\nTitle: Title: A General Lower Bound on the Number of Examples Needed for Learning  \nLabel: Theory\n\nPaper id: 1358\nTitle: Title: On the Complexity of Function Learning  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1449\nTitle: Title: Adaptive Mixtures of Probabilistic Transducers  \nLabel: Theory\n\nPaper id: 2098\nTitle: Title: Predicting a binary sequence almost as well as the optimal biased coin  \nLabel: Theory\n\nPaper id: 1364\nTitle: Title: Learning k-term DNF Formulas with an Incomplete Membership Oracle  \nLabel: Theory\n\nPaper id: 2315\nTitle: Title: Metric Entropy and Minimax Risk in Classification  \nLabel: Theory\n\nPaper id: 1269\nTitle: Title: Context-sensitive learning methods for text categorization  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1758\nTitle: Title: Simultaneous Learning of Control Laws and Local Environment Representations for Intelligent Navigation Robots  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2412\nTitle: Title: On-Line Adaptation of a Signal Predistorter through Dual Reinforcement Learning  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2255\nTitle: Title: Evolutionary Learning of the Crossover Operator  \n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2489\nTitle: Title: BECOMING AN EXPERT CASE-BASED REASONER: LEARNING TO ADAPT PRIOR CASES  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1126\nTitle: Title: Towards A Computer Model of Memory Search Strategy Learning  \n\nPaper id: 2372\nTitle: Title: Goal-Driven Learning: Fundamental Issues (A Symposium Report)  \nLabel: Case Based\n\nPaper id: 643\nTitle: Title: Modeling Case-based Planning for Repairing Reasoning Failures  \nLabel: Case Based\n\nPaper id: 2371\nTitle: Title: Learning Adaptation Strategies by Introspective Reasoning about Memory Search  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1121\nTitle: Title: Generic Teleological Mechanisms and their Use in Case Adaptation  \nLabel: Case Based\n\nPaper id: 580\nTitle: Title: Learning to Improve Case Adaptation by Introspective Reasoning and CBR  \n\nPaper id: 1904\nTitle: Title: Using Case-Based Reasoning for Mobile Robot Navigation  \nLabel: Case Based\n\nPaper id: 222\nTitle: Title: Abstract  \nLabel: Case Based\n\nPaper id: 50\nTitle: Title: Abstract  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 837\nTitle: Title: Inductive Database Design  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1007\nTitle: Title: Applications of a logical discovery engine  \nLabel: Rule Learning\n\nPaper id: 1489\nTitle: Title: Dlab: A Declarative Language Bias Formalism  \nLabel: Rule Learning\n\nPaper id: 1686\nTitle: Title: Learning with Abduction  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2217\nTitle: Title: Application of Clausal Discovery to Temporal Databases  \nLabel: Rule Learning\n\nPaper id: 344\nTitle: Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In\nLabel: Rule Learning\n\nPaper id: 2426\nTitle: Title: Inductive Constraint Logic  \nLabel: Rule Learning\n\nPaper id: 177\nTitle: Title: Evaluation and Selection of Biases in Machine Learning  \nLabel: Theory\n\nPaper id: 2282\nTitle: Title: The ILP description learning problem: Towards a general model-level definition of data mining in ILP  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2655\nTitle: Title: Associative Reinforcement Learning: A Generate and Test Algorithm  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1975\nTitle: Title: Associative Reinforcement Learning: Functions in k-DNF  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n\nPaper id: 2689\nTitle: Title: Expected Mistake Bound Model for On-Line Reinforcement Learning  \nLabel: Theory\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n\nPaper id: 2408\nTitle: Title: Exploratory Learning in the Game of GO  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 703\nTitle: Title: VECTOR ASSOCIATIVE MAPS: UNSUPERVISED REAL-TIME ERROR-BASED LEARNING AND CONTROL OF MOVEMENT TRAJECTORIES  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2233\nTitle: Title: An unsupervised neural network for low-level control of a wheeled mobile robot: noise resistance, stability,\n\nPaper id: 747\nTitle: Title: Cholinergic suppression of transmission may allow combined associative memory function and self-organization in the neocortex.  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 73\nTitle: Title: LEARNING TO GENERATE ARTIFICIAL FOVEA TRAJECTORIES FOR TARGET DETECTION  \nLabel: Reinforcement Learning\n\nPaper id: 695\nTitle: Title: There is No Free Lunch but the Starter is Cheap: Generalisation from First Principles  \nLabel: Theory\n\nPaper id: 113\nTitle: Title: LU TP  Pattern Discrimination Using Feed-Forward Networks a Benchmark Study of Scaling Behaviour  \nLabel: Neural Networks\n\nPaper id: 18\nTitle: Title: Topography And Ocular Dominance: A Model Exploring Positive Correlations  \nLabel: Neural Networks\n\nPaper id: 362\nTitle: Title: Learning Topology-Preserving Maps Using Self-Supervised Backpropagation  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 795\nTitle: Title: Learning Hierarchical Rule Sets  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 865\nTitle: Title: ON THE SAMPLE COMPLEXITY OF FINDING GOOD SEARCH STRATEGIES 2n trials of each undetermined experiment\nLabel: Theory\n\nPaper id: 794\nTitle: Title: Learning rules with local exceptions  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 932\nTitle: Title: Learning an Optimally Accurate Representational System  \nLabel: Theory\n\nPaper id: 1505\nTitle: Title: Probably Approximately Optimal Derivation Strategies  \nLabel: Theory\n\nPaper id: 251\nTitle: Title: A Statistical Approach to Solving the EBL Utility Problem  \nLabel: Theory\n\nPaper id: 2560\nTitle: Title: Learning Default Concepts  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 646\nTitle: Title: Constructing Computationally Efficient Bayesian Models via Unsupervised Clustering  Probabilistic Reasoning and Bayesian Belief Networks,  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 450\nTitle: Title: Mapping Bayesian Networks to Boltzmann Machines  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 954\nTitle: Title: Unsupervised learning of distributions on binary vectors using two layer networks  \n\nPaper id: 2558\nTitle: Title: Using Bayesian networks for incorporating probabilistic a priori knowledge into Boltzmann machines  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 896\nTitle: Title: Discretization of continuous Markov chains and MCMC convergence assessment  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 468\nTitle: Title: Adaptive Markov Chain Monte Carlo through Regeneration  Summary  \nLabel: Probabilistic Methods\n\nPaper id: 888\nTitle: Title: Looking at Markov Samplers through Cusum Path Plots: a simple diagnostic idea  \nLabel: Probabilistic Methods\n\nPaper id: 1372\nTitle: Title: MCMC CONVERGENCE DIAGNOSTIC VIA THE CENTRAL LIMIT THEOREM  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 904\nTitle: Title: Assessing Convergence of Markov Chain Monte Carlo Algorithms  \nLabel: Probabilistic Methods\n\nPaper id: 182\nTitle: Title: Adaptation for Self Regenerative MCMC  SUMMARY  \nLabel: Probabilistic Methods\n\nPaper id: 41\nTitle: Title: Markov Chain Monte Carlo Convergence Diagnostics: A Comparative Review  \nLabel: Probabilistic Methods\n\nPaper id: 491\nTitle: Title: Self Regenerative Markov Chain Monte Carlo  Summary  \nLabel: Probabilistic Methods\n\nPaper id: 1713\nTitle: Title: A simulation approach to convergence rates for Markov chain Monte Carlo algorithms  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1390\nTitle: Title: Learning Finite Automata Using Local Distinguishing Experiments  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1491\nTitle: Title: Discovery as Autonomous Learning from the Environment  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 851\nTitle: Title: Bayesian Probability Theory A General Method for Machine Learning  \n\nPaper id: 903\nTitle: Title: Learning Concepts from Sensor Data of a Mobile Robot  \nLabel: Theory\n\nPaper id: 1605\nTitle: Title: Learning from the Environment by Experimentation: The Need for Few and Informative Examples  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 954\nTitle: Title: Unsupervised learning of distributions on binary vectors using two layer networks  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 450\nTitle: Title: Mapping Bayesian Networks to Boltzmann Machines  \nLabel: Probabilistic Methods\n\nPaper id: 1591\nTitle: Title: Unsupervised Learning by Convex and Conic Coding  \nLabel: Neural Networks\n\nPaper id: 969\nTitle: Title: Learning Stochastic Feedforward Networks  \nLabel: Probabilistic Methods\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n\nPaper id: 1461\nTitle: Title: Learning in Boltzmann Trees  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 201\nTitle: Title: Neural net architectures for temporal sequence processing  \n\nPaper id: 1037\nTitle: Title: OBSERVABILITY IN RECURRENT NEURAL NETWORKS  \nLabel: Neural Networks\n\nPaper id: 312\nTitle: Title: Chain graphs for learning  \nLabel: Probabilistic Methods\n\nPaper id: 18\nTitle: Title: Topography And Ocular Dominance: A Model Exploring Positive Correlations  \nLabel: Neural Networks\n\nPaper id: 1399\nTitle: Title: Parametric regression 1.1 Learning problem model f bw b w in turn is an estimator\nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2572\nTitle: Title: Negative observations concerning approximations from spaces generated by scattered shifts of functions vanishing at 1  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2112\nTitle: Title: Approximation from shift-invariant subspaces of L  \nLabel: Neural Networks\n\nPaper id: 365\nTitle: Title: Radial basis function approximation: from gridded centers to scattered centers  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 590\nTitle: Title: APPROXIMATION IN L p (R d FROM SPACES SPANNED BY THE PERTURBED INTEGER TRANSLATES OF\nLabel: Neural Networks\n\nPaper id: 364\nTitle: Title: Radial Basis Functions: L p -approximation orders with scattered centres  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 860\nTitle: Title: A Study in Program Response and the Negative Effects of Introns in Genetic Programming  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1184\nTitle: Title: Causality in Genetic Programming  \n\nPaper id: 1940\nTitle: Title: A Comparison of Crossover and Mutation in Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 934\nTitle: Title: Complexity Compression and Evolution  \nLabel: Genetic Algorithms\n\nPaper id: 1911\nTitle: Title: Genetic Programming and Data Structures  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 120\nTitle: Title: Genetic Programming Exploratory Power and the Discovery of Functions  \nLabel: Genetic Algorithms\n\nPaper id: 1784\nTitle: Title: Genetic Programming and Redundancy  \nLabel: Genetic Algorithms\n\nPaper id: 1098\nTitle: Title: Scheduling Maintenance of Electrical Power Transmission Networks Using Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 141\nTitle: Title: Hierarchical Self-Organization in Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 2175\nTitle: Title: The Troubling Aspects of a Building Block Hypothesis for Genetic Programming  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2368\nTitle: Title: Reinforcement Learning with Modular Neural Networks for Control  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 85\nTitle: Title: Q-Learning with Hidden-Unit Restarting  \nLabel: Reinforcement Learning\n\nPaper id: 465\nTitle: Title: Strategy Learning with Multilayer Connectionist Representations 1  \nLabel: Reinforcement Learning\n\nPaper id: 2642\nTitle: Title: Learning to Play Games From Experience: An Application of Artificial Neural Networks and Temporal Difference Learning  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 103\nTitle: Title: NEUROCONTROL BY REINFORCEMENT LEARNING  \n\nPaper id: 118\nTitle: Title: Learning to Race: Experiments with a Simulated Race Car  \nLabel: Reinforcement Learning\n\nPaper id: 523\nTitle: Title: Some studies in machine learning using the game of checkers. IBM Journal, 3(3):211-229, 1959. Some\nLabel: Genetic Algorithms\n\nPaper id: 425\nTitle: Title: Reinforcement Learning, Neural Networks and PI Control Applied to a Heating Coil  \nLabel: Reinforcement Learning\n\nPaper id: 2672\nTitle: Title: REINFORCEMENT LEARNING FOR COORDINATED REACTIVE CONTROL  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 397\nTitle: Title: Truth-from-Trash Learning and the Mobot  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 747\nTitle: Title: Cholinergic suppression of transmission may allow combined associative memory function and self-organization in the neocortex.  \n\nPaper id: 2346\nTitle: Title: Parity: The Problem that Won't Go Away  \nLabel: Theory\n\nPaper id: 659\nTitle: Title: Trading Spaces: Computation, Representation and the Limits of Uninformed Learning  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 310\nTitle: Title: Forecasting electricity demand using nonlinear mixture of experts  \nLabel: Neural Networks\n\nPaper id: 11\nTitle: Title: Simple Genetic Programming for Supervised Learning Problems  \n\nPaper id: 204\nTitle: Title: Natural Language Processing with Subsymbolic Neural Networks  \nLabel: Neural Networks\n\nPaper id: 315\nTitle: Title: Cortical Functionality Emergence:  Self-Organization of Complex Structures: From Individual to Collective Dynamics,  \nLabel: Neural Networks\n\nPaper id: 186\nTitle: Title: Adaptive state space quantisation: adding and removing neurons  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 773\nTitle: Title: Reinforcement Learning with Imitation in Heterogeneous Multi-Agent Systems  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 656\nTitle: Title: Reinforcement Learning: A Survey  \n\nPaper id: 1687\nTitle: Title: Markov games as a framework for multi-agent reinforcement learning  \n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n\nPaper id: 1643\nTitle: Title: Learning to coordinate without sharing information  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 644\nTitle: Title: Multi-criteria reinforcement learning  \nLabel: Reinforcement Learning\n\nPaper id: 385\nTitle: Title: Modeling the Student with Reinforcement Learning  \nLabel: Reinforcement Learning\n\nPaper id: 1189\nTitle: Title: Figure 3: Average model size accepted from a ran-dom prefix-closed samples of various size, and\nLabel: Theory\n\nPaper id: 1632\nTitle: Title: Learning Team Strategies With Multiple Policy-Sharing Agents: A Soccer Case Study  \nLabel: Reinforcement Learning\n\nPaper id: 2\nTitle: Title: Submitted to NIPS96, Section: Applications. Preference: Oral presentation Reinforcement Learning for Dynamic Channel Allocation in\nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 469\nTitle: Title: Interpolation Models with Multiple  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 78\nTitle: Title: Probabilistic Networks: New Models and New Methods  \nLabel: Theory\n\nPaper id: 160\nTitle: Title: EVALUATION OF GAUSSIAN PROCESSES AND OTHER METHODS FOR NON-LINEAR REGRESSION  \n\nPaper id: 214\nTitle: Title: Bayesian Non-linear Modelling for the Prediction Competition  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 766\nTitle: Title: Keeping Neural Networks Simple by Minimizing the Description Length of the Weights  \n\nPaper id: 125\nTitle: Title: Gaussian Processes for Bayesian Classification via Hybrid Monte Carlo  \nLabel: Neural Networks\n\nPaper id: 560\nTitle: Title: Bayesian Methods for Adaptive Models  \nLabel: Theory\n\nPaper id: 1857\nTitle: Title: Monte Carlo Implementation of Gaussian Process Models for Bayesian Regression and Classification  \nLabel: Probabilistic Methods\n\nPaper id: 322\nTitle: Title: Statistical Tests for Comparing Supervised Classification Learning Algorithms  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1796\nTitle: Title: Evaluating and Improving Steady State Evolutionary Algorithms on Constraint Satisfaction Problems  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1030\nTitle: Title: Solving Combinatorial Problems Using Evolutionary Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 2001\nTitle: Title: Comparison of the SAW-ing Evolutionary Algorithm and the Grouping Genetic Algorithm for Graph Coloring 1  \nLabel: Genetic Algorithms\n\nPaper id: 833\nTitle: Title: Graph Coloring with Adaptive Evolutionary Algorithms  \n\nPaper id: 1917\nTitle: Title: Go and Genetic Programming Playing Go with Filter Functions  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 714\nTitle: Title: Orgy in the Computer: Multi-Parent Reproduction in Genetic Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 1946\nTitle: Title: Plateaus and Plateau Search in Boolean Satisfiability Problems: When to Give Up Searching and Start Again  \nLabel: Genetic Algorithms\n\nPaper id: 1136\nTitle: Title: Using Neural Networks and Genetic Algorithms as Heuristics for NP-Complete Problems  \n\nPaper id: 1516\nTitle: Title: Solving 3-SAT by GAs Adapting Constraint Weights  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 766\nTitle: Title: Keeping Neural Networks Simple by Minimizing the Description Length of the Weights  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 78\nTitle: Title: Probabilistic Networks: New Models and New Methods  \nLabel: Theory\n\nPaper id: 157\nTitle: Title: A Practical Bayesian Framework for Backprop Networks  \nLabel: Theory\n\nPaper id: 2532\nTitle: Title: Ensemble Learning for Hidden Markov Models  \n\nPaper id: 181\nTitle: Title: Ensemble Learning and Evidence Maximization  \nLabel: Theory\n\nPaper id: 979\nTitle: Title: FLAT MINIMA Neural Computation 9(1):1-42 (1997)  \nLabel: Neural Networks\n\nPaper id: 518\nTitle: Title: Developments in Probabilistic Modelling with Neural Networks|Ensemble Learning  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2680\nTitle: Title: Least Absolute Shrinkage is Equivalent to Quadratic Penalization  \nLabel: Neural Networks\n\nPaper id: 1075\nTitle: Title: Bayesian Learning in Feed Forward Neural Networks  \nLabel: Neural Networks\n\nPaper id: 2021\nTitle: Title: Best-First Model Merging for Dynamic Learning and Recognition  \nLabel: Neural Networks\n\nPaper id: 1340\nTitle: Title: ADAPTIVE REGULARIZATION  \nLabel: Neural Networks\n\nPaper id: 716\nTitle: Title: Covariate Selection in Hierarchical Models of Hospital Admission Counts: A Bayes Factor Approach 1  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1568\nTitle: Title: The Utility of Feature Weighting in Nearest-Neighbor Algorithms  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 430\nTitle: Title: Irrelevant Features and the Subset Selection Problem  \nLabel: Theory\n\nPaper id: 1053\nTitle: Title: Bias Plus Variance Decomposition for Zero-One Loss Functions  \nLabel: Theory\n\nPaper id: 1328\nTitle: Title: A Weighted Nearest Neighbor Algorithm for Learning with Symbolic Features  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1111\nTitle: Title: Towards a Better Understanding of Memory-Based Reasoning Systems  \nLabel: Case Based\n\nPaper id: 1207\nTitle: Title: Data Analyses Using Simulated Breeding and Inductive Learning Methods  \nLabel: Genetic Algorithms\n\nPaper id: 119\nTitle: Title: Cost-sensitive feature reduction applied to a hybrid genetic algorithm  \n\nPaper id: 1637\nTitle: Title: The Effective Size of a Neural Network: A Principal Component Approach  \nLabel: Neural Networks\n\nPaper id: 1513\nTitle: Title: Fast NP Chunking Using Memory-Based Learning Techniques  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 537\nTitle: Title: Adaptive Global Optimization with Local Search  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 606\nTitle: Title: Analysis of the Numerical Effects of Parallelism on a Parallel Genetic Algorithm  \n\nPaper id: 1204\nTitle: Title: The Role of Development in Genetic Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 357\nTitle: Title: Genetic Algorithms as Multi-Coordinators in Large-Scale Optimization  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1563\nTitle: Title: Fast EquiPartitioning of Rectangular Domains using Stripe Decomposition  \nLabel: Genetic Algorithms\n\nPaper id: 538\nTitle: Title: Learning and evolution in neural networks  \nLabel: Genetic Algorithms\n\nPaper id: 2089\nTitle: Title: A Cooperative Coevolutionary Approach to Function Optimization  \nLabel: Genetic Algorithms\n\nPaper id: 2624\nTitle: Title: A Comparison between Cellular Encoding and Direct Encoding for Genetic Neural Networks  \nLabel: Genetic Algorithms\n\nPaper id: 1153\nTitle: Title: Evolution in Time and Space The Parallel Genetic Algorithm  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 830\nTitle: Title: Orthogonal incremental learning of a feedforward network  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1252\nTitle: Title: Constructive Training Methods for Feedforward Neural Networks with Binary Weights  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1634\nTitle: Title: Combining Linear Discriminant Functions with Neural Networks for Supervised Learning  \n\nPaper id: 829\nTitle: Title: Approximation with neural networks: Between local and global approximation  \nLabel: Neural Networks\n\nPaper id: 1477\nTitle: Title: Two Constructive Methods for Designing Compact Feedforward Networks of Threshold Units  \nLabel: Neural Networks\n\nPaper id: 820\nTitle: Title: NESTED NETWORKS FOR ROBOT CONTROL  \nLabel: Neural Networks\n\nPaper id: 1485\nTitle: Title: Maximizing the Robustness of a Linear Threshold Classifier with Discrete Weights  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2573\nTitle: Title: An Optimum Decision Rule for Pattern Recognition  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1942\nTitle: Title: On Functional Relation between Recognition Error and Class-Selective Reject  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 769\nTitle: Title: On the Relations Between Search and Evolutionary Algorithms  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 764\nTitle: Title: GENETIC AND NON GENETIC OPERATORS IN ALECSYS  \nLabel: Genetic Algorithms\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2557\nTitle: Title: Growing Simpler Decision Trees to Facilitate Knowledge Discovery  \nLabel: Neural Networks\n\nPaper id: 793\nTitle: Title: A Survey of Evolution Strategies  \nLabel: Genetic Algorithms\n\nPaper id: 1380\nTitle: Title: Evaluating Evolutionary Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 1106\nTitle: Title: Genetic Algorithms for Combinatorial Optimization: The Assembly Line Balancing Problem  \nLabel: Genetic Algorithms\n\nPaper id: 1696\nTitle: Title: The Royal Road for Genetic Algorithms: Fitness Landscapes and GA Performance  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2038\nTitle: Title: Knowledge Based Systems  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2692\nTitle: Title: Multi-Strategy Learning and Theory Revision  \nLabel: Case Based\n\nPaper id: 985\nTitle: Title: Combining Symbolic and Connectionist Learning Methods to Refine Certainty-Factor Rule-Bases  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1102\nTitle: Title: Automated Refinement of First-Order Horn-Clause Domain Theories  \nLabel: Rule Learning\n\nPaper id: 2172\nTitle: Title: Tractability of Theory Patching  \nLabel: Theory\n\nPaper id: 1370\nTitle: Title: From Theory Refinement to KB Maintenance: a Position Statement  \nLabel: Rule Learning\n\nPaper id: 159\nTitle: Title: Bias-Driven Revision of Logical Domain Theories  \nLabel: Theory\n\nPaper id: 2066\nTitle: Title: On the Informativeness of the DNA Promoter Sequences Domain Theory  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1534\nTitle: Title: The Use of Explicit Goals for Knowledge to Guide Inference and Learning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1122\nTitle: Title: A Comparative Utility Analysis of Case-Based Reasoning and Control-Rule Learning Systems  \n\nPaper id: 1498\nTitle: Title: INFERENTIAL THEORY OF LEARNING: Developing Foundations for Multistrategy Learning  \nLabel: Case Based\n\nPaper id: 289\nTitle: Title: A theory of questions and question asking  \nLabel: Case Based\n\nPaper id: 1597\nTitle: Title: an Opportunistic Enterprise  \n\nPaper id: 1148\nTitle: Title: Opportunistic Reasoning: A Design Perspective  \n\nPaper id: 1278\nTitle: Title: A Functional Theory of Creative Reading  \nLabel: Case Based\n\nPaper id: 1163\nTitle: Title: Case-Based Planning to Learn  \nLabel: Case Based\n\nPaper id: 1556\nTitle: Title: A Goal-Based Approach to Intelligent Information Retrieval  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1138\nTitle: Title: Learning Generic Mechanisms from Experiences for Analogical Reasoning  \nLabel: Case Based\n\nPaper id: 1194\nTitle: Title: An Explanation-Based Approach to Improve Retrieval in Case-Based Planning  \nLabel: Case Based\n\nPaper id: 2568\nTitle: Title: Abstract  \n\nPaper id: 1355\nTitle: Title: Modeling Invention by Analogy in ACT-R  \nLabel: Case Based\n\nPaper id: 594\nTitle: Title: Design and Implementation of a Replay Framework based on a Partial Order Planner  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 546\nTitle: Title: GREQE a Diplome des Etudes Approfondies en Economie Mathematique et Econometrie A Genetic Algorithm for\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1257\nTitle: Title: The Schema Theorem and Price's Theorem  \n\nPaper id: 380\nTitle: Title: Fitness Landscapes and Difficulty in Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 1136\nTitle: Title: Using Neural Networks and Genetic Algorithms as Heuristics for NP-Complete Problems  \n\nPaper id: 1728\nTitle: Title: Dynamic Parameter Encoding for Genetic Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 1225\nTitle: Title: Knowledge-Based Genetic Learning  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 335\nTitle: Title: Incremental Reduced Error Pruning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 378\nTitle: Title: Mingers, 1989 J. Mingers. An empirical comparison of pruning methods for decision tree induction. Machine\n\nPaper id: 585\nTitle: Title: An investigation of noise-tolerant relational concept learning algorithms  \nLabel: Rule Learning\n\nPaper id: 344\nTitle: Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In\nLabel: Rule Learning\n\nPaper id: 426\nTitle: Title: Rule Induction with CN2: Some Recent Improvements  \nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 227\nTitle: Title: Induction of Oblique Decision Trees  \nLabel: Theory\n\nPaper id: 2589\nTitle: Title: Pac-Learning Recursive Logic Programs: Efficient Algorithms  \nLabel: Rule Learning\n\nPaper id: 963\nTitle: Title: Cooperation of Data-driven and Model-based Induction Methods for Relational Learning  \nLabel: Rule Learning\n\nPaper id: 1\nTitle: Title: Applications of machine learning: a medical follow up study  \n\nPaper id: 1275\nTitle: Title: Fossil: A Robust Relational Learner  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 854\nTitle: Title: A Comparison of Random Search versus Genetic Programming as Engines for Collective Adaptation  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1178\nTitle: Title: Strongly Typed Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 2598\nTitle: Title: Duplication of Coding Segments in Genetic Programming  \n\nPaper id: 2211\nTitle: Title: Collective Memory Search 1 Collective Memory Search: Exploiting an Information Center for Exploration  \nLabel: Genetic Algorithms\n\nPaper id: 1231\nTitle: Title: Type Inheritance in Strongly Typed Genetic Programming  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2330\nTitle: Title: A comparison of the fixed and floating building block representation in the genetic algorithm  \nLabel: Genetic Algorithms\n\nPaper id: 1631\nTitle: Title: A Survey of Intron Research in Genetics  \n\nPaper id: 1362\nTitle: Title: Towards Automatic Discovery of Building Blocks in Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 1690\nTitle: Title: Evolving Behavioral Strategies in Predators and Prey  \nLabel: Genetic Algorithms\n\nPaper id: 1495\nTitle: Title: Clique Detection via Genetic Programming  Topics in Combinatorial Optimization  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1300\nTitle: Title: Tempering Backpropagation Networks: Not All Weights are Created Equal approach yields hitherto unparalleled performance on\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1342\nTitle: Title: Centering Neural Network Gradient Factors  \nLabel: Neural Networks\n\nPaper id: 1320\nTitle: Title: On Centering Neural Network Weight Updates  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 808\nTitle: Title: Unsupervised Discrimination of Clustered Data via Optimization of Binary Information Gain  \nLabel: Neural Networks\n\nPaper id: 2454\nTitle: Title: Early Stopping but when?  \n\nPaper id: 359\nTitle: Title: Feature Extraction Using an Unsupervised Neural Network  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 833\nTitle: Title: Graph Coloring with Adaptive Evolutionary Algorithms  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1218\nTitle: Title: Genetic algorithms with multi-parent recombination  \n\nPaper id: 2001\nTitle: Title: Comparison of the SAW-ing Evolutionary Algorithm and the Grouping Genetic Algorithm for Graph Coloring 1  \nLabel: Genetic Algorithms\n\nPaper id: 1516\nTitle: Title: Solving 3-SAT by GAs Adapting Constraint Weights  \n\nPaper id: 714\nTitle: Title: Orgy in the Computer: Multi-Parent Reproduction in Genetic Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 1796\nTitle: Title: Evaluating and Improving Steady State Evolutionary Algorithms on Constraint Satisfaction Problems  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1917\nTitle: Title: Go and Genetic Programming Playing Go with Filter Functions  \nLabel: Genetic Algorithms\n\nPaper id: 1670\nTitle: Title: Raising GA Performance by Simultaneous Tuning of Selective Pressure and Recombination Disruptiveness  \nLabel: Genetic Algorithms\n\nPaper id: 145\nTitle: Title: LIBGA: A USER-FRIENDLY WORKBENCH FOR ORDER-BASED GENETIC ALGORITHM RESEARCH  \nLabel: Genetic Algorithms\n\nPaper id: 1571\nTitle: Title: Average-Case Analysis of a Nearest Neighbor Algorithm  \n\nPaper id: 1424\nTitle: Title: Multi-parent's niche: n-ary crossovers on NK-landscapes  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2317\nTitle: Title: Cellular Encoding Applied to Neurocontrol  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1353\nTitle: Title: Culling Teaching -1 Culling and Teaching in Neuro-evolution  \nLabel: Genetic Algorithms\n\nPaper id: 2429\nTitle: Title: Automatic Definition of Modular Neural Networks  \nLabel: Genetic Algorithms\n\nPaper id: 2624\nTitle: Title: A Comparison between Cellular Encoding and Direct Encoding for Genetic Neural Networks  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2702\nTitle: Title: An Evolutionary Method to Find Good Building-Blocks for Architectures of Artificial Neural Networks  \nLabel: Genetic Algorithms\n\nPaper id: 2302\nTitle: Title: Genes, Phenes and the Baldwin Effect: Learning and Evolution in a Simulated Population  \nLabel: Genetic Algorithms\n\nPaper id: 294\nTitle: Title: References elements that can solve difficult learning control problems. on Simulation of Adaptive Behavior, pages\nLabel: Reinforcement Learning\n\nPaper id: 2281\nTitle: Title: GENE REGULATION AND BIOLOGICAL DEVELOPMENT IN NEURAL NETWORKS: AN EXPLORATORY MODEL  \n\nPaper id: 1931\nTitle: Title: AUTOMATED TOPOLOGY AND SIZING OF ANALOG CIRCUITS AUTOMATED DESIGN OF BOTH THE TOPOLOGY AND SIZING\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2570\nTitle: Title: In  Fast Non-Linear Dimension Reduction  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 667\nTitle: Title: Recognizing Handwritten Digits Using Mixtures of Linear Models  \nLabel: Neural Networks\n\nPaper id: 1928\nTitle: Title: Mixtures of Probabilistic Principal Component Analysers  \nLabel: Neural Networks\n\nPaper id: 480\nTitle: Title: Modelling the Manifolds of Images of Handwritten Digits  \nLabel: Neural Networks\n\nPaper id: 1806\nTitle: Title: MBP on T0: mixing floating- and fixed-point formats in BP learning  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2279\nTitle: Title: Quicknet on MultiSpert: Fast Parallel Neural Network Training  \nLabel: Neural Networks\n\nPaper id: 2114\nTitle: Title: Probabilistic Principal Component Analysis  \nLabel: Probabilistic Methods\n\nPaper id: 2072\nTitle: Title: Data Mining for Association Rules with Unsupervised Neural Networks  \nLabel: Neural Networks\n\nPaper id: 867\nTitle: Title: Comparison of Neural and Statistical Classifiers| Theory and Practice  \nLabel: Neural Networks\n\nPaper id: 2124\nTitle: Title: A Hierarchical Latent Variable Model for Data Visualization  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1693\nTitle: Title: INCREMENTAL SELF-IMPROVEMENT FOR LIFE-TIME MULTI-AGENT REINFORCEMENT LEARNING  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1228\nTitle: Title: Team-Partitioned, Opaque-Transition Reinforcement Learning  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1649\nTitle: Title: Multi-Agent Reinforcement Learning: Independent vs. Cooperative Agents  \n\nPaper id: 1687\nTitle: Title: Markov games as a framework for multi-agent reinforcement learning  \n\nPaper id: 1688\nTitle: Title: Co-Evolving Soccer Softbot Team Coordination with Genetic Programming  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 815\nTitle: Title: Genetic Algorithm based Scheduling in a Dynamic Manufacturing Environment  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1523\nTitle: Title: A Generalized Permutation Approach to Job Shop Scheduling with Genetic Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 880\nTitle: Title: Control of Parallel Population Dynamics by Social-Like Behavior of GA-Individuals  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1136\nTitle: Title: Using Neural Networks and Genetic Algorithms as Heuristics for NP-Complete Problems  \n\nPaper id: 813\nTitle: Title: The Application of a Parallel Genetic Algorithm to the n=m=P=C max Flowshop Problem  \nLabel: Genetic Algorithms\n\nPaper id: 343\nTitle: Title: A Promising genetic Algorithm Approach to Job-Shop Scheduling, Rescheduling, and Open-Shop Scheduling Problems  \nLabel: Genetic Algorithms\n\nPaper id: 1060\nTitle: Title: An Overview of Genetic Algorithms Part 1, Fundamentals  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1542\nTitle: Title: Protein Sequencing Experiment Planning Using Analogy protein sequencing experiments. Planning is interleaved with experiment execution,\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 801\nTitle: Title: Massively Parallel Support for Case-based Planning  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 313\nTitle: Title: The Case for Graph-Structured Representations  \nLabel: Case Based\n\nPaper id: 1475\nTitle: Title: Within the Letter of the Law: open-textured planning  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 895\nTitle: Title: CABeN: A Collection of Algorithms for Belief Networks  Correspond with:  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1436\nTitle: Title: Advantages of Decision Lists and Implicit Negatives in Inductive Logic Programming  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1782\nTitle: Title: Least-Squares Temporal Difference Learning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 295\nTitle: Title: A Neuro-Dynamic Programming Approach to Retailer Inventory Management 1  \nLabel: Reinforcement Learning\n\nPaper id: 2328\nTitle: Title: A Comparison of Direct and Model-Based Reinforcement Learning  \nLabel: Reinforcement Learning\n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n\nPaper id: 134\nTitle: Title: Gain Adaptation Beats Least Squares?  \nLabel: Neural Networks\n\nPaper id: 566\nTitle: Title: Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 465\nTitle: Title: Strategy Learning with Multilayer Connectionist Representations 1  \nLabel: Reinforcement Learning\n\nPaper id: 1378\nTitle: Title: Generalization in Reinforcement Learning: Safely Approximating the Value Function  \nLabel: Reinforcement Learning\n\nPaper id: 1118\nTitle: Title: Adapting Bias by Gradient Descent: An Incremental Version of Delta-Bar-Delta  \nLabel: Neural Networks\n\nPaper id: 621\nTitle: Title: Reinforcement Learning Methods for Continuous-Time Markov Decision Problems  \nLabel: Reinforcement Learning\n\nPaper id: 554\nTitle: Title: Reinforcement Learning Algorithms for Average-Payoff Markovian Decision Processes  \nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2146\nTitle: Title: On Learning Read-k-Satisfy-j DNF  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1003\nTitle: Title: Learning Conjunctions of Horn Clauses  \nLabel: Theory\n\nPaper id: 2182\nTitle: Title: Weakly Learning DNF and Characterizing Statistical Query Learning Using Fourier Analysis  \n\nPaper id: 1004\nTitle: Title: Learning Read-Once Formulas with Queries  \nLabel: Theory\n\nPaper id: 638\nTitle: Title: Learning a set of primitive actions with an Induction of decision trees. Machine Learning, 1(1):81-106,\nLabel: Theory\n\nPaper id: 1897\nTitle: Title: On Learning Visual Concepts and DNF Formulae  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 862\nTitle: Title: Language-Independent Data-Oriented Grapheme-to-Phoneme Conversion  \nLabel: Case Based\n\nPaper id: 25\nTitle: Title: General Bounds on Statistical Query Learning and PAC Learning with Noise via Hypothesis Boosting  \nLabel: Theory\n\nPaper id: 2541\nTitle: Title: PLEASE: A prototype learning system using genetic algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 294\nTitle: Title: References elements that can solve difficult learning control problems. on Simulation of Adaptive Behavior, pages\nLabel: Reinforcement Learning\n\nPaper id: 1539\nTitle: Title: Finding new rules for incomplete theories: Explicit biases for induction with contextual information. In Proceedings\nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2459\nTitle: Title: Control of Selective Visual Attention: Modeling the \"Where\" Pathway  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2606\nTitle: Title: Computational modeling of spatial attention  \nLabel: Neural Networks\n\nPaper id: 553\nTitle: Title: Object Selection Based on Oscillatory Correlation  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 527\nTitle: Title: VISIT: An Efficient Computational Model of Human Visual Attention  \nLabel: Neural Networks\n\nPaper id: 2337\nTitle: Title: Learning to segment images using dynamic feature binding an isolated object in an image is\nLabel: Neural Networks\n\nPaper id: 2662\nTitle: Title: Efficient Visual Search: A Connectionist Solution  \nLabel: Neural Networks\n\nPaper id: 123\nTitle: Title: Fast Numerical Integration of Relaxation Oscillator Networks Based on Singular Limit Solutions  \nLabel: Neural Networks\n\nPaper id: 2611\nTitle: Title: The end of the line for a brain-damaged model of unilateral neglect  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2306\nTitle: Title: On the Applicability of Neural Network and Machine Learning Methodologies to Natural Language Processing  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2049\nTitle: Title: Learning Feature-based Semantics with Simple Recurrent Networks  \n\nPaper id: 2594\nTitle: Title: Can Recurrent Neural Networks Learn Natural Language Grammars? W&Z recurrent neural networks are able to\nLabel: Neural Networks\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1283\nTitle: Title: Bilinear Separation of Two Sets in n-Space  \nLabel: Neural Networks\n\nPaper id: 477\nTitle: Title: Forward models: Supervised learning with a distal teacher  \nLabel: Reinforcement Learning\n\nPaper id: 205\nTitle: Title: Beyond the Cognitive Map: Contributions to a Computational Neuroscience Theory of Rodent Navigation for the\nLabel: Neural Networks\n\nPaper id: 350\nTitle: Title: Induction of Multiscale Temporal Structure  \nLabel: Neural Networks\n\nPaper id: 1760\nTitle: Title: Parallel Environments for Implementing Neural Networks  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 957\nTitle: Title: ANNEALED THEORIES OF LEARNING  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 967\nTitle: Title: Rigorous Learning Curve Bounds from Statistical Mechanics  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 848\nTitle: Title: An Experimental and Theoretical Comparison of Model Selection Methods on simple model selection problems, the\nLabel: Theory\n\nPaper id: 322\nTitle: Title: Statistical Tests for Comparing Supervised Classification Learning Algorithms  \nLabel: Theory\n\nPaper id: 1400\nTitle: Title: Towards Robust Model Selection using Estimation and Approximation Error Bounds  \n\nPaper id: 306\nTitle: Title: Learning Curve Bounds for Markov Decision Processes with Undiscounted Rewards  \nLabel: Reinforcement Learning\n\nPaper id: 57\nTitle: Title: Markov Decision Processes in Large State Spaces  \nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2562\nTitle: Title: NONLINEAR TRADING MODELS THROUGH SHARPE RATIO MAXIMIZATION  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 668\nTitle: Title: Nonlinear gated experts for time series: discovering regimes and avoiding overfitting  \nLabel: Neural Networks\n\nPaper id: 2595\nTitle: Title: TO IMPROVE FORECASTING  \nLabel: Neural Networks\n\nPaper id: 1366\nTitle: Title: ``Learning Local Error Bars for Nonlinear Regression.''  Learning Local Error Bars for Nonlinear Regression  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 263\nTitle: Title: Non-linear Models for Time Series Using Mixtures of Experts  \nLabel: Neural Networks\n\nPaper id: 2414\nTitle: Title: On-Line Adaptation of a Signal Predistorter through Dual Reinforcement Learning  \n\nPaper id: 2513\nTitle: Title: Avoiding overfitting by locally matching the noise level of the data gating network discovers the\n\nPaper id: 310\nTitle: Title: Forecasting electricity demand using nonlinear mixture of experts  \nLabel: Neural Networks\n\nPaper id: 2373\nTitle: Title: Evaluating Neural Network Predictors by Bootstrapping  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1881\nTitle: Title: Integrity Constraints in ILP using a Monte Carlo approach  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 344\nTitle: Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In\nLabel: Rule Learning\n\nPaper id: 2449\nTitle: Title: Learning by Refining Algorithm Sketches  \n\nPaper id: 2450\nTitle: Title: Architecture for Iterative Learning of Recursive Definitions  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1498\nTitle: Title: INFERENTIAL THEORY OF LEARNING: Developing Foundations for Multistrategy Learning  \nLabel: Case Based\n\nPaper id: 2032\nTitle: Title: Learning Action-oriented Perceptual Features for Robot Navigation  \nLabel: Rule Learning\n\nPaper id: 2426\nTitle: Title: Inductive Constraint Logic  \nLabel: Rule Learning\n\nPaper id: 2339\nTitle: Title: An intelligent search method using Inductive Logic Programming  \nLabel: Rule Learning\n\nPaper id: 1244\nTitle: Title: Producing More Comprehensible Models While Retaining Their Performance  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2049\nTitle: Title: Learning Feature-based Semantics with Simple Recurrent Networks  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2218\nTitle: Title: L 0 |The First Four Years Abstract A summary of the progress and plans of\nLabel: Neural Networks\n\nPaper id: 2306\nTitle: Title: On the Applicability of Neural Network and Machine Learning Methodologies to Natural Language Processing  \n\nPaper id: 2410\nTitle: Title: Subsymbolic Case-Role Analysis of Sentences with Embedded Clauses  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n\nPaper id: 2594\nTitle: Title: Can Recurrent Neural Networks Learn Natural Language Grammars? W&Z recurrent neural networks are able to\nLabel: Neural Networks\n\nPaper id: 204\nTitle: Title: Natural Language Processing with Subsymbolic Neural Networks  \nLabel: Neural Networks\n\nPaper id: 2021\nTitle: Title: Best-First Model Merging for Dynamic Learning and Recognition  \nLabel: Neural Networks\n\nPaper id: 1811\nTitle: Title: Disambiguation and Grammar as Emergent Soft Constraints  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 784\nTitle: Title: Studies of Neurological Transmission Analysis using Hierarchical Bayesian Mixture Models  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 917\nTitle: Title: Practical Bayesian Inference Using Mixtures of Mixtures  \nLabel: Probabilistic Methods\n\nPaper id: 1613\nTitle: Title: Priors and Component Structures in Autoregressive Time Series Models  \nLabel: Probabilistic Methods\n\nPaper id: 845\nTitle: Title: Mixture Models in the Exploration of Structure-Activity Relationships in Drug Design  \nLabel: Neural Networks\n\nPaper id: 1338\nTitle: Title: Computing Nonparametric Hierarchical Models  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1015\nTitle: Title: Bayesian curve fitting using multivariate normal mixtures  \n\nPaper id: 99\nTitle: Title: Bayesian Forecasting of Multinomial Time Series through Conditionally Gaussian Dynamic Models  \nLabel: Probabilistic Methods\n\nPaper id: 850\nTitle: Title: COMPUTING DISTRIBUTIONS OF ORDER STATISTICS  \n\nPaper id: 1654\nTitle: Title: Hyperparameter estimation in Dirichlet process mixture models  \nLabel: Probabilistic Methods\n\nPaper id: 1614\nTitle: Title: Bayesian Inference on Periodicities and Component Spectral Structure in Time Series  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1733\nTitle: Title: Decision Analysis by Augmented Probability Simulation  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 904\nTitle: Title: Assessing Convergence of Markov Chain Monte Carlo Algorithms  \nLabel: Probabilistic Methods\n\nPaper id: 41\nTitle: Title: Markov Chain Monte Carlo Convergence Diagnostics: A Comparative Review  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 23\nTitle: Title: Applications and extensions of MCMC in IRT: Multiple item types, missing data, and rated responses  \nLabel: Probabilistic Methods\n\nPaper id: 94\nTitle: Title: Perfect Simulation in Stochastic Geometry  \nLabel: Probabilistic Methods\n\nPaper id: 889\nTitle: Title: Bounding Convergence Time of the Gibbs Sampler in Bayesian Image Restoration  \nLabel: Probabilistic Methods\n\nPaper id: 533\nTitle: Title: Estimating Ratios of Normalizing Constants for Densities with Different Dimensions  \nLabel: Probabilistic Methods\n\nPaper id: 292\nTitle: Title: An Approach to Diagnosing Total Variation Convergence of MCMC Algorithms  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 154\nTitle: Title: Data-driven Modeling and Synthesis of Acoustical Instruments  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 392\nTitle: Title: DRAFT Cluster-Weighted Modeling for Time Series Prediction and Characterization  \n\nPaper id: 74\nTitle: Title: Hierarchical Mixtures of Experts and the EM Algorithm  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 881\nTitle: Title: Proben1 A Set of Neural Network Benchmark Problems and Benchmarking Rules  \nLabel: Neural Networks\n\nPaper id: 787\nTitle: Title: Hidden Markov decision trees  \nLabel: Probabilistic Methods\n\nPaper id: 680\nTitle: Title: Cortical Mechanisms of Visual Recognition and Learning: A Hierarchical Kalman Filter Model  \nLabel: Neural Networks\n\nPaper id: 1103\nTitle: Reference: [39] <author> Yoda, M. </author> <year> (1994). </year> <title> Predicting the Tokyo stock market. </title> <editor> In Deboeck, G.J. (Ed.) </editor> <year> (1994). </year> <title> Trading on the Edge. </title> <address> New York: </address> <publisher> Wiley., </publisher> <pages> 66-79. </pages> <institution> VITA Graduate School Southern Illinois University Daniel Nikolaev Nikovski Date of Birth: </institution> <address> April 13, 1969 606 West College Street, Apt.4, Rm. 6, Carbondale, Illinois 62901 150 Hristo Botev Boulevard, Apt. </address> <month> 54, </month> <title> 4004 Plovdiv, Bulgaria Technical University - Sofia, Bulgaria Engineer of Computer Systems and Control Thesis Title: Adaptive Computation Techniques for Time Series Analysis Major Professor: </title> <journal> Dr. Mehdi Zargham </journal>\nLabel: Neural Networks\n\nPaper id: 252\nTitle: Title: A Modular Q-Learning Architecture for Manipulator Task Decomposition `Data storage in the cerebellar model ar\nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2082\nTitle: Title: %A L. Ingber %T Adaptive simulated annealing (ASA): Lessons learned %J Control and Cybernetics Annealing\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1793\nTitle: Title: STATISTICAL MECHANICS OF COMBAT WITH HUMAN FACTORS  \nLabel: Neural Networks\n\nPaper id: 2545\nTitle: Title: Volatility of Volatility of Financial Markets  \nLabel: Neural Networks\n\nPaper id: 1795\nTitle: Title: Application of statistical mechanics methodol- ogy to term-structure bond-pricing models, Mathl. Comput. Modelling Application of\nLabel: Neural Networks\n\nPaper id: 1775\nTitle: Title: GENETIC ALGORITHMS AND VERY FAST SIMULATED REANNEALING: A COMPARISON  \nLabel: Genetic Algorithms\n\nPaper id: 2178\nTitle: Title: Statistical Mechanics of Nonlinear Nonequilibrium Financial Markets: Applications to Optimized Trading  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 1728\nTitle: Title: Dynamic Parameter Encoding for Genetic Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 2582\nTitle: Title: Noisy Time Series Prediction using Symbolic Representation and Recurrent Neural Network Grammatical Inference  \nLabel: Neural Networks\n\nPaper id: 1794\nTitle: Title: NONLINEAR NONEQUILIBRIUM NONQUANTUM NONCHAOTIC STATISTICAL MECHANICS OF NEOCORTICAL INTERACTIONS  \n\nPaper id: 1773\nTitle: Title: Canonical Momenta Indicators of Financial Markets and Neocortical EEG  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2660\nTitle: Title: Discovering Structure in Continuous Variables Using Bayesian Networks  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 558\nTitle: Title: A Tutorial on Learning With Bayesian Networks  \nLabel: Probabilistic Methods\n\nPaper id: 577\nTitle: Title: Operations for Learning with Graphical Models decomposition techniques and the demonstration that graphical models provide\nLabel: Probabilistic Methods\n\nPaper id: 1933\nTitle: Title: Continuous sigmoidal belief networks trained using slice sampling  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 748\nTitle: Title: Markov Chain Monte Carlo Methods Based on `Slicing' the Density Function  \nLabel: Probabilistic Methods\n\nPaper id: 1934\nTitle: Title: Sequential Update of Bayesian Network Structure  \nLabel: Probabilistic Methods\n\nPaper id: 36\nTitle: Title: Generative Models for Discovering Sparse Distributed Representations  \n\nPaper id: 2463\nTitle: Title: Learning Belief Networks in the Presence of Missing Values and Hidden Variables  \nLabel: Probabilistic Methods\n\nPaper id: 1502\nTitle: Title: Belief Networks, Hidden Markov Models, and Markov Random Fields: a Unifying View  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1856\nTitle: Title: Identifiability, Improper Priors and Gibbs Sampling for Generalized Linear Models  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2421\nTitle: Title: On Convergence of the EM Algorithm and the Gibbs Sampler  SUMMARY  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2590\nTitle: Title: Backfitting in Smoothing Spline ANOVA  \nLabel: Probabilistic Methods\n\nPaper id: 2654\nTitle: Title: On the Sample Complexity of Weakly Learning  \nLabel: Probabilistic Methods\n\nPaper id: 74\nTitle: Title: Hierarchical Mixtures of Experts and the EM Algorithm  \nLabel: Probabilistic Methods\n\nPaper id: 345\nTitle: Title: On Convergence Properties of the EM Algorithm for Gaussian Mixtures  \nLabel: Probabilistic Methods\n\nPaper id: 1868\nTitle: Title: Convergence in Norm for Alternating Expectation-Maximization (EM) Type Algorithms 1  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2343\nTitle: Title: Feature Subset Selection Using the Wrapper Method: Overfitting and Dynamic Search Space Topology  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 430\nTitle: Title: Irrelevant Features and the Subset Selection Problem  \nLabel: Theory\n\nPaper id: 2443\nTitle: Title: Issues in the Integration of Data Mining and Data Visualization Visualizing the Simple Bayesian Classifier  \n\nPaper id: 1337\nTitle: Title: MLC A Machine Learning Library in C  \nLabel: Theory\n\nPaper id: 208\nTitle: Title: Feature Subset Selection as Search with Probabilistic Estimates  \nLabel: Theory\n\nPaper id: 1618\nTitle: Title: Selection of Relevant Features and Examples in Machine Learning  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2487\nTitle: Title: An Optimized Theory Revision Module  \nLabel: Theory\n\nPaper id: 1284\nTitle: Title: Feature Selection via Mathematical Programming  \nLabel: Neural Networks\n\nPaper id: 1335\nTitle: Title: A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection  \nLabel: Probabilistic Methods\n\nPaper id: 1568\nTitle: Title: The Utility of Feature Weighting in Nearest-Neighbor Algorithms  \n\nPaper id: 2137\nTitle: Title: Search-based Class Discretization  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1408\nTitle: Title: Use of Architecture-Altering Operations to Dynamically Adapt a Three-Way Analog Source Identification Circuit to Accommodate\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1249\nTitle: Title: Evolution of Non-Deterministic Incremental Algorithms as a New Approach for Search in State Spaces  \nLabel: Genetic Algorithms\n\nPaper id: 1921\nTitle: Title: Computation. Automated Synthesis of Analog Electrical Circuits by Means of Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 1931\nTitle: Title: AUTOMATED TOPOLOGY AND SIZING OF ANALOG CIRCUITS AUTOMATED DESIGN OF BOTH THE TOPOLOGY AND SIZING\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1473\nTitle: Title: Evolving Non-Determinism: An Inventive and Efficient Tool for Optimization and Discovery of Strategies  \nLabel: Genetic Algorithms\n\nPaper id: 2624\nTitle: Title: A Comparison between Cellular Encoding and Direct Encoding for Genetic Neural Networks  \nLabel: Genetic Algorithms\n\nPaper id: 523\nTitle: Title: Some studies in machine learning using the game of checkers. IBM Journal, 3(3):211-229, 1959. Some\nLabel: Genetic Algorithms\n\nPaper id: 2402\nTitle: Title: Evolution of a Time-Optimal Fly-To Controller Circuit using Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 1728\nTitle: Title: Dynamic Parameter Encoding for Genetic Algorithms  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2191\nTitle: Reference: [Tex89] <institution> Texas Instruments. </institution> <note> TMS320C30 C Compiler Reference Guide, 1989. Document Title: SPRU034A. </note>\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2275\nTitle: Title: Connectionist Layered Object-Oriented Network Simulator (CLONES): User's Manual minimize the learning curve for using CLONES,\nLabel: Neural Networks\n\nPaper id: 362\nTitle: Title: Learning Topology-Preserving Maps Using Self-Supervised Backpropagation  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2522\nTitle: Title: A Symbolic Complexity Analysis of Connectionist Algorithms for Distributed-Memory Machines  \nLabel: Neural Networks\n\nPaper id: 747\nTitle: Title: Cholinergic suppression of transmission may allow combined associative memory function and self-organization in the neocortex.  \n\nPaper id: 2445\nTitle: Title: Simulation of Reduced Precision Arithmetic for Digital Neural Networks Using the RAP Machine  \nLabel: Neural Networks\n\nPaper id: 2268\nTitle: Title: SPERT: A VLIW/SIMD Microprocessor for Artificial Neural Network Computations  \nLabel: Neural Networks\n\nPaper id: 1120\nTitle: Title: ICSIM: An Object-Oriented Connectionist Simulator gives an overview of the simulator. Its main concepts, the\nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1363\nTitle: Title: Exact Identification of Read-once Formulas Using Fixed Points of Amplification Functions  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 672\nTitle: Title: Cryptographic Limitations on Learning Boolean Formulae and Finite Automata  \nLabel: Theory\n\nPaper id: 2168\nTitle: Title: Malicious Membership Queries and Exceptions  \nLabel: Theory\n\nPaper id: 640\nTitle: Title: Learning in the Presence of Malicious Errors  \n\nPaper id: 2653\nTitle: Title: On the Sample Complexity of Weakly Learning  \nLabel: Theory\n\nPaper id: 786\nTitle: Title: Learning Boolean Read-Once Formulas over Generalized Bases  \nLabel: Theory\n\nPaper id: 1364\nTitle: Title: Learning k-term DNF Formulas with an Incomplete Membership Oracle  \nLabel: Theory\n\nPaper id: 1343\nTitle: Title: Randomly Fallible Teachers: Learning Monotone DNF with an Incomplete Membership Oracle  \nLabel: Theory\n\nPaper id: 2475\nTitle: Title: Learning polynomials with queries: The highly noisy case  task for the case when F  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2360\nTitle: Title: Efficient Learning of Typical Finite Automata from Random Walks (Extended Abstract)  \nLabel: Theory\n\nPaper id: 1003\nTitle: Title: Learning Conjunctions of Horn Clauses  \nLabel: Theory\n\nPaper id: 2040\nTitle: Title: On the Learnability and Usage of Acyclic Probabilistic Finite Automata  \nLabel: Theory\n\nPaper id: 1293\nTitle: Title: Using Recurrent Neural Networks to Learn the Structure of Interconnection Networks  \nLabel: Neural Networks\n\nPaper id: 549\nTitle: Title: Efficient Distribution-free Learning of Probabilistic Concepts  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2470\nTitle: Title: Induction and Recapitulation of Deep Musical Structure  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2646\nTitle: Title: Automated Fitness Raters for the GP-Music System  \nLabel: Genetic Algorithms\n\nPaper id: 2101\nTitle: Title: Evolving Control Structures with Automatically Defined Macros  Evolving Control Structures with Automatically Defined Macros.  \n\nPaper id: 1277\nTitle: Title: Evolution of Pseudo-colouring Algorithms for Image Enhancement with Interactive Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 1230\nTitle: Title: Entailment for Specification Refinement  \nLabel: Genetic Algorithms\n\nPaper id: 2643\nTitle: Title: GP-Music: An Interactive Genetic Programming System for Music Generation with Automated Fitness Raters  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 995\nTitle: Title: Evolving a Team  \n\nPaper id: 1533\nTitle: Title: Evolving Visual Routines  \nLabel: Genetic Algorithms\n\nPaper id: 1476\nTitle: Title: Program Optimization for Faster Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 2598\nTitle: Title: Duplication of Coding Segments in Genetic Programming  \n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1638\nTitle: Title: Walsh Functions and Predicting Problem Complexity  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1441\nTitle: Title: Nonlinearity, Hyperplane Ranking and the Simple Genetic Algorithm  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1717\nTitle: Title: 3 Representation Issues in Neighborhood Search and Evolutionary Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 941\nTitle: Title: Hyperplane Ranking in Simple Genetic Algorithms  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1095\nTitle: Title: Learning Unions of Boxes with Membership and Equivalence Queries  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 798\nTitle: Title: Composite Geometric Concepts and Polynomial Predictability  \nLabel: Theory\n\nPaper id: 1456\nTitle: Title: An Interactive Model of Teaching  \nLabel: Theory\n\nPaper id: 1360\nTitle: Title: Learning From a Consistently Ignorant Teacher  \nLabel: Theory\n\nPaper id: 792\nTitle: Title: Learning Unions of Rectangles with Queries  \nLabel: Theory\n\nPaper id: 1433\nTitle: Title: Learning Boxes in High Dimension  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1105\nTitle: Title: PAC Learning Intersections of Halfspaces with Membership Queries (Extended Abstract)  \nLabel: Theory\n\nPaper id: 507\nTitle: Title: PAC Learning Axis-aligned Rectangles with Respect to Product Distributions from Multiple-instance Examples  \nLabel: Theory\n\nPaper id: 1469\nTitle: Title: Warning: missing six few referencesfixed in proceedings. Learning with Queries but Incomplete Information (Extended Abstract)  \nLabel: Theory\n\nPaper id: 308\nTitle: Title: The Power of Self-Directed Learning  \nLabel: Theory\n\nPaper id: 1343\nTitle: Title: Randomly Fallible Teachers: Learning Monotone DNF with an Incomplete Membership Oracle  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 455\nTitle: Title: Learning from an Automated Training Agent  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 552\nTitle: Title: Learning to Act using Real-Time Dynamic Programming  \nLabel: Reinforcement Learning\n\nPaper id: 374\nTitle: Title: An Introspection Approach to Querying a Trainer  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 723\nTitle: Title: Exploiting Structure in Policy Construction  \nLabel: Probabilistic Methods\n\nPaper id: 483\nTitle: Title: The Parti-game Algorithm for Variable Resolution Reinforcement Learning in Multidimensional State-spaces  \nLabel: Reinforcement Learning\n\nPaper id: 548\nTitle: Title: Value Function Based Production Scheduling  \nLabel: Reinforcement Learning\n\nPaper id: 691\nTitle: Title: Reinforcement Learning in the Multi-Robot Domain  \nLabel: Reinforcement Learning\n\nPaper id: 671\nTitle: Title: Learning to Achieve Goals  \nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 652\nTitle: Title: ARB: A Hardware Mechanism for Dynamic Reordering of Memory References*  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 86\nTitle: Title: THE EXPANDABLE SPLIT WINDOW PARADIGM FOR EXPLOITING FINE-GRAIN PARALLELISM  \nLabel: Rule Learning\n\nPaper id: 249\nTitle: Title: Control Flow Prediction For Dynamic ILP Processors  \nLabel: Rule Learning\n\nPaper id: 373\nTitle: Title: Task Selection for a Multiscalar Processor  \nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2649\nTitle: Title: Limits of Control Flow on Parallelism  \nLabel: Rule Learning\n\nPaper id: 735\nTitle: Title: The Limits of Instruction Level Parallelism in SPEC95 Applications  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1768\nTitle: Title: Evolving Neural Networks to Play Go  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2257\nTitle: Title: Real-time Interactive Neuro-evolution  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 247\nTitle: Title: Machine Learning,  Efficient Reinforcement Learning through Symbiotic Evolution  \nLabel: Reinforcement Learning\n\nPaper id: 2444\nTitle: Title: Symbiotic Evolution of Neural Networks in Sequential Decision Tasks  \nLabel: Reinforcement Learning\n\nPaper id: 22\nTitle: Title: Discovering Complex Othello Strategies Through Evolutionary Neural Networks  \nLabel: Genetic Algorithms\n\nPaper id: 1767\nTitle: Title: Incremental Evolution of Complex General Behavior  \nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1384\nTitle: Title: Use of Methodological Diversity to Improve Neural Network Generalisation  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1383\nTitle: Title: Data-defined Problems and Multiversion Neural-net Systems  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1398\nTitle: Title: Self-Organizing Sets of Experts  \nLabel: Neural Networks\n\nPaper id: 152\nTitle: Title: Replicability of Neural Computing Experiments  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2062\nTitle: Title: A Case-Based Reasoning Approach  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2066\nTitle: Title: On the Informativeness of the DNA Promoter Sequences Domain Theory  \nLabel: Theory\n\nPaper id: 2061\nTitle: Title: Inductive Learning and Case-Based Reasoning  \n\nPaper id: 2052\nTitle: Title: Applying Case-Based Reasoning to Control in Robotics  \nLabel: Case Based\n\nPaper id: 2060\nTitle: Title: A Similarity-Based Retrieval Tool for Software Repositories  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 857\nTitle: Title: How to Retrieve Relevant Information?  \nLabel: Case Based\n\nPaper id: 159\nTitle: Title: Bias-Driven Revision of Logical Domain Theories  \nLabel: Theory\n\nPaper id: 1483\nTitle: Title: Context-Based Similarity Applied to Retrieval of Relevant Cases  \nLabel: Case Based\n\nPaper id: 96\nTitle: Title: Lazy Induction Triggered by CBR  \nLabel: Case Based\n\nPaper id: 2674\nTitle: Title: Comparing Methods for Refining Certainty-Factor Rule-Bases  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 160\nTitle: Title: EVALUATION OF GAUSSIAN PROCESSES AND OTHER METHODS FOR NON-LINEAR REGRESSION  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 125\nTitle: Title: Gaussian Processes for Bayesian Classification via Hybrid Monte Carlo  \nLabel: Neural Networks\n\nPaper id: 322\nTitle: Title: Statistical Tests for Comparing Supervised Classification Learning Algorithms  \nLabel: Theory\n\nPaper id: 2681\nTitle: Title: Regression with Input-dependent Noise: A Gaussian Process Treatment  \nLabel: Neural Networks\n\nPaper id: 469\nTitle: Title: Interpolation Models with Multiple  \n\nPaper id: 2540\nTitle: Title: Efficient Implementation of Gaussian Processes  \nLabel: Neural Networks\n\nPaper id: 1857\nTitle: Title: Monte Carlo Implementation of Gaussian Process Models for Bayesian Regression and Classification  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 15\nTitle: Title: Back Propagation is Sensitive to Initial Conditions  \nLabel: Neural Networks\n\nPaper id: 78\nTitle: Title: Probabilistic Networks: New Models and New Methods  \nLabel: Theory\n\nPaper id: 611\nTitle: Title: Learning networks for face analysis and synthesis  \nLabel: Neural Networks\n\nPaper id: 214\nTitle: Title: Bayesian Non-linear Modelling for the Prediction Competition  \nLabel: Neural Networks\n\nPaper id: 2508\nTitle: Title: WRAPPERS FOR PERFORMANCE ENHANCEMENT AND OBLIVIOUS DECISION GRAPHS  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 225\nTitle: Title: on Inductive Logic Programming (ILP-95) Inducing Logic Programs without Explicit Negative Examples  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 88\nTitle: Title: Hoeffding Races: Accelerating Model Selection Search for Classification and Function Approximation  \nLabel: Theory\n\nPaper id: 686\nTitle: Title: Prototype and Feature Selection by Sampling and Random Mutation Hill Climbing Algorithms  \nLabel: Case Based\n\nPaper id: 2428\nTitle: Title: Bumptrees for Efficient Function, Constraint, and Classification Learning  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 381\nTitle: Title: Compression-Based Feature Subset Selection  Keywords: Minimum Description Length Principle, Cross Validation, Noise  \nLabel: Theory\n\nPaper id: 762\nTitle: Title: Using Errors to Create Piecewise Learnable Partitions  \nLabel: Theory\n\nPaper id: 44\nTitle: Title: Competitive Anti-Hebbian Learning of Invariants  \nLabel: Case Based\n\nPaper id: 1698\nTitle: Title: CBET: a Case Base Exploration Tool  \n\nPaper id: 634\nTitle: Title: Oblivious Decision Trees and Abstract Cases  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2645\nTitle: Title: CBR on Semi-structured Documents: The ExperienceBook and the FAllQ Project  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2482\nTitle: Title: CBR for Document Retrieval: The FAllQ Project  \nLabel: Case Based\n\nPaper id: 1854\nTitle: Title: Case Retrieval Nets: Basic Ideas and Extensions  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1855\nTitle: Title: Applying Case Retrieval Nets to Diagnostic Tasks in Technical Domains  \nLabel: Case Based\n\nPaper id: 2122\nTitle: Title: Preparing Case Retrieval Nets for Distributed Processing  \nLabel: Case Based\n\nPaper id: 75\nTitle: Title: A Memory Model for Case Retrieval by Activation Passing  \n\nPaper id: 2299\nTitle: Title: Case Retrieval Nets Applied to Large Case Bases  \nLabel: Case Based\n\nPaper id: 1864\nTitle: Title: An Investigation of Marker-Passing Algorithms for Analogue Retrieval  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1167\nTitle: Title: Evolving Globally Synchronized Cellular Automata  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1330\nTitle: Title: Evolving Cellular Automata with Genetic Algorithms: A Review of Recent Work  \nLabel: Genetic Algorithms\n\nPaper id: 1331\nTitle: Title: Mechanisms of Emergent Computation in Cellular Automata  \nLabel: Genetic Algorithms\n\nPaper id: 1332\nTitle: Title: Statistical Dynamics of the Royal Road Genetic Algorithm  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 793\nTitle: Title: A Survey of Evolution Strategies  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 684\nTitle: Title: Finding Overlapping Distributions with MML  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 525\nTitle: Title: MML mixture modelling of multi-state, Poisson, von Mises circular and Gaussian distributions  \nLabel: Theory\n\nPaper id: 1550\nTitle: Title: MDL and MML Similarities and Differences (Introduction to Minimum Encoding Inference Part III)  \nLabel: Theory\n\nPaper id: 779\nTitle: Title: Monte Carlo Comparison of Non-hierarchical Unsupervised Classifiers  \n\nPaper id: 161\nTitle: Title: On Bayesian analysis of mixtures with an unknown number of components  Summary  \n\nPaper id: 1425\nTitle: Title: Unsupervised Learning Using MML  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1419\nTitle: Title: BAYESIAN ESTIMATION OF THE VON MISES CONCENTRATION PARAMETER  \nLabel: Probabilistic Methods\n\nPaper id: 996\nTitle: Title: Reparameterisation Issues in Mixture Modelling and their bearing on MCMC algorithms  \n\nPaper id: 84\nTitle: Title: Approximate Bayes Factors and Accounting for Model Uncertainty in Generalized Linear Models  \nLabel: Probabilistic Methods\n\nPaper id: 759\nTitle: Title: BAYESIAN STATISTICS 6, pp. 000--000  Exact sampling for Bayesian inference: towards general purpose algorithms  \nLabel: Probabilistic Methods\n\nPaper id: 1555\nTitle: Title: Bayesian and Information-Theoretic Priors for Bayesian Network Parameters  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 378\nTitle: Title: Mingers, 1989 J. Mingers. An empirical comparison of pruning methods for decision tree induction. Machine\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 960\nTitle: Title: Proceedings of the First International Workshop on Intelligent Adaptive Systems (IAS-95) Constructive Induction-based Learning Agents:\n\nPaper id: 1644\nTitle: Title: A Comparative Study of ID3 and Backpropagation for English Text-to-Speech Mapping  \nLabel: Neural Networks\n\nPaper id: 178\nTitle: Title: Learning Decision Trees from Decision Rules:  \nLabel: Rule Learning\n\nPaper id: 2447\nTitle: Title: New Roles for Machine Learning in Design for Design of Educational Computing New roles for\nLabel: Case Based\n\nPaper id: 1207\nTitle: Title: Data Analyses Using Simulated Breeding and Inductive Learning Methods  \nLabel: Genetic Algorithms\n\nPaper id: 1027\nTitle: Title: Pessimistic decision tree pruning based on tree size  \nLabel: Theory\n\nPaper id: 1275\nTitle: Title: Fossil: A Robust Relational Learner  \n\nPaper id: 218\nTitle: Title: Learning Classification Trees  \nLabel: Probabilistic Methods\n\nPaper id: 2291\nTitle: Title: Top-Down Pruning in Relational Learning  \nLabel: Rule Learning\n\nPaper id: 396\nTitle: Title: Geometric Comparison of Classifications and Rule Sets*  \n\nPaper id: 227\nTitle: Title: Induction of Oblique Decision Trees  \nLabel: Theory\n\nPaper id: 1238\nTitle: Title: On Pruning and Averaging Decision Trees  \n\nPaper id: 1539\nTitle: Title: Finding new rules for incomplete theories: Explicit biases for induction with contextual information. In Proceedings\nLabel: Rule Learning\n\nPaper id: 286\nTitle: Title: The Estimation of Probabilities in Attribute Selection Measures for Decision Tree Induction  \nLabel: Rule Learning\n\nPaper id: 335\nTitle: Title: Incremental Reduced Error Pruning  \n\nPaper id: 2195\nTitle: Title: LEARNING FOR DECISION MAKING: The FRD Approach and a Comparative Study  Machine Learning and Inference Laboratory  \nLabel: Rule Learning\n\nPaper id: 1678\nTitle: Title: Induction of One-Level Decision Trees  \n\nPaper id: 2290\nTitle: Title: A Comparison of Pruning Methods for Relational Concept Learning  \nLabel: Rule Learning\n\nPaper id: 1963\nTitle: Title: Learning Problem-Oriented Decision Structures from Decision Rules: The AQDT-2 System  \nLabel: Rule Learning\n\nPaper id: 2583\nTitle: Title: Dynamic Automatic Model Selection  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1173\nTitle: Title: Dynamical Selection of Learning Algorithms  \nLabel: Theory\n\nPaper id: 56\nTitle: Title: Self bounding learning algorithms  \nLabel: Theory\n\nPaper id: 893\nTitle: Title: LEARNING LOGICAL EXCEPTIONS IN CHESS  \nLabel: Rule Learning\n\nPaper id: 1191\nTitle: Title: Machine Learning Bias, Statistical Bias, and Statistical Variance of Decision Tree Algorithms  \n\nPaper id: 701\nTitle: Title: Experiments on the Transfer of Knowledge between Neural Networks Reprinted from: Computational Learning Theory and\nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2542\nTitle: Title: Worst-Case Identification of Nonlinear Fading Memory Systems  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2262\nTitle: Title: OPTIMAL ASYMPTOTIC IDENTIFICATION UNDER BOUNDED DISTURBANCES  \nLabel: Neural Networks\n\nPaper id: 2236\nTitle: Title: Robust Convergence of Two-Stage Nonlinear Algorithms for Identification in H 1  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2435\nTitle: Title: Identification in H 1 with Nonuniformly Spaced Frequency Response Measurements  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1571\nTitle: Title: Average-Case Analysis of a Nearest Neighbor Algorithm  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 343\nTitle: Title: A Promising genetic Algorithm Approach to Job-Shop Scheduling, Rescheduling, and Open-Shop Scheduling Problems  \nLabel: Genetic Algorithms\n\nPaper id: 2202\nTitle: Title: An Evolutionary Approach to Combinatorial Optimization Problems  \nLabel: Genetic Algorithms\n\nPaper id: 1216\nTitle: Title: Evolutionary Programming and Evolution Strategies: Similarities and Differences  \nLabel: Genetic Algorithms\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 1218\nTitle: Title: Genetic algorithms with multi-parent recombination  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 402\nTitle: Title: The Evolutionary Cost of Learning  \nLabel: Genetic Algorithms\n\nPaper id: 833\nTitle: Title: Graph Coloring with Adaptive Evolutionary Algorithms  \n\nPaper id: 2077\nTitle: Title: An Adaptive Penalty Approach for Constrained Genetic-Algorithm Optimization  \nLabel: Genetic Algorithms\n\nPaper id: 658\nTitle: Title: Hill Climbing with Learning (An Abstraction of Genetic Algorithm)  \n\nPaper id: 1130\nTitle: Title: Dynamic Hill Climbing: Overcoming the limita- tions of optimization techniques  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2385\nTitle: Title: Receptive Fields for Vision: from Hyperacuity to Object Recognition  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 611\nTitle: Title: Learning networks for face analysis and synthesis  \nLabel: Neural Networks\n\nPaper id: 2499\nTitle: Title: Objective Function Formulation of the BCM Theory of Visual Cortical Plasticity: Statistical Connections, Stability Conditions  \n\nPaper id: 2676\nTitle: Title: Models of perceptual learning in vernier hyperacuity  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 864\nTitle: Title: A Sparse Representation for Function Approximation  \nLabel: Neural Networks\n\nPaper id: 633\nTitle: Title: Chapter 1 Reinforcement Learning for Planning and Control  \n\nPaper id: 938\nTitle: Title: Genetic Programming of Minimal Neural Nets Using Occam's Razor  \nLabel: Genetic Algorithms\n\nPaper id: 579\nTitle: Title: Comparison of Kernel Estimators, Perceptrons, and Radial-Basis Functions for OCR and Speech Classification  \nLabel: Neural Networks\n\nPaper id: 386\nTitle: Title: Temporal Compositional Processing by a DSOM Hierarchical Model  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 699\nTitle: Title: Adaptive state space quantisation for reinforcement learning of collision-free navigation  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 566\nTitle: Title: Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming  \nLabel: Reinforcement Learning\n\nPaper id: 588\nTitle: Title: LEARNING TO AVOID COLLISIONS: A REINFORCEMENT LEARNING PARADIGM FOR MOBILE ROBOT NAVIGATION  \nLabel: Reinforcement Learning\n\nPaper id: 294\nTitle: Title: References elements that can solve difficult learning control problems. on Simulation of Adaptive Behavior, pages\nLabel: Reinforcement Learning\n\nPaper id: 747\nTitle: Title: Cholinergic suppression of transmission may allow combined associative memory function and self-organization in the neocortex.  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 333\nTitle: Title: A Comparison of Action Selection Learning Methods  \nLabel: Reinforcement Learning\n\nPaper id: 353\nTitle: Title: Application of Neural Networks for the Classification of Diffuse Liver Disease by Quantitative Echography  \nLabel: Neural Networks\n\nPaper id: 34\nTitle: Title: Using a Case Base of Surfaces to Speed-Up Reinforcement Learning  \n\nPaper id: 465\nTitle: Title: Strategy Learning with Multilayer Connectionist Representations 1  \nLabel: Reinforcement Learning\n\nPaper id: 202\nTitle: Title: Dyslexic and Category-Specific Aphasic Impairments in a Self-Organizing Feature Map Model of the Lexicon  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 114\nTitle: Title: A Generalization of Sauer's Lemma  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 171\nTitle: Title: Characterizations of Learnability for Classes of f0; ng-valued Functions  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 109\nTitle: Title: A General Lower Bound on the Number of Examples Needed for Learning  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 284\nTitle: Title: Role of Ontology in Creative Understanding  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 64\nTitle: Title: Integrating Creativity and Reading: A Functional Approach  \n\nPaper id: 486\nTitle: Title: CASE-BASED CREATIVE DESIGN  \nLabel: Case Based\n\nPaper id: 583\nTitle: Title: Introspective reasoning using meta-explanations for multistrategy learning  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 50\nTitle: Title: Abstract  \n\nPaper id: 231\nTitle: Title: Understanding Creativity: A Case-Based Approach  \nLabel: Case Based\n\nPaper id: 1126\nTitle: Title: Towards A Computer Model of Memory Search Strategy Learning  \n\nPaper id: 289\nTitle: Title: A theory of questions and question asking  \nLabel: Case Based\n\nPaper id: 2568\nTitle: Title: Abstract  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 995\nTitle: Title: Evolving a Team  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2139\nTitle: Title: Evolving Teamwork and Coordination with Genetic Programming  \n\nPaper id: 1985\nTitle: Title: ABSTRACT  \nLabel: Genetic Algorithms\n\nPaper id: 415\nTitle: Title: Competitive Environments Evolve Better Solutions for Complex Tasks  \nLabel: Genetic Algorithms\n\nPaper id: 1971\nTitle: Title: Voting for Schemata  \nLabel: Genetic Algorithms\n\nPaper id: 1232\nTitle: Title: Augmenting Collective Adaptation with Simple Process Agents  \nLabel: Genetic Algorithms\n\nPaper id: 1178\nTitle: Title: Strongly Typed Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 956\nTitle: Title: Modeling Distributed Search via Social Insects  \n\nPaper id: 2673\nTitle: Title: A genetic prototype learner  \nLabel: Genetic Algorithms\n\nPaper id: 1231\nTitle: Title: Type Inheritance in Strongly Typed Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 1690\nTitle: Title: Evolving Behavioral Strategies in Predators and Prey  \nLabel: Genetic Algorithms\n\nPaper id: 1230\nTitle: Title: Entailment for Specification Refinement  \nLabel: Genetic Algorithms\n\nPaper id: 1495\nTitle: Title: Clique Detection via Genetic Programming  Topics in Combinatorial Optimization  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2470\nTitle: Title: Induction and Recapitulation of Deep Musical Structure  \n\nPaper id: 1688\nTitle: Title: Co-Evolving Soccer Softbot Team Coordination with Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 1224\nTitle: Title: Using Real-Valued Genetic Algorithms to Evolve Rule Sets for Classification  \nLabel: Genetic Algorithms\n\nPaper id: 1034\nTitle: Title: 1 GP-COM: A Distributed, Component-Based Genetic Programming System in C++  \nLabel: Genetic Algorithms\n\nPaper id: 1476\nTitle: Title: Program Optimization for Faster Genetic Programming  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2327\nTitle: Title: A Comparison of New and Old Algorithms for A Mixture Estimation Problem  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1924\nTitle: Title: Training Algorithms for Hidden Markov Models Using Entropy Based Distance Functions  \nLabel: Theory\n\nPaper id: 2034\nTitle: Title: Update rules for parameter estimation in Bayesian networks  \nLabel: Probabilistic Methods\n\nPaper id: 76\nTitle: Title: A VIEW OF THE EM ALGORITHM THAT JUSTIFIES INCREMENTAL, SPARSE, AND OTHER VARIANTS  \nLabel: Probabilistic Methods\n\nPaper id: 2015\nTitle: Title: On-Line Portfolio Selection Using Multiplicative Updates  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1934\nTitle: Title: Sequential Update of Bayesian Network Structure  \nLabel: Probabilistic Methods\n\nPaper id: 661\nTitle: Title: A Statistical Approach to Decision Tree Modeling  \nLabel: Probabilistic Methods\n\nPaper id: 131\nTitle: Title: The Expectation-Maximization Algorithm for MAP Estimation  \nLabel: Probabilistic Methods\n\nPaper id: 577\nTitle: Title: Operations for Learning with Graphical Models decomposition techniques and the demonstration that graphical models provide\nLabel: Probabilistic Methods\n\nPaper id: 2092\nTitle: Title: Universal Portfolios With and Without Transaction Costs  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1680\nTitle: Title: Making SME greedy and pragmatic  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1123\nTitle: Title: MAC/FAC: A Model of Similarity-based Retrieval  \nLabel: Case Based\n\nPaper id: 1354\nTitle: Title: The Structure-Mapping Engine: Algorithm and Examples  \n\nPaper id: 1674\nTitle: Title: Proceedings of CogSci89 Structural Evaluation of Analogies: What Counts?  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1188\nTitle: Title: In  Estimating analogical similarity by dot-products of Holographic Reduced Representations.  \nLabel: Neural Networks\n\nPaper id: 1001\nTitle: Title: Is analogical problem solving always analogical? The case for imitation. Second draft Is analogical problem\nLabel: Case Based\n\nPaper id: 75\nTitle: Title: A Memory Model for Case Retrieval by Activation Passing  \n\nPaper id: 994\nTitle: Title: Role of Stories 1  \nLabel: Case Based\n\nPaper id: 1317\nTitle: Title: Use of Analogy in Automated Theorem Proving  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 98\nTitle: Title: Planning and Learning in an Adversarial Robotic Game  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 615\nTitle: Title: Efficient Algorithms for Learning to Play Repeated Games Against Computationally Bounded Adversaries  \nLabel: Theory\n\nPaper id: 1954\nTitle: Title: TD Models: Modeling the World at a Mixture of Time Scales  \nLabel: Reinforcement Learning\n\nPaper id: 2696\nTitle: Title: Learning DFA from Simple Examples  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2183\nTitle: Title: Multi-time Models for Temporally  \nLabel: Reinforcement Learning\n\nPaper id: 2695\nTitle: Title: A Polynomial Time Incremental Algorithm for Regular Grammar Inference  \nLabel: Theory\n\nPaper id: 54\nTitle: Title: A Competitive Approach to Game Learning  \nLabel: Theory\n\nPaper id: 556\nTitle: Title: The Power of a Pebble: Exploring and Mapping Directed Graphs  \nLabel: Theory\n\nPaper id: 672\nTitle: Title: Cryptographic Limitations on Learning Boolean Formulae and Finite Automata  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1028\nTitle: Title: NETWORKS, FUNCTION DETERMINES FORM  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1037\nTitle: Title: OBSERVABILITY IN RECURRENT NEURAL NETWORKS  \nLabel: Neural Networks\n\nPaper id: 1610\nTitle: Title: Using Fourier-Neural Recurrent Networks to Fit Sequential Input/Output Data  \nLabel: Neural Networks\n\nPaper id: 1042\nTitle: Title: Recurrent Neural Networks: Some Systems-Theoretic Aspects  \nLabel: Neural Networks\n\nPaper id: 206\nTitle: Title: NEURAL NETS AS SYSTEMS MODELS AND CONTROLLERS suitability of \"neural nets\" as models for dynamical\n\nPaper id: 1435\nTitle: Title: Advantages of Decision Lists and Implicit Negatives in Inductive Logic Programming  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n\nPaper id: 536\nTitle: Title: Dimension of Recurrent Neural Networks  \nLabel: Neural Networks\n\nPaper id: 1490\nTitle: Title: FEEDBACK STABILIZATION USING TWO-HIDDEN-LAYER NETS  \nLabel: Neural Networks\n\nPaper id: 1043\nTitle: Title: Complete Controllability of Continuous-Time Recurrent Neural Networks  \nLabel: Neural Networks\n\nPaper id: 1488\nTitle: Title: Identification and Control of Nonlinear Systems Using Neural Network Models: Design and Stability Analysis  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1931\nTitle: Title: AUTOMATED TOPOLOGY AND SIZING OF ANALOG CIRCUITS AUTOMATED DESIGN OF BOTH THE TOPOLOGY AND SIZING\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 523\nTitle: Title: Some studies in machine learning using the game of checkers. IBM Journal, 3(3):211-229, 1959. Some\nLabel: Genetic Algorithms\n\nPaper id: 1408\nTitle: Title: Use of Architecture-Altering Operations to Dynamically Adapt a Three-Way Analog Source Identification Circuit to Accommodate\n\nPaper id: 2624\nTitle: Title: A Comparison between Cellular Encoding and Direct Encoding for Genetic Neural Networks  \nLabel: Genetic Algorithms\n\nPaper id: 1921\nTitle: Title: Computation. Automated Synthesis of Analog Electrical Circuits by Means of Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 2402\nTitle: Title: Evolution of a Time-Optimal Fly-To Controller Circuit using Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 2277\nTitle: Title: Discovery of Symbolic, Neuro-Symbolic and Neural Networks with Parallel Distributed Genetic Programming  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1249\nTitle: Title: Evolution of Non-Deterministic Incremental Algorithms as a New Approach for Search in State Spaces  \nLabel: Genetic Algorithms\n\nPaper id: 961\nTitle: Title: CFS-C: A Package of Domain Independent Subroutines for Implementing Classifier Systems in Arbitrary, User-Defined Environments.  \nLabel: Genetic Algorithms\n\nPaper id: 910\nTitle: Title: Learning Sequential Decision Rules Using Simulation Models and Competition  \nLabel: Genetic Algorithms\n\nPaper id: 2252\nTitle: Title: Neural Programming and an Internal Reinforcement Policy  \nLabel: Genetic Algorithms\n\nPaper id: 283\nTitle: Title: A Local Learning Algorithm for Dynamic Feedforward and Recurrent Networks  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2156\nTitle: Title: WORST CASE PREDICTION OVER SEQUENCES UNDER LOG LOSS  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 453\nTitle: Title: How to Use Expert Advice (Extended Abstract)  \nLabel: Theory\n\nPaper id: 2098\nTitle: Title: Predicting a binary sequence almost as well as the optimal biased coin  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2059\nTitle: Title: Challenges in Evolving Controllers for Physical Robots  \nLabel: Theory\n\nPaper id: 1358\nTitle: Title: On the Complexity of Function Learning  \nLabel: Theory\n\nPaper id: 9\nTitle: Title: Online Learning versus O*ine Learning  \nLabel: Theory\n\nPaper id: 1269\nTitle: Title: Context-sensitive learning methods for text categorization  \nLabel: Theory\n\nPaper id: 2099\nTitle: Title: Game Theory, On-line Prediction and Boosting  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1065\nTitle: Title: A Survey of Parallel Genetic Algorithms  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 1063\nTitle: Title: An Analysis of the Effects of Neighborhood Size and Shape on Local Selection Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 1305\nTitle: Title: Distribution Category:  A Parallel Genetic Algorithm for the Set Partitioning Problem  \nLabel: Genetic Algorithms\n\nPaper id: 1106\nTitle: Title: Genetic Algorithms for Combinatorial Optimization: The Assembly Line Balancing Problem  \nLabel: Genetic Algorithms\n\nPaper id: 1279\nTitle: Title: Speeding up Genetic Programming: A Parallel BSP implementation the Bulk Synchronous Parallel Pro gramming (BSP)\nLabel: Genetic Algorithms\n\nPaper id: 1153\nTitle: Title: Evolution in Time and Space The Parallel Genetic Algorithm  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2361\nTitle: Title: Program Search with a Hierarchical Variable Length Representation: Genetic Programming, Simulated Annealing and Hill Climbing  \nLabel: Genetic Algorithms\n\nPaper id: 2248\nTitle: Title: Heuristic for Improved Genetic Bin Packing  \nLabel: Genetic Algorithms\n\nPaper id: 1571\nTitle: Title: Average-Case Analysis of a Nearest Neighbor Algorithm  \n\nPaper id: 1850\nTitle: Title: Genetic Programming for Pedestrians  \nLabel: Genetic Algorithms\n\nPaper id: 2200\nTitle: Title: Adaptation in constant utility non-stationary environments  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 206\nTitle: Title: NEURAL NETS AS SYSTEMS MODELS AND CONTROLLERS suitability of \"neural nets\" as models for dynamical\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 536\nTitle: Title: Dimension of Recurrent Neural Networks  \nLabel: Neural Networks\n\nPaper id: 1028\nTitle: Title: NETWORKS, FUNCTION DETERMINES FORM  \n\nPaper id: 1891\nTitle: Title: Vapnik-Chervonenkis Dimension of Recurrent Neural Networks  \nLabel: Neural Networks\n\nPaper id: 1042\nTitle: Title: Recurrent Neural Networks: Some Systems-Theoretic Aspects  \nLabel: Neural Networks\n\nPaper id: 1490\nTitle: Title: FEEDBACK STABILIZATION USING TWO-HIDDEN-LAYER NETS  \nLabel: Neural Networks\n\nPaper id: 1488\nTitle: Title: Identification and Control of Nonlinear Systems Using Neural Network Models: Design and Stability Analysis  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1435\nTitle: Title: Advantages of Decision Lists and Implicit Negatives in Inductive Logic Programming  \nLabel: Neural Networks\n\nPaper id: 411\nTitle: Title: POWER OF NEURAL NETS  \nLabel: Neural Networks\n\nPaper id: 1668\nTitle: Title: Space-Frequency Localized Basis Function Networks for Nonlinear System Estimation and Control  \nLabel: Neural Networks\n\nPaper id: 980\nTitle: Title: Some Topics in Neural Networks and Control  \n\nPaper id: 1043\nTitle: Title: Complete Controllability of Continuous-Time Recurrent Neural Networks  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 241\nTitle: Title: Segmentation and Classification of Combined Optical and Radar Imagery  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 763\nTitle: Title: PREENS, a Parallel Research Execution Environment for Neural Systems  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 747\nTitle: Title: Cholinergic suppression of transmission may allow combined associative memory function and self-organization in the neocortex.  \n\nPaper id: 1879\nTitle: Title: Rochester Connectionist Simulator  \nLabel: Neural Networks\n\nPaper id: 2355\nTitle: Title: CONVIS: Action Oriented Control and Visualization of Neural Networks Introduction and Technical Description  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 21\nTitle: Title: Decision Tree Function Approximation in Reinforcement Learning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 438\nTitle: Title: A System for Induction of Oblique Decision Trees  \nLabel: Theory\n\nPaper id: 1378\nTitle: Title: Generalization in Reinforcement Learning: Safely Approximating the Value Function  \nLabel: Reinforcement Learning\n\nPaper id: 294\nTitle: Title: References elements that can solve difficult learning control problems. on Simulation of Adaptive Behavior, pages\nLabel: Reinforcement Learning\n\nPaper id: 567\nTitle: Title: Generalization in Reinforcement Learning: Successful Examples Using Sparse Coarse Coding  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 466\nTitle: Title: On the Computational Economics of Reinforcement Learning  \n\nPaper id: 807\nTitle: Title: Designing Neural Networks for Adaptive Control  \nLabel: Reinforcement Learning\n\nPaper id: 1540\nTitle: Title: MultiPlayer Residual Advantage Learning With General Function Approximation  \n\nPaper id: 239\nTitle: Title: Robust Value Function Approximation by Working Backwards Computing an accurate value function is the key\nLabel: Reinforcement Learning\n\nPaper id: 970\nTitle: Title: Generality versus Size in Genetic Programming  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 713\nTitle: Title: FLEXIBLE PARAMETRIC MEASUREMENT ERROR MODELS  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 347\nTitle: Title: A Reference Bayesian Test for Nested Hypotheses And its Relationship to the Schwarz Criterion  \nLabel: Probabilistic Methods\n\nPaper id: 161\nTitle: Title: On Bayesian analysis of mixtures with an unknown number of components  Summary  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 84\nTitle: Title: Approximate Bayes Factors and Accounting for Model Uncertainty in Generalized Linear Models  \nLabel: Probabilistic Methods\n\nPaper id: 95\nTitle: Title: Bayesian Detection of Clusters and Discontinuities in Disease Maps  \n\nPaper id: 996\nTitle: Title: Reparameterisation Issues in Mixture Modelling and their bearing on MCMC algorithms  \n\nPaper id: 684\nTitle: Title: Finding Overlapping Distributions with MML  \n\nPaper id: 759\nTitle: Title: BAYESIAN STATISTICS 6, pp. 000--000  Exact sampling for Bayesian inference: towards general purpose algorithms  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2454\nTitle: Title: Early Stopping but when?  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1058\nTitle: Title: Statistical Theory of Overtraining Is Cross-Validation Asymptotically Effective?  \nLabel: Neural Networks\n\nPaper id: 1342\nTitle: Title: Centering Neural Network Gradient Factors  \nLabel: Neural Networks\n\nPaper id: 2129\nTitle: Title: Fast Pruning Using Principal Components  \nLabel: Neural Networks\n\nPaper id: 881\nTitle: Title: Proben1 A Set of Neural Network Benchmark Problems and Benchmarking Rules  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2423\nTitle: Title: Error-Correcting Output Codes: A General Method for Improving Multiclass Inductive Learning Programs  \nLabel: Theory\n\nPaper id: 1256\nTitle: Title: A BENCHMARK FOR CLASSIFIER LEARNING  \nLabel: Rule Learning\n\nPaper id: 74\nTitle: Title: Hierarchical Mixtures of Experts and the EM Algorithm  \nLabel: Probabilistic Methods\n\nPaper id: 1211\nTitle: Title: Natural Gradient Descent for Training Multi-Layer Perceptrons  \nLabel: Neural Networks\n\nPaper id: 1119\nTitle: Title: Adaptive Parameter Pruning in Neural Networks  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1155\nTitle: Title: Memory-Based Lexical Acquisition and Processing  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 783\nTitle: Title: Resolving PP attachment Ambiguities with Memory-Based Learning  \nLabel: Case Based\n\nPaper id: 785\nTitle: Title: RAPID DEVELOPMENT OF NLP MODULES WITH MEMORY-BASED LEARNING  \nLabel: Case Based\n\nPaper id: 1601\nTitle: Title: Learning the Past Tense of English Verbs: The Symbolic Pattern Associator vs. Connectionist Models  \nLabel: Neural Networks\n\nPaper id: 862\nTitle: Title: Language-Independent Data-Oriented Grapheme-to-Phoneme Conversion  \nLabel: Case Based\n\nPaper id: 1407\nTitle: Title: ABSTRACTION CONSIDERED HARMFUL: LAZY LEARNING OF LANGUAGE PROCESSING  \nLabel: Case Based\n\nPaper id: 1328\nTitle: Title: A Weighted Nearest Neighbor Algorithm for Learning with Symbolic Features  \nLabel: Neural Networks\n\nPaper id: 1812\nTitle: Title: GENERALIZATION PERFORMANCE OF BACKPROPAGATION LEARNING ON A SYLLABIFICATION TASK  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1101\nTitle: Title: On Reasoning from Data  \nLabel: Case Based\n\nPaper id: 1429\nTitle: Title: Learning First-Order Definitions of Functions  \nLabel: Rule Learning\n\nPaper id: 224\nTitle: Title: on Inductive Logic Programming (ILP-95) Inducing Logic Programs without Explicit Negative Examples  \nLabel: Rule Learning\n\nPaper id: 2423\nTitle: Title: Error-Correcting Output Codes: A General Method for Improving Multiclass Inductive Learning Programs  \nLabel: Theory\n\nPaper id: 1111\nTitle: Title: Towards a Better Understanding of Memory-Based Reasoning Systems  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 197\nTitle: Title: Optimal Navigation in a Probibalistic World  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 295\nTitle: Title: A Neuro-Dynamic Programming Approach to Retailer Inventory Management 1  \nLabel: Reinforcement Learning\n\nPaper id: 749\nTitle: Title: On the Complexity of Solving Markov Decision Problems  \nLabel: Reinforcement Learning\n\nPaper id: 3\nTitle: Title: Planning and Acting in Partially Observable Stochastic Domains  \nLabel: Reinforcement Learning\n\nPaper id: 633\nTitle: Title: Chapter 1 Reinforcement Learning for Planning and Control  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 82\nTitle: Title: A Reinforcement Learning Approach to Job-shop Scheduling  \nLabel: Reinforcement Learning\n\nPaper id: 2485\nTitle: Title: Tight Performance Bounds on Greedy Policies Based on Imperfect Value Functions  \nLabel: Reinforcement Learning\n\nPaper id: 1782\nTitle: Title: Least-Squares Temporal Difference Learning  \n\nPaper id: 210\nTitle: Title: A Unified Analysis of Value-Function-Based Reinforcement-Learning Algorithms  \nLabel: Reinforcement Learning\n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 870\nTitle: Title: Learning to take risks  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1687\nTitle: Title: Markov games as a framework for multi-agent reinforcement learning  \n\nPaper id: 523\nTitle: Title: Some studies in machine learning using the game of checkers. IBM Journal, 3(3):211-229, 1959. Some\nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2442\nTitle: Title: Using Temporal-Difference Reinforcement Learning to Improve Decision-Theoretic Utilities for Diagnosis  \nLabel: Reinforcement Learning\n\nPaper id: 2600\nTitle: Title: Evolution of Iteration in Genetic Programming D a v d A The solution to many\nLabel: Genetic Algorithms\n\nPaper id: 277\nTitle: Title: Applying Online Search Techniques to Continuous-State Reinforcement Learning key to the success of the local\nLabel: Reinforcement Learning\n\nPaper id: 717\nTitle: Title: Information filtering: Selection mechanisms in learning systems. Machine Learning, 10:113-151, 1993. Generalization as search. Artificial\n\nPaper id: 1921\nTitle: Title: Computation. Automated Synthesis of Analog Electrical Circuits by Means of Genetic Programming  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1595\nTitle: Title: ID2-of-3: Constructive Induction of M of-N Concepts for Discriminators in Decision Trees  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2346\nTitle: Title: Parity: The Problem that Won't Go Away  \nLabel: Theory\n\nPaper id: 1964\nTitle: Title: Constructing Nominal Xof-N Attributes  \nLabel: Theory\n\nPaper id: 151\nTitle: Title: Rerepresenting and Restructuring Domain Theories: A Constructive Induction Approach  \nLabel: Theory\n\nPaper id: 1863\nTitle: Title: Effects of Different Types of New Attribute on Constructive Induction  \n\nPaper id: 1776\nTitle: Title: Extending Theory Refinement to M-of-N Rules  \nLabel: Rule Learning\n\nPaper id: 1301\nTitle: Title: Discovering Representation Space Transformations for Learning Concept Descriptions Combining DNF and M-of-N Rules  \nLabel: Rule Learning\n\nPaper id: 836\nTitle: Title: Unsupervised Constructive Learning  \nLabel: Theory\n\nPaper id: 2675\nTitle: Title: CONSTRUCTING CONJUNCTIVE TESTS FOR DECISION TREES  \n\nPaper id: 1657\nTitle: Title: Using Neural Networks to Automatically Refine Expert System Knowledge Bases: Experiments in the NYNEX MAX Domain  \nLabel: Neural Networks\n\nPaper id: 1862\nTitle: Title: Continuous-valued Xof-N Attributes Versus Nominal Xof-N Attributes for Constructive Induction: A Case Study  \nLabel: Theory\n\nPaper id: 1576\nTitle: Title: What do Constructive Learners Really Learn?  \nLabel: Theory\n\nPaper id: 1824\nTitle: Title: Constructing Conjunctions using Systematic Search on Decision Trees  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1256\nTitle: Title: A BENCHMARK FOR CLASSIFIER LEARNING  \nLabel: Rule Learning\n\nPaper id: 1644\nTitle: Title: A Comparative Study of ID3 and Backpropagation for English Text-to-Speech Mapping  \nLabel: Neural Networks\n\nPaper id: 1422\nTitle: Title: Generating Accurate and Diverse Members of a Neural-Network Ensemble  \nLabel: Neural Networks\n\nPaper id: 375\nTitle: Title: Constructive Induction Using a Non-Greedy Strategy for Feature Selection  \nLabel: Theory\n\nPaper id: 2543\nTitle: Title: Combining Connectionist and Symbolic Learning to Refine Certainty-Factor Rule Bases  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1787\nTitle: Title: An integrated approach to the study of object features in visual recognition  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 359\nTitle: Title: Feature Extraction Using an Unsupervised Neural Network  \nLabel: Neural Networks\n\nPaper id: 2499\nTitle: Title: Objective Function Formulation of the BCM Theory of Visual Cortical Plasticity: Statistical Connections, Stability Conditions  \n\nPaper id: 2676\nTitle: Title: Models of perceptual learning in vernier hyperacuity  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2385\nTitle: Title: Receptive Fields for Vision: from Hyperacuity to Object Recognition  \n\nPaper id: 1871\nTitle: Title: 3D Object Recognition Using Unsupervised Feature Extraction  \nLabel: Neural Networks\n\nPaper id: 203\nTitle: Title: Theory of Synaptic Plasticity in Visual Cortex  \nLabel: Neural Networks\n\nPaper id: 1418\nTitle: Title: BCM Network develops Orientation Selectivity and Ocular Dominance in Natural Scene Environment.  \nLabel: Neural Networks\n\nPaper id: 2498\nTitle: Title: Combining Exploratory Projection Pursuit And Projection Pursuit Regression With Application To Neural Networks  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 959\nTitle: Title: Numerical techniques for efficient sonar bearing and range searching in the near field using genetic algorithms  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1130\nTitle: Title: Dynamic Hill Climbing: Overcoming the limita- tions of optimization techniques  \n\nPaper id: 793\nTitle: Title: A Survey of Evolution Strategies  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1127\nTitle: Title: Recombination Operator, its Correlation to the Fitness Landscape and Search Performance  \nLabel: Genetic Algorithms\n\nPaper id: 1380\nTitle: Title: Evaluating Evolutionary Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 856\nTitle: Title: Hierarchical priors and mixture models, with application in regression and density estimation  \nLabel: Genetic Algorithms\n\nPaper id: 1330\nTitle: Title: Evolving Cellular Automata with Genetic Algorithms: A Review of Recent Work  \nLabel: Genetic Algorithms\n\nPaper id: 1715\nTitle: Title: A Sampling-Based Heuristic for Tree Search Applied to Grammar Induction  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 89\nTitle: Title: NP-Completeness of Searches for Smallest Possible Feature Sets a subset of the set of all\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 430\nTitle: Title: Irrelevant Features and the Subset Selection Problem  \nLabel: Theory\n\nPaper id: 635\nTitle: Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features  \n\nPaper id: 638\nTitle: Title: Learning a set of primitive actions with an Induction of decision trees. Machine Learning, 1(1):81-106,\nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 660\nTitle: Title: Efficient Algorithms for Identifying Relevant Features  \nLabel: Theory\n\nPaper id: 52\nTitle: Title: Theory Revision in Fault Hierarchies  \nLabel: Theory\n\nPaper id: 521\nTitle: Title: Covering vs. Divide-and-Conquer for Top-Down Induction of Logic Programs  \nLabel: Rule Learning\n\nPaper id: 683\nTitle: Title: On the Greediness of Feature Selection Algorithms  \n\nPaper id: 441\nTitle: Title: BRACE: A Paradigm For the Discretization of Continuously Valued Data  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 863\nTitle: Title: Empirical Entropy Manipulation for Real-World Problems  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 576\nTitle: Title: An information-maximisation approach to blind separation and blind deconvolution  \nLabel: Neural Networks\n\nPaper id: 808\nTitle: Title: Unsupervised Discrimination of Clustered Data via Optimization of Binary Information Gain  \nLabel: Neural Networks\n\nPaper id: 2499\nTitle: Title: Objective Function Formulation of the BCM Theory of Visual Cortical Plasticity: Statistical Connections, Stability Conditions  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 834\nTitle: Title: Simple Neuron Models for Independent Component Analysis  \nLabel: Neural Networks\n\nPaper id: 2500\nTitle: Title: Face Recognition using a Hybrid Supervised/Unsupervised Neural Network  \nLabel: Neural Networks\n\nPaper id: 2552\nTitle: Title: Inferring sparse, overcomplete image codes using an efficient coding framework  \nLabel: Neural Networks\n\nPaper id: 2498\nTitle: Title: Combining Exploratory Projection Pursuit And Projection Pursuit Regression With Application To Neural Networks  \nLabel: Neural Networks\n\nPaper id: 1067\nTitle: Title: A Fast Fixed-Point Algorithm for Independent Component Analysis  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2334\nTitle: Title: New Methods for Competitive Coevolution  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1832\nTitle: Title: Tackling the Boolean Even N Parity Problem with Genetic Programming and Limited-Error Fitness standard GP\nLabel: Genetic Algorithms\n\nPaper id: 54\nTitle: Title: A Competitive Approach to Game Learning  \nLabel: Theory\n\nPaper id: 2332\nTitle: Title: Improved Hoeffding-Style Performance Guarantees for Accurate Classifiers  \nLabel: Genetic Algorithms\n\nPaper id: 2353\nTitle: Title: Dynamics of Co-evolutionary Learning  \nLabel: Genetic Algorithms\n\nPaper id: 602\nTitle: Title: Every Niching Method has its Niche: Fitness Sharing and Implicit Sharing Compared  \nLabel: Genetic Algorithms\n\nPaper id: 209\nTitle: Title: 17 Massively Parallel Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 2103\nTitle: Title: The Evolution of Communication Schemes Over Continuous Channels  \nLabel: Genetic Algorithms\n\nPaper id: 1790\nTitle: Title: Using Genetic Programming to Evolve Board Evaluation Functions  \nLabel: Genetic Algorithms\n\nPaper id: 1917\nTitle: Title: Go and Genetic Programming Playing Go with Filter Functions  \nLabel: Genetic Algorithms\n\nPaper id: 1588\nTitle: Title: Automatic Modularization by Speciation  \nLabel: Genetic Algorithms\n\nPaper id: 1836\nTitle: Title: Small Populations over Many Generations can beat Large Populations over Few Generations in Genetic Programming  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1831\nTitle: Title: Some Training Subset Selection Methods for Supervised Learning in Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 1687\nTitle: Title: Markov games as a framework for multi-agent reinforcement learning  \n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n\nPaper id: 523\nTitle: Title: Some studies in machine learning using the game of checkers. IBM Journal, 3(3):211-229, 1959. Some\nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 980\nTitle: Title: Some Topics in Neural Networks and Control  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1488\nTitle: Title: Identification and Control of Nonlinear Systems Using Neural Network Models: Design and Stability Analysis  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n\nPaper id: 1668\nTitle: Title: Space-Frequency Localized Basis Function Networks for Nonlinear System Estimation and Control  \nLabel: Neural Networks\n\nPaper id: 611\nTitle: Title: Learning networks for face analysis and synthesis  \nLabel: Neural Networks\n\nPaper id: 206\nTitle: Title: NEURAL NETS AS SYSTEMS MODELS AND CONTROLLERS suitability of \"neural nets\" as models for dynamical\n\nPaper id: 1490\nTitle: Title: FEEDBACK STABILIZATION USING TWO-HIDDEN-LAYER NETS  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2658\nTitle: Title: Control Systems Magazine, 14, 1, pp.57-71. Robot Juggling: An Implementation of Memory-based Learning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 691\nTitle: Title: Reinforcement Learning in the Multi-Robot Domain  \nLabel: Reinforcement Learning\n\nPaper id: 477\nTitle: Title: Forward models: Supervised learning with a distal teacher  \nLabel: Reinforcement Learning\n\nPaper id: 1559\nTitle: Title: In  Active Learning with Statistical Models  \nLabel: Neural Networks\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n\nPaper id: 2647\nTitle: Title: Using Local Trajectory Optimizers To Speed Up Global Optimization In Dynamic Programming  \n\nPaper id: 566\nTitle: Title: Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming  \nLabel: Reinforcement Learning\n\nPaper id: 1860\nTitle: Title: Efficient Locally Weighted Polynomial Regression Predictions  \nLabel: Case Based\n\nPaper id: 843\nTitle: Title: Locally Weighted Learning for Control  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1683\nTitle: Title: An Algorithm for Active Data Collection for Learning Feasibility Study with Neural Networks.  \n\nPaper id: 1697\nTitle: Title: Neural Network Exploration Using Optimal Experiment Design  \nLabel: Neural Networks\n\nPaper id: 696\nTitle: Title: GAL: Networks that grow when they learn and shrink when they forget  \nLabel: Neural Networks\n\nPaper id: 304\nTitle: Title: Boltzmann Machine learning using mean field theory and linear response correction  \nLabel: Neural Networks\n\nPaper id: 2295\nTitle: Title: Diplomarbeit A Genetic Algorithm for the Topological Optimization of Neural Networks  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1348\nTitle: Title: Learning Indices for Schema Selection  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1047\nTitle: Title: GIT-CC-92/60 A Model-Based Approach to Analogical Reasoning and Learning in Design  \nLabel: Case Based\n\nPaper id: 1537\nTitle: Title: Incremental Learning of Explanation Patterns and their Indices  \nLabel: Case Based\n\nPaper id: 612\nTitle: Title: Indexing, Elaboration and Refinement: Incremental Learning of Explanatory Cases  \nLabel: Case Based\n\nPaper id: 1535\nTitle: Title: Decision Models: A Theory of Volitional Explanation  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1344\nTitle: Title: Discovery of Physical Principles from Design Experiences  \nLabel: Case Based\n\nPaper id: 1556\nTitle: Title: A Goal-Based Approach to Intelligent Information Retrieval  \nLabel: Case Based\n\nPaper id: 603\nTitle: Title: METHOD-SPECIFIC KNOWLEDGE COMPILATION: TOWARDS PRACTICAL DESIGN SUPPORT SYSTEMS  \nLabel: Case Based\n\nPaper id: 289\nTitle: Title: A theory of questions and question asking  \nLabel: Case Based\n\nPaper id: 1355\nTitle: Title: Modeling Invention by Analogy in ACT-R  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1148\nTitle: Title: Opportunistic Reasoning: A Design Perspective  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 30\nTitle: Title: Towards More Creative Case-Based Design Systems  \nLabel: Case Based\n\nPaper id: 285\nTitle: Title: Explaining Serendipitous Recognition in Design  \nLabel: Case Based\n\nPaper id: 1597\nTitle: Title: an Opportunistic Enterprise  \n\nPaper id: 486\nTitle: Title: CASE-BASED CREATIVE DESIGN  \nLabel: Case Based\n\nPaper id: 1534\nTitle: Title: The Use of Explicit Goals for Knowledge to Guide Inference and Learning  \n\nPaper id: 1355\nTitle: Title: Modeling Invention by Analogy in ACT-R  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 64\nTitle: Title: Integrating Creativity and Reading: A Functional Approach  \n\nPaper id: 231\nTitle: Title: Understanding Creativity: A Case-Based Approach  \nLabel: Case Based\n\nPaper id: 1163\nTitle: Title: Case-Based Planning to Learn  \nLabel: Case Based\n\nPaper id: 1047\nTitle: Title: GIT-CC-92/60 A Model-Based Approach to Analogical Reasoning and Learning in Design  \nLabel: Case Based\n\nPaper id: 289\nTitle: Title: A theory of questions and question asking  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2224\nTitle: Title: Design of Optimization Criteria for Multiple Sequence Alignment  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1827\nTitle: Title: Efficient Algorithms for Inverting Evolution  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 574\nTitle: Title: On the Learnability of Discrete Distributions (extended abstract)  \n\nPaper id: 2083\nTitle: Title: TREE CONTRACTIONS AND EVOLUTIONARY TREES  \nLabel: Neural Networks\n\nPaper id: 2110\nTitle: Title: Constructing Big Trees from Short Sequences  \nLabel: Theory\n\nPaper id: 299\nTitle: Title: On the Approximability of Numerical Taxonomy (Fitting Distances by Tree Metrics)  \nLabel: Theory\n\nPaper id: 1962\nTitle: Title: Learning Distributions from Random Walks  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 90\nTitle: Title: The wake-sleep algorithm for unsupervised neural networks  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 680\nTitle: Title: Cortical Mechanisms of Visual Recognition and Learning: A Hierarchical Kalman Filter Model  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 74\nTitle: Title: Hierarchical Mixtures of Experts and the EM Algorithm  \nLabel: Probabilistic Methods\n\nPaper id: 608\nTitle: Title: Regularization Theory and Neural Networks Architectures  \n\nPaper id: 747\nTitle: Title: Cholinergic suppression of transmission may allow combined associative memory function and self-organization in the neocortex.  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1485\nTitle: Title: Maximizing the Robustness of a Linear Threshold Classifier with Discrete Weights  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1252\nTitle: Title: Constructive Training Methods for Feedforward Neural Networks with Binary Weights  \nLabel: Neural Networks\n\nPaper id: 1159\nTitle: Title: An evolutionary tabu search algorithm and the NHL scheduling problem  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 830\nTitle: Title: Orthogonal incremental learning of a feedforward network  \n\nPaper id: 2564\nTitle: Title: Embedding of a sequential procedure within an evolutionary algorithm for coloring problems in graphs  \nLabel: Genetic Algorithms\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 1634\nTitle: Title: Combining Linear Discriminant Functions with Neural Networks for Supervised Learning  \n\nPaper id: 918\nTitle: Title: Predictive Robot Control with Neural Networks  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1903\nTitle: Title: DNA: A New ASOCS Model With Improved Implementation Potential  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2612\nTitle: Title: Models of Parallel Adaptive Logic  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 26\nTitle: Title: Neural Network Applicability: Classifying the Problem Space  \nLabel: Neural Networks\n\nPaper id: 724\nTitle: Title: ASOCS: A Multilayered Connectionist Network with Guaranteed Learning of Arbitrary Mappings  \nLabel: Neural Networks\n\nPaper id: 2625\nTitle: Title: Digital Neural Networks  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 894\nTitle: Title: Bayesian Analysis of Agricultural Field Experiments  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1255\nTitle: Title: Modelling Risk from a Disease in Time and Space  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 99\nTitle: Title: Bayesian Forecasting of Multinomial Time Series through Conditionally Gaussian Dynamic Models  \nLabel: Probabilistic Methods\n\nPaper id: 358\nTitle: Title: Hierarchical Spatio-Temporal Mapping of Disease Rates  \nLabel: Probabilistic Methods\n\nPaper id: 95\nTitle: Title: Bayesian Detection of Clusters and Discontinuities in Disease Maps  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2450\nTitle: Title: Architecture for Iterative Learning of Recursive Definitions  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1498\nTitle: Title: INFERENTIAL THEORY OF LEARNING: Developing Foundations for Multistrategy Learning  \nLabel: Case Based\n\nPaper id: 1881\nTitle: Title: Integrity Constraints in ILP using a Monte Carlo approach  \n\nPaper id: 2449\nTitle: Title: Learning by Refining Algorithm Sketches  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 1163\nTitle: Title: Case-Based Planning to Learn  \nLabel: Case Based\n\nPaper id: 1534\nTitle: Title: The Use of Explicit Goals for Knowledge to Guide Inference and Learning  \n\nPaper id: 289\nTitle: Title: A theory of questions and question asking  \nLabel: Case Based\n\nPaper id: 2158\nTitle: Title: Learning Recursion with Iterative Bootstrap Induction (Extended Abstract)  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 625\nTitle: Title: Statistical Biases in Backpropagation Learning  Keywords: Cognitive Science, Pattern recognition  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 659\nTitle: Title: Trading Spaces: Computation, Representation and the Limits of Uninformed Learning  \n\nPaper id: 700\nTitle: Title: Is Transfer Inductive?  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 695\nTitle: Title: There is No Free Lunch but the Starter is Cheap: Generalisation from First Principles  \nLabel: Theory\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 11\nTitle: Title: Simple Genetic Programming for Supervised Learning Problems  \n\nPaper id: 624\nTitle: Title: Measuring the Difficulty of Specific Learning Problems  \nLabel: Theory\n\nPaper id: 747\nTitle: Title: Cholinergic suppression of transmission may allow combined associative memory function and self-organization in the neocortex.  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 991\nTitle: Title: Systematic Evaluation of Design Decisions in CBR Systems  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 858\nTitle: Title: MULTISTRATEGY LEARNING IN REACTIVE CONTROL SYSTEMS FOR AUTONOMOUS ROBOTIC NAVIGATION  \nLabel: Case Based\n\nPaper id: 1368\nTitle: Title: Structure oriented case retrieval  \nLabel: Case Based\n\nPaper id: 318\nTitle: Title: Generalizing from Case Studies: A Case Study  \nLabel: Case Based\n\nPaper id: 1084\nTitle: Title: Continuous Case-Based Reasoning  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 281\nTitle: Title: Clay: Integrating Motor Schemas and Reinforcement Learning  \nLabel: Reinforcement Learning\n\nPaper id: 426\nTitle: Title: Rule Induction with CN2: Some Recent Improvements  \nLabel: Rule Learning\n\nPaper id: 686\nTitle: Title: Prototype and Feature Selection by Sampling and Random Mutation Hill Climbing Algorithms  \nLabel: Case Based\n\nPaper id: 454\nTitle: Title: Towards Formalizations in Case-Based Reasoning for Synthesis  \nLabel: Case Based\n\nPaper id: 2333\nTitle: Title: Recursive Automatic Algorithm Selection for Inductive Learning  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 146\nTitle: Title: Convergence-Zone Episodic Memory: Analysis and Simulations  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 17\nTitle: Title: A Neural Network Model of Memory Consolidation  \nLabel: Neural Networks\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n\nPaper id: 747\nTitle: Title: Cholinergic suppression of transmission may allow combined associative memory function and self-organization in the neocortex.  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 461\nTitle: Title: Product Unit Learning constructive algorithm is then introduced which adds product units to a network\nLabel: Neural Networks\n\nPaper id: 198\nTitle: Title: EEG Signal Classification with Different Signal Representations  for a large number of hidden units.  \nLabel: Neural Networks\n\nPaper id: 204\nTitle: Title: Natural Language Processing with Subsymbolic Neural Networks  \nLabel: Neural Networks\n\nPaper id: 1274\nTitle: Title: Surgery  \nLabel: Genetic Algorithms\n\nPaper id: 610\nTitle: Title: Figure 1: The architecture of a Kohonen network. Each input neuron is fully connected with\nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1\nTitle: Title: Applications of machine learning: a medical follow up study  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 344\nTitle: Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In\nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2589\nTitle: Title: Pac-Learning Recursive Logic Programs: Efficient Algorithms  \nLabel: Rule Learning\n\nPaper id: 1627\nTitle: Title: Inductive Learning of Characteristic Concept Descriptions from Small Sets of Classified Examples  \nLabel: Rule Learning\n\nPaper id: 2291\nTitle: Title: Top-Down Pruning in Relational Learning  \nLabel: Rule Learning\n\nPaper id: 1881\nTitle: Title: Integrity Constraints in ILP using a Monte Carlo approach  \n\nPaper id: 1260\nTitle: Title: Transferring and Retraining Learned Information Filters  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 648\nTitle: Title: Reprint of: Sontag, E.D., \"Remarks on stabilization and input-to-state stability,\"  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 693\nTitle: Title: FURTHER FACTS ABOUT INPUT TO STATE STABILIZATION \"Further facts about input to state stabilization\", IEEE\nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 531\nTitle: Title: FEEDBACK STABILIZATION OF NONLINEAR SYSTEMS  \nLabel: Neural Networks\n\nPaper id: 1471\nTitle: Title: New Characterizations of Input to State Stability  \nLabel: Neural Networks\n\nPaper id: 1501\nTitle: Title: A Characterization of Integral Input to State Stability  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2452\nTitle: Title: A Bootstrap Evaluation of the Effect of Data Splitting on Financial Time Series  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2595\nTitle: Title: TO IMPROVE FORECASTING  \nLabel: Neural Networks\n\nPaper id: 1315\nTitle: Title: Modeling Volatility using State Space Models  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 668\nTitle: Title: Nonlinear gated experts for time series: discovering regimes and avoiding overfitting  \nLabel: Neural Networks\n\nPaper id: 1079\nTitle: Title: Nonlinear Prediction of Chaotic Time Series Using Support Vector Machines  \nLabel: Neural Networks\n\nPaper id: 611\nTitle: Title: Learning networks for face analysis and synthesis  \nLabel: Neural Networks\n\nPaper id: 2562\nTitle: Title: NONLINEAR TRADING MODELS THROUGH SHARPE RATIO MAXIMIZATION  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1504\nTitle: Title: From Inheritance Relation to Non-Axiomatic Logic  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1276\nTitle: Title: Heuristics and Normative Models of Judgment under Uncertainty  \nLabel: Probabilistic Methods\n\nPaper id: 1506\nTitle: Title: Non-Axiomatic Reasoning System (Version 2.2) used to show how the system works. The limitations of\nLabel: Probabilistic Methods\n\nPaper id: 1108\nTitle: Title: Confidence as Higher Order Uncertainty proposed for handling higher order uncertainty, including the Bayesian approach,\nLabel: Probabilistic Methods\n\nPaper id: 1525\nTitle: Title: Reference Classes and Multiple Inheritances  \nLabel: Probabilistic Methods\n\nPaper id: 1308\nTitle: Title: A Defect in Dempster-Shafer Theory  \nLabel: Probabilistic Methods\n\nPaper id: 1503\nTitle: Title: Belief Revision in Probability Theory  \nLabel: Probabilistic Methods\n\nPaper id: 1415\nTitle: Title: A New Approach for Induction: From a Non-Axiomatic Logical Point of View  \n\nPaper id: 1507\nTitle: Title: A Unified Treatment of Uncertainties  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1470\nTitle: Title: Interconnected Automata and Linear Systems: A Theoretical Framework in Discrete-Time In Hybrid Systems III: Verification\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 411\nTitle: Title: POWER OF NEURAL NETS  \nLabel: Neural Networks\n\nPaper id: 1037\nTitle: Title: OBSERVABILITY IN RECURRENT NEURAL NETWORKS  \nLabel: Neural Networks\n\nPaper id: 1464\nTitle: Title: LINEAR SYSTEMS WITH SIGN-OBSERVATIONS  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1100\nTitle: Title: Observability of Linear Systems with Saturated Outputs  \nLabel: Neural Networks\n\nPaper id: 2232\nTitle: Title: Facing The Facts: Necessary Requirements For The Artificial Evolution of Complex Behaviour  \nLabel: Genetic Algorithms\n\nPaper id: 1610\nTitle: Title: Using Fourier-Neural Recurrent Networks to Fit Sequential Input/Output Data  \nLabel: Neural Networks\n\nPaper id: 536\nTitle: Title: Dimension of Recurrent Neural Networks  \nLabel: Neural Networks\n\nPaper id: 2594\nTitle: Title: Can Recurrent Neural Networks Learn Natural Language Grammars? W&Z recurrent neural networks are able to\nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1183\nTitle: Title: Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 738\nTitle: Title: On the Convergence of Stochastic Iterative Dynamic Programming Algorithms  \nLabel: Reinforcement Learning\n\nPaper id: 1202\nTitle: Title: Between MDPs and Semi-MDPs: Learning, Planning, and Representing Knowledge at Multiple Temporal Scales  \nLabel: Reinforcement Learning\n\nPaper id: 562\nTitle: Title: Transfer of Learning by Composing Solutions of Elemental Sequential Tasks  \n\nPaper id: 1193\nTitle: Title: Reinforcement Learning with Hierarchies of Machines  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 575\nTitle: Title: Issues in Using Function Approximation for Reinforcement Learning  \nLabel: Reinforcement Learning\n\nPaper id: 1727\nTitle: Title: Machine Learning, 22(1/2/3):95-121, 1996. On the Worst-case Analysis of Temporal-difference Learning Algorithms  \nLabel: Theory\n\nPaper id: 60\nTitle: Title: The Efficient Learning of Multiple Task Sequences  \nLabel: Reinforcement Learning\n\nPaper id: 2014\nTitle: Title: Emergent Hierarchical Control Structures: Learning Reactive/Hierarchical Relationships in Reinforcement Environments  \nLabel: Reinforcement Learning\n\nPaper id: 1117\nTitle: Title: A Coevolutionary Approach to Learning Sequential Decision Rules  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1306\nTitle: Title: Improving the Accuracy and Speed of Support Vector Machines  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1050\nTitle: Title: Extracting Support Data for a Given Task  \nLabel: Theory\n\nPaper id: 1499\nTitle: Title: Comparing Support Vector Machines with Gaussian Kernels to Radial Basis Function Classifiers  \nLabel: Neural Networks\n\nPaper id: 607\nTitle: Title: A Support Vector Machine Approach to Decision Trees  \nLabel: Neural Networks\n\nPaper id: 1310\nTitle: Title: Incorporating Invariances in Support Vector Learning Machines  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 611\nTitle: Title: Learning networks for face analysis and synthesis  \nLabel: Neural Networks\n\nPaper id: 1389\nTitle: Title: Support Vector Machines: Training and Applications  \nLabel: Neural Networks\n\nPaper id: 438\nTitle: Title: A System for Induction of Oblique Decision Trees  \nLabel: Theory\n\nPaper id: 1591\nTitle: Title: Unsupervised Learning by Convex and Conic Coding  \nLabel: Neural Networks\n\nPaper id: 821\nTitle: Title: Massive Data Discrimination via Linear Support Vector Machines  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1059\nTitle: Title: Mathematical Programming in Data Mining  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1055\nTitle: Title: Parsimonious Least Norm Approximation  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1284\nTitle: Title: Feature Selection via Mathematical Programming  \nLabel: Neural Networks\n\nPaper id: 607\nTitle: Title: A Support Vector Machine Approach to Decision Trees  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2139\nTitle: Title: Evolving Teamwork and Coordination with Genetic Programming  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 995\nTitle: Title: Evolving a Team  \n\nPaper id: 2220\nTitle: Title: The Automatic Programming of Agents that Learn Mental Models and Create Simple Plans of Action  \nLabel: Genetic Algorithms\n\nPaper id: 2226\nTitle: Title: Simultaneous Evolution of Programs and their Control Structures Simultaneous Evolution of Programs and their Control\nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1409\nTitle: Title: Evolution of Mapmaking: Learning, planning, and memory using Genetic Programming  \n\nPaper id: 2252\nTitle: Title: Neural Programming and an Internal Reinforcement Policy  \nLabel: Genetic Algorithms\n\nPaper id: 129\nTitle: Title: Evolving Networks: Using the Genetic Algorithm with Connectionist Learning  \nLabel: Genetic Algorithms\n\nPaper id: 2600\nTitle: Title: Evolution of Iteration in Genetic Programming D a v d A The solution to many\nLabel: Genetic Algorithms\n\nPaper id: 1940\nTitle: Title: A Comparison of Crossover and Mutation in Genetic Programming  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1773\nTitle: Title: Canonical Momenta Indicators of Financial Markets and Neocortical EEG  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2545\nTitle: Title: Volatility of Volatility of Financial Markets  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1795\nTitle: Title: Application of statistical mechanics methodol- ogy to term-structure bond-pricing models, Mathl. Comput. Modelling Application of\nLabel: Neural Networks\n\nPaper id: 2178\nTitle: Title: Statistical Mechanics of Nonlinear Nonequilibrium Financial Markets: Applications to Optimized Trading  \nLabel: Neural Networks\n\nPaper id: 2082\nTitle: Title: %A L. Ingber %T Adaptive simulated annealing (ASA): Lessons learned %J Control and Cybernetics Annealing\n\nPaper id: 1794\nTitle: Title: NONLINEAR NONEQUILIBRIUM NONQUANTUM NONCHAOTIC STATISTICAL MECHANICS OF NEOCORTICAL INTERACTIONS  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1520\nTitle: Title: Equivariant adaptive source separation  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 59\nTitle: Title: SELF-ADAPTIVE NEURAL NETWORKS FOR BLIND SEPARATION OF SOURCES  \nLabel: Neural Networks\n\nPaper id: 354\nTitle: Title: Principal and Independent Components in Neural Networks Recent Developments  \nLabel: Neural Networks\n\nPaper id: 920\nTitle: Title: Maximum likelihood source separation for discrete sources  \n\nPaper id: 872\nTitle: Title: A Blind Identification and Separation Technique via Multi-layer Neural Networks  \n\nPaper id: 834\nTitle: Title: Simple Neuron Models for Independent Component Analysis  \nLabel: Neural Networks\n\nPaper id: 1246\nTitle: Title: NIPS*97 Multiplicative Updating Rule for Blind Separation Derived from the Method of Scoring  \nLabel: Neural Networks\n\nPaper id: 1526\nTitle: Title: Working Paper IS-97-22 (Information Systems) A First Application of Independent Component Analysis to Extracting Structure\nLabel: Neural Networks\n\nPaper id: 1524\nTitle: Title: BLIND SEPARATION OF DELAYED SOURCES BASED ON INFORMATION MAXIMIZATION  \nLabel: Neural Networks\n\nPaper id: 1211\nTitle: Title: Natural Gradient Descent for Training Multi-Layer Perceptrons  \nLabel: Neural Networks\n\nPaper id: 570\nTitle: Title: A New Learning Algorithm for Blind Signal Separation  \nLabel: Neural Networks\n\nPaper id: 1072\nTitle: Title: The Nonlinear PCA Learning Rule and Signal Separation Mathematical Analysis  \nLabel: Neural Networks\n\nPaper id: 1709\nTitle: Title: NEURAL NETWORK APPROACH TO BLIND SEPARATION AND ENHANCEMENT OF IMAGES  \nLabel: Neural Networks\n\nPaper id: 839\nTitle: Title: Signal Separation by Nonlinear Hebbian Learning  \nLabel: Neural Networks\n\nPaper id: 1245\nTitle: Title: Blind separation of delayed and convolved sources.  \nLabel: Neural Networks\n\nPaper id: 874\nTitle: Title: LOCAL ADAPTIVE LEARNING ALGORITHMS FOR BLIND SEPARATION OF NATURAL IMAGES  \nLabel: Neural Networks\n\nPaper id: 1200\nTitle: Title: Edges are the `Independent Components' of Natural Scenes.  \nLabel: Neural Networks\n\nPaper id: 1258\nTitle: Title: Independent Component Analysis of Simulated EEG Using a Three-Shell Spherical Head Model 1  \nLabel: Neural Networks\n\nPaper id: 873\nTitle: Title: On the performance of orthogonal source separation algorithms  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1922\nTitle: Title: Maximum Likelihood and Covariant Algorithms for Independent Component Analysis somewhat more biologically plausible, involving no\nLabel: Probabilistic Methods\n\nPaper id: 1814\nTitle: Title: Independent Component Analysis by General Non-linear Hebbian-like Learning Rules  \nLabel: Neural Networks\n\nPaper id: 169\nTitle: Title: LEARNING LINEAR, SPARSE, FACTORIAL CODES  \nLabel: Neural Networks\n\nPaper id: 1381\nTitle: Title: A Context-Sensitive Generalization of ICA  \nLabel: Probabilistic Methods\n\nPaper id: 1067\nTitle: Title: A Fast Fixed-Point Algorithm for Independent Component Analysis  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 510\nTitle: Title: The Bayesian Approach to Tree-Structured Regression  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 356\nTitle: Title: A Flexible Model For Human Circadian Rhythms  \n\nPaper id: 2223\nTitle: Title: Smoothing Spline Models With Correlated Random Errors 1  \nLabel: Neural Networks\n\nPaper id: 192\nTitle: Title: Smoothing Spline ANOVA with Component-Wise Bayesian \"Confidence Intervals\" To Appear, J. Computational and Graphical Statistics  \nLabel: Neural Networks\n\nPaper id: 519\nTitle: Title: Smoothing Spline ANOVA for Exponential Families, with Application to the Wisconsin Epidemiological Study of Diabetic\nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2590\nTitle: Title: Backfitting in Smoothing Spline ANOVA  \nLabel: Probabilistic Methods\n\nPaper id: 2549\nTitle: Title: A Generalized Approximate Cross Validation for Smoothing Splines with Non-Gaussian Data 1  \nLabel: Neural Networks\n\nPaper id: 10\nTitle: Title: GRKPACK: FITTING SMOOTHING SPLINE ANOVA MODELS FOR EXPONENTIAL FAMILIES  \nLabel: Neural Networks\n\nPaper id: 2448\nTitle: Title: Automatic Smoothing Spline Projection Pursuit  Automatic Smoothing Spline Projection Pursuit.  \nLabel: Neural Networks\n\nPaper id: 439\nTitle: Title: Adaptive tuning of numerical weather prediction models: Randomized GCV in three and four dimensional data assimilation  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2539\nTitle: Title: Mining for Causes of Cancer: Machine Learning Experiments at Various Levels of Detail  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1322\nTitle: Title: Theory and Applications of Agnostic PAC-Learning with Small Decision Trees  \nLabel: Theory\n\nPaper id: 1428\nTitle: Title: Inverse entailment and Progol  \nLabel: Rule Learning\n\nPaper id: 2213\nTitle: Title: Generating Declarative Language Bias for Top-Down ILP Algorithms  \nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 323\nTitle: Title: Learning Active Classifiers  \nLabel: Theory\n\nPaper id: 1020\nTitle: Title: Error-Based and Entropy-Based Discretization of Continuous Features  \n\nPaper id: 1601\nTitle: Title: Learning the Past Tense of English Verbs: The Symbolic Pattern Associator vs. Connectionist Models  \nLabel: Neural Networks\n\nPaper id: 1259\nTitle: Title: Finding Accurate Frontiers: A Knowledge-Intensive Approach to Relational Learning  \nLabel: Rule Learning\n\nPaper id: 2290\nTitle: Title: A Comparison of Pruning Methods for Relational Concept Learning  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 38\nTitle: Title: HOW TO EVOLVE AUTONOMOUS ROBOTS: DIFFERENT APPROACHES IN EVOLUTIONARY ROBOTICS  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 273\nTitle: Title: Two is better than one: A diploid genotype for neural networks  \nLabel: Genetic Algorithms\n\nPaper id: 1689\nTitle: Title: Selection for Wandering Behavior in a Small Robot  \nLabel: Genetic Algorithms\n\nPaper id: 372\nTitle: Title: Investigating the role of diploidy in simulated populations of evolving individuals  \nLabel: Genetic Algorithms\n\nPaper id: 219\nTitle: Title: Issues in Evolutionary Robotics  \nLabel: Genetic Algorithms\n\nPaper id: 563\nTitle: Title: Evolving Obstacle Avoidance Behavior in a Robot Arm  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1738\nTitle: Title: Evolving nonTrivial Behaviors on Real Robots: an Autonomous Robot that Picks up Objects  \nLabel: Genetic Algorithms\n\nPaper id: 1325\nTitle: Title: Environmental Effects on Minimal Behaviors in the Minimat World  \nLabel: Genetic Algorithms\n\nPaper id: 37\nTitle: Title: Hierarchical Evolution of Neural Networks  \nLabel: Reinforcement Learning\n\nPaper id: 846\nTitle: Title: Evolving Visually Guided Robots  \nLabel: Genetic Algorithms\n\nPaper id: 538\nTitle: Title: Learning and evolution in neural networks  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1998\nTitle: Title: Programming Environment for a High Performance Parallel Supercomputer with Intelligent Communication  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1873\nTitle: Title: Achieving Super Computer Performance with a DSP Array Processor  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1416\nTitle: Title: Synergy and Commonality in Case-Based and Constraint-Based Reasoning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 923\nTitle: Title: Dynamic Constraint Satisfaction using Case-Based Reasoning Techniques  \nLabel: Case Based\n\nPaper id: 922\nTitle: Title: Towards Improving Case Adaptability with a Genetic Algorithm  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1126\nTitle: Title: Towards A Computer Model of Memory Search Strategy Learning  \n\nPaper id: 580\nTitle: Title: Learning to Improve Case Adaptation by Introspective Reasoning and CBR  \n\nPaper id: 1233\nTitle: Title: A CBR Integration From Inception to Productization  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2200\nTitle: Title: Adaptation in constant utility non-stationary environments  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1797\nTitle: Title: Improving the Performance of Evolutionary Optimization by Dynamically Scaling the Evaluation Function  \nLabel: Genetic Algorithms\n\nPaper id: 2703\nTitle: Title: learning easier tasks. More work is necessary in order to determine more precisely the relationship\nLabel: Genetic Algorithms\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 1969\nTitle: Title: Generalization and scaling in reinforcement learning  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1221\nTitle: Title: Adapting the Evaluation Space to Improve Global Learning  \nLabel: Genetic Algorithms\n\nPaper id: 2177\nTitle: Title: Analyzing Social Network Structures in the Iterated Prisoner's Dilemma with Choice and Refusal  \nLabel: Genetic Algorithms\n\nPaper id: 2298\nTitle: Title: Convergence Analysis of Canonical Genetic Algorithms  \n\nPaper id: 1106\nTitle: Title: Genetic Algorithms for Combinatorial Optimization: The Assembly Line Balancing Problem  \nLabel: Genetic Algorithms\n\nPaper id: 2363\nTitle: Title: Modeling the Evolution of Motivation  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 524\nTitle: Title: An Inductive Learning Approach to Prognostic Prediction  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 520\nTitle: Title: CANCER DIAGNOSIS AND PROGNOSIS VIA LINEAR-PROGRAMMING-BASED MACHINE LEARNING  \nLabel: Neural Networks\n\nPaper id: 1169\nTitle: Title: Individual and Collective Prognostic Prediction  \nLabel: Neural Networks\n\nPaper id: 1454\nTitle: Title: A Neural Network Model for Prognostic Prediction  \nLabel: Neural Networks\n\nPaper id: 430\nTitle: Title: Irrelevant Features and the Subset Selection Problem  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 52\nTitle: Title: Theory Revision in Fault Hierarchies  \nLabel: Theory\n\nPaper id: 1617\nTitle: Title: Knowledge Discovery in International Conflict Databases  \nLabel: Case Based\n\nPaper id: 1207\nTitle: Title: Data Analyses Using Simulated Breeding and Inductive Learning Methods  \nLabel: Genetic Algorithms\n\nPaper id: 1637\nTitle: Title: The Effective Size of a Neural Network: A Principal Component Approach  \nLabel: Neural Networks\n\nPaper id: 1569\nTitle: Title: Estimating Attributes: Analysis and Extensions of RELIEF  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 16\nTitle: Title: Exploration in Active Learning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 552\nTitle: Title: Learning to Act using Real-Time Dynamic Programming  \nLabel: Reinforcement Learning\n\nPaper id: 1697\nTitle: Title: Neural Network Exploration Using Optimal Experiment Design  \nLabel: Neural Networks\n\nPaper id: 466\nTitle: Title: On the Computational Economics of Reinforcement Learning  \n\nPaper id: 566\nTitle: Title: Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 85\nTitle: Title: Q-Learning with Hidden-Unit Restarting  \nLabel: Reinforcement Learning\n\nPaper id: 1664\nTitle: Title: \"What is the best thing to do right now?\": getting beyond greedy exploration  \n\nPaper id: 311\nTitle: Title: June 1994 T o app ear in Neural Computation A Coun terexample to T emp\nLabel: Neural Networks\n\nPaper id: 2\nTitle: Title: Submitted to NIPS96, Section: Applications. Preference: Oral presentation Reinforcement Learning for Dynamic Channel Allocation in\nLabel: Reinforcement Learning\n\nPaper id: 455\nTitle: Title: Learning from an Automated Training Agent  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2300\nTitle: Title: Applying a Machine Learning Workbench: Experience with Agricultural Databases  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 479\nTitle: Title: Learning physical descriptions from functional definitions, examples, Learning from examples: The effect of different conceptual\nLabel: Case Based\n\nPaper id: 1337\nTitle: Title: MLC A Machine Learning Library in C  \nLabel: Theory\n\nPaper id: 2636\nTitle: Title: EMERALD: An Integrated System of Machine Learning and Discovery Programs to Support AI Education and\nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1627\nTitle: Title: Inductive Learning of Characteristic Concept Descriptions from Small Sets of Classified Examples  \nLabel: Rule Learning\n\nPaper id: 1335\nTitle: Title: A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection  \nLabel: Probabilistic Methods\n\nPaper id: 92\nTitle: Title: Learning Analytically and Inductively  \nLabel: Reinforcement Learning\n\nPaper id: 1020\nTitle: Title: Error-Based and Entropy-Based Discretization of Continuous Features  \n\nPaper id: 478\nTitle: Title: An Improved Algorithm for Incremental Induction of Decision Trees  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2207\nTitle: Title: Machine Learning Research: Four Current Directions  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1786\nTitle: Title: Decision Trees: Equivalence and Propositional Operations  \nLabel: Theory\n\nPaper id: 79\nTitle: Title: A hierarchical ensemble of decision trees applied to classifying data from a psychological experiment  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 438\nTitle: Title: A System for Induction of Oblique Decision Trees  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 391\nTitle: Title: Geometry in Learning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 230\nTitle: Title: Mathematical Programming in Neural Networks  \nLabel: Neural Networks\n\nPaper id: 1283\nTitle: Title: Bilinear Separation of Two Sets in n-Space  \nLabel: Neural Networks\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n\nPaper id: 142\nTitle: Title: PATTERN RECOGNITION VIA LINEAR PROGRAMMING THEORY AND APPLICATION TO MEDICAL DIAGNOSIS  \nLabel: Neural Networks\n\nPaper id: 438\nTitle: Title: A System for Induction of Oblique Decision Trees  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 146\nTitle: Title: Convergence-Zone Episodic Memory: Analysis and Simulations  \n\nPaper id: 698\nTitle: Title: Learning to Predict Reading Frames in E. coli DNA Sequences  \n\nPaper id: 296\nTitle: Title: Lookahead and Pathology in Decision Tree Induction  \nLabel: Theory\n\nPaper id: 18\nTitle: Title: Topography And Ocular Dominance: A Model Exploring Positive Correlations  \nLabel: Neural Networks\n\nPaper id: 1284\nTitle: Title: Feature Selection via Mathematical Programming  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 823\nTitle: Title: Misclassification Minimization  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 227\nTitle: Title: Induction of Oblique Decision Trees  \nLabel: Theory\n\nPaper id: 1283\nTitle: Title: Bilinear Separation of Two Sets in n-Space  \nLabel: Neural Networks\n\nPaper id: 142\nTitle: Title: PATTERN RECOGNITION VIA LINEAR PROGRAMMING THEORY AND APPLICATION TO MEDICAL DIAGNOSIS  \nLabel: Neural Networks\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 205\nTitle: Title: Beyond the Cognitive Map: Contributions to a Computational Neuroscience Theory of Rodent Navigation for the\nLabel: Neural Networks\n\nPaper id: 2388\nTitle: Title: Combining Neural Network Forecasts on Wavelet-Transformed Time Series  \nLabel: Neural Networks\n\nPaper id: 477\nTitle: Title: Forward models: Supervised learning with a distal teacher  \nLabel: Reinforcement Learning\n\nPaper id: 18\nTitle: Title: Topography And Ocular Dominance: A Model Exploring Positive Correlations  \nLabel: Neural Networks\n\nPaper id: 638\nTitle: Title: Learning a set of primitive actions with an Induction of decision trees. Machine Learning, 1(1):81-106,\nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 488\nTitle: Title: Prediction, Learning, Uniform Convergence, and Scale-sensitive Dimensions  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 549\nTitle: Title: Efficient Distribution-free Learning of Probabilistic Concepts  \nLabel: Theory\n\nPaper id: 2053\nTitle: Title: On the Complexity of Learning from Drifting Distributions  \nLabel: Theory\n\nPaper id: 109\nTitle: Title: A General Lower Bound on the Number of Examples Needed for Learning  \nLabel: Theory\n\nPaper id: 591\nTitle: Title: Toward Efficient Agnostic Learning  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 640\nTitle: Title: Learning in the Presence of Malicious Errors  \n\nPaper id: 1661\nTitle: Title: Simulating Access to Hidden Information while Learning  \n\nPaper id: 453\nTitle: Title: How to Use Expert Advice (Extended Abstract)  \nLabel: Theory\n\nPaper id: 1032\nTitle: Title: Algorithmic Stability and Sanity-Check Bounds for Leave-One-Out Cross-Validation  \nLabel: Theory\n\nPaper id: 1074\nTitle: Title: Inductive Logic Programming  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1154\nTitle: Title: Case-Based Learning: Beyond Classification of Feature Vectors  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1531\nTitle: Title: NACODAE: Navy Conversational Decision Aids Environment  \n\nPaper id: 819\nTitle: Title: A Case Study of Case-Based CBR  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 817\nTitle: Title: Case-Based Similarity Assessment: Estimating Adaptability from Experience  \nLabel: Case Based\n\nPaper id: 818\nTitle: Title: Learning to Integrate Multiple Knowledge Sources for Case-Based Reasoning  \nLabel: Case Based\n\nPaper id: 983\nTitle: Title: Refining Conversational Case Libraries  \nLabel: Case Based\n\nPaper id: 1215\nTitle: Title: Supporting Combined Human and Machine Planning: An Interface for Planning by Analogical Reasoning  \n\nPaper id: 887\nTitle: Title: Simplifying Decision Trees: A Survey  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1180\nTitle: Title: Efficient Algorithms for -Subsumption  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1620\nTitle: Title: Efficient -Subsumption based on Graph Algorithms  \nLabel: Rule Learning\n\nPaper id: 1177\nTitle: Title: An Efficient Subsumption Algorithm for Inductive Logic Programming  \nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1519\nTitle: Title: What online Machine Learning can do for Knowledge Acquisition A Case Study  \n\nPaper id: 1627\nTitle: Title: Inductive Learning of Characteristic Concept Descriptions from Small Sets of Classified Examples  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1969\nTitle: Title: Generalization and scaling in reinforcement learning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2200\nTitle: Title: Adaptation in constant utility non-stationary environments  \n\nPaper id: 2363\nTitle: Title: Modeling the Evolution of Motivation  \n\nPaper id: 2051\nTitle: Title: Emergent Control and Planning in an Autonomous Vehicle  \nLabel: Reinforcement Learning\n\nPaper id: 2309\nTitle: Title: EVOLVING SENSORS IN ENVIRONMENTS OF CONTROLLED COMPLEXITY  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 538\nTitle: Title: Learning and evolution in neural networks  \nLabel: Genetic Algorithms\n\nPaper id: 2703\nTitle: Title: learning easier tasks. More work is necessary in order to determine more precisely the relationship\nLabel: Genetic Algorithms\n\nPaper id: 129\nTitle: Title: Evolving Networks: Using the Genetic Algorithm with Connectionist Learning  \nLabel: Genetic Algorithms\n\nPaper id: 2165\nTitle: Title: Auto-teaching: networks that develop their own teaching input  \nLabel: Genetic Algorithms\n\nPaper id: 1325\nTitle: Title: Environmental Effects on Minimal Behaviors in the Minimat World  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2513\nTitle: Title: Avoiding overfitting by locally matching the noise level of the data gating network discovers the\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 310\nTitle: Title: Forecasting electricity demand using nonlinear mixture of experts  \nLabel: Neural Networks\n\nPaper id: 2374\nTitle: Title: Predictions with Confidence Intervals (Local Error Bars)  \nLabel: Neural Networks\n\nPaper id: 1366\nTitle: Title: ``Learning Local Error Bars for Nonlinear Regression.''  Learning Local Error Bars for Nonlinear Regression  \nLabel: Neural Networks\n\nPaper id: 74\nTitle: Title: Hierarchical Mixtures of Experts and the EM Algorithm  \nLabel: Probabilistic Methods\n\nPaper id: 2239\nTitle: Title: Predicting Conditional Probability Distributions: A Connectionist Approach  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 19\nTitle: Title: Validation of Average Error Rate Over Classifiers  \n\nPaper id: 263\nTitle: Title: Non-linear Models for Time Series Using Mixtures of Experts  \nLabel: Neural Networks\n\nPaper id: 2124\nTitle: Title: A Hierarchical Latent Variable Model for Data Visualization  \nLabel: Neural Networks\n\nPaper id: 2507\nTitle: Title: The Observer-Observation Dilemma in Neuro-Forecasting: Reliable Models From Unreliable Data Through CLEARNING  \n\nPaper id: 622\nTitle: Title: CLASSIFICATION USING HIERARCHICAL MIXTURES OF EXPERTS  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 512\nTitle: Title: Fault-Tolerant Implementation of Finite-State Automata in Recurrent Neural Networks  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 411\nTitle: Title: POWER OF NEURAL NETS  \nLabel: Neural Networks\n\nPaper id: 407\nTitle: Title: Constructing Deterministic Finite-State Automata in Recurrent Neural Networks  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1875\nTitle: Title: On the Effect of Analog Noise in Discrete-Time Analog Computations  \nLabel: Theory\n\nPaper id: 536\nTitle: Title: Dimension of Recurrent Neural Networks  \nLabel: Neural Networks\n\nPaper id: 2582\nTitle: Title: Noisy Time Series Prediction using Symbolic Representation and Recurrent Neural Network Grammatical Inference  \nLabel: Neural Networks\n\nPaper id: 2594\nTitle: Title: Can Recurrent Neural Networks Learn Natural Language Grammars? W&Z recurrent neural networks are able to\nLabel: Neural Networks\n\nPaper id: 1470\nTitle: Title: Interconnected Automata and Linear Systems: A Theoretical Framework in Discrete-Time In Hybrid Systems III: Verification\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1115\nTitle: Title: The locally linear Nested Network for robot manipulation  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1252\nTitle: Title: Constructive Training Methods for Feedforward Neural Networks with Binary Weights  \nLabel: Neural Networks\n\nPaper id: 820\nTitle: Title: NESTED NETWORKS FOR ROBOT CONTROL  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1634\nTitle: Title: Combining Linear Discriminant Functions with Neural Networks for Supervised Learning  \n\nPaper id: 830\nTitle: Title: Orthogonal incremental learning of a feedforward network  \n\nPaper id: 1477\nTitle: Title: Two Constructive Methods for Designing Compact Feedforward Networks of Threshold Units  \nLabel: Neural Networks\n\nPaper id: 829\nTitle: Title: Approximation with neural networks: Between local and global approximation  \nLabel: Neural Networks\n\nPaper id: 1485\nTitle: Title: Maximizing the Robustness of a Linear Threshold Classifier with Discrete Weights  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 216\nTitle: Title: d d Code Scheduling for Multiple Instruction Stream Architectures  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 735\nTitle: Title: The Limits of Instruction Level Parallelism in SPEC95 Applications  \nLabel: Rule Learning\n\nPaper id: 196\nTitle: Title: d d MISC: A Multiple Instruction Stream Computer  \nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2649\nTitle: Title: Limits of Control Flow on Parallelism  \nLabel: Rule Learning\n\nPaper id: 195\nTitle: Title: d d Techniques for Extracting Instruction Level Parallelism on MIMD Architectures  \nLabel: Rule Learning\n\nPaper id: 2106\nTitle: Title: Theoretical Modeling of Superscalar Processor Performance  \nLabel: Rule Learning\n\nPaper id: 86\nTitle: Title: THE EXPANDABLE SPLIT WINDOW PARADIGM FOR EXPLOITING FINE-GRAIN PARALLELISM  \nLabel: Rule Learning\n\nPaper id: 2527\nTitle: Title: 248 Efficient Superscalar Performance Through Boosting  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2647\nTitle: Title: Using Local Trajectory Optimizers To Speed Up Global Optimization In Dynamic Programming  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2658\nTitle: Title: Control Systems Magazine, 14, 1, pp.57-71. Robot Juggling: An Implementation of Memory-based Learning  \n\nPaper id: 2430\nTitle: Title: Category: Control, Navigation and Planning Preference: Oral presentation Exploiting Model Uncertainty Estimates for Safe Dynamic\nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1559\nTitle: Title: In  Active Learning with Statistical Models  \nLabel: Neural Networks\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n\nPaper id: 691\nTitle: Title: Reinforcement Learning in the Multi-Robot Domain  \nLabel: Reinforcement Learning\n\nPaper id: 294\nTitle: Title: References elements that can solve difficult learning control problems. on Simulation of Adaptive Behavior, pages\nLabel: Reinforcement Learning\n\nPaper id: 1860\nTitle: Title: Efficient Locally Weighted Polynomial Regression Predictions  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2690\nTitle: Title: Robust Trainability of Single Neurons  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2053\nTitle: Title: On the Complexity of Learning from Drifting Distributions  \nLabel: Theory\n\nPaper id: 591\nTitle: Title: Toward Efficient Agnostic Learning  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 109\nTitle: Title: A General Lower Bound on the Number of Examples Needed for Learning  \nLabel: Theory\n\nPaper id: 199\nTitle: Title: On Learning Conjunctions with Malicious Noise  \nLabel: Theory\n\nPaper id: 848\nTitle: Title: An Experimental and Theoretical Comparison of Model Selection Methods on simple model selection problems, the\nLabel: Theory\n\nPaper id: 549\nTitle: Title: Efficient Distribution-free Learning of Probabilistic Concepts  \nLabel: Theory\n\nPaper id: 453\nTitle: Title: How to Use Expert Advice (Extended Abstract)  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1648\nTitle: Title: Creative Design: Reasoning and Understanding  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1355\nTitle: Title: Modeling Invention by Analogy in ACT-R  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1047\nTitle: Title: GIT-CC-92/60 A Model-Based Approach to Analogical Reasoning and Learning in Design  \nLabel: Case Based\n\nPaper id: 1148\nTitle: Title: Opportunistic Reasoning: A Design Perspective  \n\nPaper id: 1640\nTitle: Title: KRITIK: AN EARLY CASE-BASED DESIGN SYSTEM  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 804\nTitle: Title: Exploration Bonuses and Dual Control  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1585\nTitle: Title: Q-Learning for Bandit Problems  \n\nPaper id: 1697\nTitle: Title: Neural Network Exploration Using Optimal Experiment Design  \nLabel: Neural Networks\n\nPaper id: 1459\nTitle: Title: Generalized Markov Decision Processes: Dynamic-programming and Reinforcement-learning Algorithms  \nLabel: Reinforcement Learning\n\nPaper id: 1664\nTitle: Title: \"What is the best thing to do right now?\": getting beyond greedy exploration  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 633\nTitle: Title: Chapter 1 Reinforcement Learning for Planning and Control  \n\nPaper id: 1540\nTitle: Title: MultiPlayer Residual Advantage Learning With General Function Approximation  \n\nPaper id: 16\nTitle: Title: Exploration in Active Learning  \n\nPaper id: 2221\nTitle: Title: Reasoning about Time and Probability  \nLabel: Probabilistic Methods\n\nPaper id: 740\nTitle: Title: Information-based objective functions for active data selection  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 920\nTitle: Title: Maximum likelihood source separation for discrete sources  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1520\nTitle: Title: Equivariant adaptive source separation  \n\nPaper id: 873\nTitle: Title: On the performance of orthogonal source separation algorithms  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 59\nTitle: Title: SELF-ADAPTIVE NEURAL NETWORKS FOR BLIND SEPARATION OF SOURCES  \nLabel: Neural Networks\n\nPaper id: 354\nTitle: Title: Principal and Independent Components in Neural Networks Recent Developments  \nLabel: Neural Networks\n\nPaper id: 872\nTitle: Title: A Blind Identification and Separation Technique via Multi-layer Neural Networks  \n\nPaper id: 1526\nTitle: Title: Working Paper IS-97-22 (Information Systems) A First Application of Independent Component Analysis to Extracting Structure\nLabel: Neural Networks\n\nPaper id: 1524\nTitle: Title: BLIND SEPARATION OF DELAYED SOURCES BASED ON INFORMATION MAXIMIZATION  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 356\nTitle: Title: A Flexible Model For Human Circadian Rhythms  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 190\nTitle: Title: Spline Smoothing For Bivariate Data With Applications To Association Between Hormones  \n\nPaper id: 510\nTitle: Title: The Bayesian Approach to Tree-Structured Regression  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 192\nTitle: Title: Smoothing Spline ANOVA with Component-Wise Bayesian \"Confidence Intervals\" To Appear, J. Computational and Graphical Statistics  \nLabel: Neural Networks\n\nPaper id: 2223\nTitle: Title: Smoothing Spline Models With Correlated Random Errors 1  \nLabel: Neural Networks\n\nPaper id: 519\nTitle: Title: Smoothing Spline ANOVA for Exponential Families, with Application to the Wisconsin Epidemiological Study of Diabetic\nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 608\nTitle: Title: Regularization Theory and Neural Networks Architectures  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 133\nTitle: Title: PRIOR KNOWLEDGE AND THE CREATION OF \"VIRTUAL\" EXAMPLES FOR RBF NETWORKS 1  \nLabel: Neural Networks\n\nPaper id: 179\nTitle: Title: for Projective Basis Function Networks 2m1 Global Form 2m Local Form With appropriate constant factors,\nLabel: Neural Networks\n\nPaper id: 975\nTitle: Title: State Reconstruction for Determining Predictability in Driven Nonlinear Acoustical Systems  \n\nPaper id: 394\nTitle: Title: Prior Information and Generalized Questions  \nLabel: Neural Networks\n\nPaper id: 680\nTitle: Title: Cortical Mechanisms of Visual Recognition and Learning: A Hierarchical Kalman Filter Model  \nLabel: Neural Networks\n\nPaper id: 611\nTitle: Title: Learning networks for face analysis and synthesis  \nLabel: Neural Networks\n\nPaper id: 2230\nTitle: Title: In Advances in Neural Information Processing Systems 8  Gaussian Processes for Regression  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 633\nTitle: Title: Chapter 1 Reinforcement Learning for Planning and Control  \n\nPaper id: 2501\nTitle: Title: EMRBF: A Statistical Basis for Using Radial Basis Functions for Process Control  \nLabel: Neural Networks\n\nPaper id: 2540\nTitle: Title: Efficient Implementation of Gaussian Processes  \nLabel: Neural Networks\n\nPaper id: 2385\nTitle: Title: Receptive Fields for Vision: from Hyperacuity to Object Recognition  \n\nPaper id: 719\nTitle: Title: Parzen. On estimation of a probability density function and mode. Annual Mathematical Statistics, 33:1065-1076, 1962.\nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 971\nTitle: Title: Decision-Theoretic Foundations for Causal Reasoning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1527\nTitle: Title: A THEORY OF INFERRED CAUSATION perceive causal relationships in uncon trolled observations. 2. the task\n\nPaper id: 2166\nTitle: Title: Probabilistic evaluation of counterfactual queries  \nLabel: Probabilistic Methods\n\nPaper id: 1326\nTitle: Title: Causal diagrams for empirical research  \nLabel: Probabilistic Methods\n\nPaper id: 1602\nTitle: Title: Defining Explanation in Probabilistic Systems  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 827\nTitle: Title: Two Algorithms for Inducing Structural Equation Models from Data  \nLabel: Probabilistic Methods\n\nPaper id: 1549\nTitle: Title: Explaining Predictions in Bayesian Networks and Influence Diagrams  \nLabel: Probabilistic Methods\n\nPaper id: 909\nTitle: Title: Regression Can Build Predictive Causal Models  \nLabel: Probabilistic Methods\n\nPaper id: 2221\nTitle: Title: Reasoning about Time and Probability  \nLabel: Probabilistic Methods\n\nPaper id: 105\nTitle: Title: The New Challenge: From a Century of Statistics to an Age of Causation  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1296\nTitle: Title: Sifting informative examples from a random source.  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 109\nTitle: Title: A General Lower Bound on the Number of Examples Needed for Learning  \nLabel: Theory\n\nPaper id: 456\nTitle: Title: Boosting a weak learning algorithm by majority To be published in Information and Computation  \nLabel: Theory\n\nPaper id: 1198\nTitle: Title: Query by Committee  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 884\nTitle: Title: PAC Learning of One-Dimensional Patterns  \n\nPaper id: 1170\nTitle: Title: Selective sampling using the Query by Committee algorithm Running title: Selective sampling using Query by Committee  \nLabel: Theory\n\nPaper id: 2099\nTitle: Title: Game Theory, On-line Prediction and Boosting  \nLabel: Theory\n\nPaper id: 2054\nTitle: Title: Tracking Drifting Concepts By Minimizing Disagreements  \nLabel: Theory\n\nPaper id: 549\nTitle: Title: Efficient Distribution-free Learning of Probabilistic Concepts  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 459\nTitle: Title: Pac Learning, Noise, and Geometry  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 130\nTitle: Title: PAC-Learning PROLOG clauses with or without errors  \n\nPaper id: 1705\nTitle: Title: Learning from Incomplete Boundary Queries Using Split Graphs and Hypergraphs (Extended Abstract)  \n\nPaper id: 267\nTitle: Title: On Learning from Noisy and Incomplete Examples  \nLabel: Theory\n\nPaper id: 109\nTitle: Title: A General Lower Bound on the Number of Examples Needed for Learning  \nLabel: Theory\n\nPaper id: 640\nTitle: Title: Learning in the Presence of Malicious Errors  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1296\nTitle: Title: Sifting informative examples from a random source.  \n\nPaper id: 955\nTitle: Title: Separating Formal Bounds from Practical Performance in Learning Systems  \n\nPaper id: 884\nTitle: Title: PAC Learning of One-Dimensional Patterns  \n\nPaper id: 2053\nTitle: Title: On the Complexity of Learning from Drifting Distributions  \nLabel: Theory\n\nPaper id: 334\nTitle: Title: Improved Noise-Tolerant Learning and Generalized Statistical Queries  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2449\nTitle: Title: Learning by Refining Algorithm Sketches  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1881\nTitle: Title: Integrity Constraints in ILP using a Monte Carlo approach  \n\nPaper id: 2158\nTitle: Title: Learning Recursion with Iterative Bootstrap Induction (Extended Abstract)  \nLabel: Rule Learning\n\nPaper id: 2450\nTitle: Title: Architecture for Iterative Learning of Recursive Definitions  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1498\nTitle: Title: INFERENTIAL THEORY OF LEARNING: Developing Foundations for Multistrategy Learning  \nLabel: Case Based\n\nPaper id: 344\nTitle: Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In\nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1227\nTitle: Title: What should be minimized in a decision tree: A re-examination  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1236\nTitle: Title: Exploring the Decision Forest: An Empirical Investigation of Occam's Razor in Decision Tree Induction  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 382\nTitle: Title: Learning Decision Lists Using Homogeneous Rules  \nLabel: Theory\n\nPaper id: 1669\nTitle: Title: Bias and the Quantification of Stability Bias and the Quantification of Stability Bias and the\nLabel: Theory\n\nPaper id: 296\nTitle: Title: Lookahead and Pathology in Decision Tree Induction  \nLabel: Theory\n\nPaper id: 861\nTitle: Title: In Defense of C4.5: Notes on Learning One-Level Decision Trees  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2047\nTitle: Title: Evolutionary wanderlust: Sexual selection with directional mate preferences.  Evolutionary wanderlust: Sexual selection with directional mate preferences  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2111\nTitle: Title: Artificial Life as Theoretical Biology: How to do real science with computer simulation  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2302\nTitle: Title: Genes, Phenes and the Baldwin Effect: Learning and Evolution in a Simulated Population  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1570\nTitle: Title: Average-Case Analysis of a Nearest Neighbor Algorithm  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 634\nTitle: Title: Oblivious Decision Trees and Abstract Cases  \nLabel: Case Based\n\nPaper id: 1109\nTitle: Title: Inductive Bias in Case-Based Reasoning Systems  \nLabel: Theory\n\nPaper id: 1678\nTitle: Title: Induction of One-Level Decision Trees  \n\nPaper id: 1111\nTitle: Title: Towards a Better Understanding of Memory-Based Reasoning Systems  \nLabel: Case Based\n\nPaper id: 1339\nTitle: Title: An Analysis of Bayesian Classifiers (1988), involves the formulation of average-case models for specific algorithms\nLabel: Theory\n\nPaper id: 1164\nTitle: Title: PAC Analyses of a `Similarity Learning' IBL Algorithm  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1101\nTitle: Title: On Reasoning from Data  \nLabel: Case Based\n\nPaper id: 2292\nTitle: Title: Logarithmic-Time Updates and Queries in Probabilistic Networks  \nLabel: Probabilistic Methods\n\nPaper id: 256\nTitle: Title: Using Decision Trees to Improve Case-Based Learning  \nLabel: Case Based\n\nPaper id: 2677\nTitle: Title: Mining and Model Simplicity: A Case Study in Diagnosis  \nLabel: Probabilistic Methods\n\nPaper id: 1412\nTitle: Title: EXPLORING A FRAMEWORK FOR INSTANCE BASED LEARNING AND NAIVE BAYESIAN CLASSIFIERS  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 996\nTitle: Title: Reparameterisation Issues in Mixture Modelling and their bearing on MCMC algorithms  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1015\nTitle: Title: Bayesian curve fitting using multivariate normal mixtures  \n\nPaper id: 161\nTitle: Title: On Bayesian analysis of mixtures with an unknown number of components  Summary  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1147\nTitle: Title: Decomposable graphical Gaussian model determination  \n\nPaper id: 95\nTitle: Title: Bayesian Detection of Clusters and Discontinuities in Disease Maps  \n\nPaper id: 759\nTitle: Title: BAYESIAN STATISTICS 6, pp. 000--000  Exact sampling for Bayesian inference: towards general purpose algorithms  \nLabel: Probabilistic Methods\n\nPaper id: 713\nTitle: Title: FLEXIBLE PARAMETRIC MEASUREMENT ERROR MODELS  \n\nPaper id: 684\nTitle: Title: Finding Overlapping Distributions with MML  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1516\nTitle: Title: Solving 3-SAT by GAs Adapting Constraint Weights  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 833\nTitle: Title: Graph Coloring with Adaptive Evolutionary Algorithms  \n\nPaper id: 1136\nTitle: Title: Using Neural Networks and Genetic Algorithms as Heuristics for NP-Complete Problems  \n\nPaper id: 1218\nTitle: Title: Genetic algorithms with multi-parent recombination  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 145\nTitle: Title: LIBGA: A USER-FRIENDLY WORKBENCH FOR ORDER-BASED GENETIC ALGORITHM RESEARCH  \nLabel: Genetic Algorithms\n\nPaper id: 935\nTitle: Title: Complexity Compression and Evolution  \nLabel: Genetic Algorithms\n\nPaper id: 1594\nTitle: Title: An Evolutionary Approach to Vector Quantizer Design  \nLabel: Genetic Algorithms\n\nPaper id: 1299\nTitle: Title: Multi-parent Recombination  \nLabel: Genetic Algorithms\n\nPaper id: 1575\nTitle: Title: A Comparative Study of Genetic Search  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2335\nTitle: Title: Function Approximation with Neural Networks and Local Methods: Bias, Variance and Smoothness  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2378\nTitle: Title: Priors, Stabilizers and Basis Functions: from regularization to radial, tensor and additive splines  \nLabel: Neural Networks\n\nPaper id: 74\nTitle: Title: Hierarchical Mixtures of Experts and the EM Algorithm  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2284\nTitle: Title: Performance of On-Line Learning Methods in Predicting Multiprocessor Memory Access Patterns  \nLabel: Neural Networks\n\nPaper id: 987\nTitle: Title: Stacked Density Estimation  \nLabel: Probabilistic Methods\n\nPaper id: 1017\nTitle: Title: Using Neural Networks for Descriptive Statistical Analysis of Educational Data  \nLabel: Neural Networks\n\nPaper id: 2266\nTitle: Title: A Gentle Tutorial of the EM Algorithm and its Application to Parameter Estimation for Gaussian\nLabel: Probabilistic Methods\n\nPaper id: 2050\nTitle: Title: TABLE DES MATI ERES 1 Apprentissage et approximation les techniques de regularisation 3 1.1 Introduction\nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 264\nTitle: Title: On Learning More Concepts  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 638\nTitle: Title: Learning a set of primitive actions with an Induction of decision trees. Machine Learning, 1(1):81-106,\nLabel: Theory\n\nPaper id: 635\nTitle: Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 375\nTitle: Title: Constructive Induction Using a Non-Greedy Strategy for Feature Selection  \nLabel: Theory\n\nPaper id: 294\nTitle: Title: References elements that can solve difficult learning control problems. on Simulation of Adaptive Behavior, pages\nLabel: Reinforcement Learning\n\nPaper id: 89\nTitle: Title: NP-Completeness of Searches for Smallest Possible Feature Sets a subset of the set of all\n\nPaper id: 2171\nTitle: Title: K unstliche Intelligenz Grdt: Enhancing Model-Based Learning for Its Application in Robot Navigation  \nLabel: Rule Learning\n\nPaper id: 227\nTitle: Title: Induction of Oblique Decision Trees  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 130\nTitle: Title: PAC-Learning PROLOG clauses with or without errors  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 459\nTitle: Title: Pac Learning, Noise, and Geometry  \n\nPaper id: 640\nTitle: Title: Learning in the Presence of Malicious Errors  \n\nPaper id: 672\nTitle: Title: Cryptographic Limitations on Learning Boolean Formulae and Finite Automata  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2696\nTitle: Title: Learning DFA from Simple Examples  \nLabel: Theory\n\nPaper id: 1293\nTitle: Title: Using Recurrent Neural Networks to Learn the Structure of Interconnection Networks  \nLabel: Neural Networks\n\nPaper id: 2329\nTitle: Title: Programming Research Group A LEARNABILITY MODEL FOR UNIVERSAL REPRESENTATIONS  \nLabel: Theory\n\nPaper id: 1363\nTitle: Title: Exact Identification of Read-once Formulas Using Fixed Points of Amplification Functions  \n\nPaper id: 574\nTitle: Title: On the Learnability of Discrete Distributions (extended abstract)  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2586\nTitle: Title: Learning One More Thing  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1889\nTitle: Title: The Functional Transfer of Knowledge for Coronary Artery Disease Diagnosis  \nLabel: Neural Networks\n\nPaper id: 2486\nTitle: Title: The Canonical Distortion Measure for Vector Quantization and Function Approximation  \nLabel: Neural Networks\n\nPaper id: 2113\nTitle: Title: Learning Model Bias minimum number of examples requred to learn a single task, and O(a\nLabel: Theory\n\nPaper id: 1647\nTitle: Title: Recognition and Exploitation of Contextual Clues via Incremental Meta-Learning (Extended Version)  \nLabel: Theory\n\nPaper id: 2162\nTitle: Title: Incremental Class Learning approach and its application to Handwritten Digit Recognition  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2599\nTitle: Title: Recognizing Handwritten Digit Strings Using Modular Spatio-temporal Connectionist Networks  \nLabel: Neural Networks\n\nPaper id: 1908\nTitle: Title: Induction of Selective Bayesian Classifiers  \nLabel: Probabilistic Methods\n\nPaper id: 2648\nTitle: Title: The Task Rehearsal Method of Sequential Learning  \n\nPaper id: 1684\nTitle: Title: Context-sensitive attribute estimation in regression  \nLabel: Rule Learning\n\nPaper id: 730\nTitle: Title: Learning Sequential Tasks by Incrementally Adding Higher Orders  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1630\nTitle: Title: Averaging and Data Snooping  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1150\nTitle: Title: Lessons in Neural Network Training: Overfitting Lessons in Neural Network Training: Overfitting May be Harder\n\nPaper id: 1195\nTitle: Title: Statistical Evaluation of Neural Network Experiments: Minimum Requirements and Current Practice  \nLabel: Neural Networks\n\nPaper id: 1203\nTitle: Title: A Quantitative Study of Experimental Evaluations of Neural Network Learning Algorithms: Current Research Practice  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 881\nTitle: Title: Proben1 A Set of Neural Network Benchmark Problems and Benchmarking Rules  \nLabel: Neural Networks\n\nPaper id: 1323\nTitle: Title: On the Distribution of Performance from Multiple Neural Network Trials, On the Distribution of Performance\nLabel: Neural Networks\n\nPaper id: 542\nTitle: Title: Comparison of Bayesian and Neural Net Unsupervised Classification Techniques  \nLabel: Neural Networks\n\nPaper id: 1411\nTitle: Title: Connection Pruning with Static and Adaptive Pruning Schedules  \nLabel: Neural Networks\n\nPaper id: 1119\nTitle: Title: Adaptive Parameter Pruning in Neural Networks  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1434\nTitle: Title: Advantages of Decision Lists and Implicit Negatives in Inductive Logic Programming  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1208\nTitle: Title: An Experimental Comparison of Genetic Programming and Inductive Logic Programming on Learning Recursive List Functions  \nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1429\nTitle: Title: Learning First-Order Definitions of Functions  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 850\nTitle: Title: COMPUTING DISTRIBUTIONS OF ORDER STATISTICS  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 917\nTitle: Title: Practical Bayesian Inference Using Mixtures of Mixtures  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 784\nTitle: Title: Studies of Neurological Transmission Analysis using Hierarchical Bayesian Mixture Models  \n\nPaper id: 1338\nTitle: Title: Computing Nonparametric Hierarchical Models  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2517\nTitle: Title: Solving the Temporal Binding Problem: A Neural Theory for Constructing and Updating Object Files  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2533\nTitle: Title: An Object-Based Neural Model of Serial Processing in Visual Multielement Tracking  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 180\nTitle: Title: REDUCED MEMORY REPRESENTATIONS FOR MUSIC  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 350\nTitle: Title: Induction of Multiscale Temporal Structure  \nLabel: Neural Networks\n\nPaper id: 143\nTitle: Title: RESONANCE AND THE PERCEPTION OF MUSICAL METER  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 363\nTitle: Title: Representing Rhythmic Patterns in a Network of Oscillators  \nLabel: Neural Networks\n\nPaper id: 111\nTitle: Title: Tau Net: A Neural Network for Modeling Temporal Variability  \nLabel: Neural Networks\n\nPaper id: 770\nTitle: Title: A Connectionist Symbol Manipulator That Discovers the Structure of Context-Free Languages  \nLabel: Neural Networks\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n\nPaper id: 337\nTitle: Title: Meter as Mechanism: A Neural Network that Learns Metrical Patterns  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2393\nTitle: Title: Coordination and Control Structures and Processes: Possibilities for Connectionist Networks (CN)  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 496\nTitle: Title: BRAINSTRUCTURED CONNECTIONIST NETWORKS THAT PERCEIVE AND LEARN  \n\nPaper id: 663\nTitle: Title: Perceptual Development and Learning: From Behavioral, Neurophysiological, and Morphological Evidence To Computational Models  \n\nPaper id: 2029\nTitle: Title: A Simple Randomized Quantization Algorithm for Neural Network Pattern Classifiers  \nLabel: Neural Networks\n\nPaper id: 1813\nTitle: Title: Pruning Strategies for the MTiling Constructive Learning Algorithm  \nLabel: Neural Networks\n\nPaper id: 1952\nTitle: Title: Analysis of Decision Boundaries Generated by Constructive Neural Network Learning Algorithms  \nLabel: Neural Networks\n\nPaper id: 1896\nTitle: Title: Experiments with the Cascade-Correlation Algorithm  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1818\nTitle: Title: Constructive Neural Network Learning Algorithms for Multi-Category Real-Valued Pattern Classification  \nLabel: Neural Networks\n\nPaper id: 501\nTitle: Title: Some Biases for Efficient Learning of Spatial, Temporal, and Spatio-Temporal Patterns  \nLabel: Neural Networks\n\nPaper id: 2396\nTitle: Title: Properties of Genetic Representations of Neural Architectures  \nLabel: Genetic Algorithms\n\nPaper id: 503\nTitle: Title: Generative Learning Structures and Processes for Generalized Connectionist Networks  \nLabel: Neural Networks\n\nPaper id: 1851\nTitle: Title: Faster Learning in Multi-Layer Networks by Handling  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2641\nTitle: Title: Toward Simulated Evolution of Machine-Language Iteration  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1745\nTitle: Title: Learning Recursive Sequences via Evolution of Machine-Language Programs  \nLabel: Genetic Algorithms\n\nPaper id: 380\nTitle: Title: Fitness Landscapes and Difficulty in Genetic Programming  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1474\nTitle: Title: Incremental Co-evolution of Organisms: A New Approach for Optimization and Discovery of Strategies  \nLabel: Genetic Algorithms\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 2196\nTitle: Title: Effects of Occam's Razor in Evolving Sigma-Pi Neural Nets  \nLabel: Genetic Algorithms\n\nPaper id: 1737\nTitle: Title: A Simulation of Adaptive Agents in a Hostile Environment  \nLabel: Genetic Algorithms\n\nPaper id: 934\nTitle: Title: Complexity Compression and Evolution  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1291\nTitle: Title: Bits-back coding software guide  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1548\nTitle: Title: Free energy coding  In  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1374\nTitle: Title: A simple algorithm that discovers efficient perceptual codes  \nLabel: Neural Networks\n\nPaper id: 76\nTitle: Title: A VIEW OF THE EM ALGORITHM THAT JUSTIFIES INCREMENTAL, SPARSE, AND OTHER VARIANTS  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 293\nTitle: Title: Independent Component Analysis of Electroencephalographic Data  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 576\nTitle: Title: An information-maximisation approach to blind separation and blind deconvolution  \nLabel: Neural Networks\n\nPaper id: 387\nTitle: Title: JUNG ET AL.: ESTIMATING ALERTNESS FORM THE EEG POWER SPECTRUM 1 Estimating Alertness from the\nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2026\nTitle: Title: Learning overcomplete representations  \nLabel: Neural Networks\n\nPaper id: 1067\nTitle: Title: A Fast Fixed-Point Algorithm for Independent Component Analysis  \nLabel: Neural Networks\n\nPaper id: 1801\nTitle: Title: A FAMILY OF FIXED-POINT ALGORITHMS FOR INDEPENDENT COMPONENT ANALYSIS  \nLabel: Neural Networks\n\nPaper id: 1245\nTitle: Title: Blind separation of delayed and convolved sources.  \nLabel: Neural Networks\n\nPaper id: 726\nTitle: Title: Natural image statistics and efficient coding  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 201\nTitle: Title: Neural net architectures for temporal sequence processing  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 350\nTitle: Title: Induction of Multiscale Temporal Structure  \nLabel: Neural Networks\n\nPaper id: 1990\nTitle: Title: A FIXED SIZE STORAGE O(n 3 TIME COMPLEXITY LEARNING ALGORITHM FOR FULLY RECURRENT CONTINUALLY RUNNING\nLabel: Neural Networks\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n\nPaper id: 143\nTitle: Title: RESONANCE AND THE PERCEPTION OF MUSICAL METER  \n\nPaper id: 1718\nTitle: Title: PREDICTING SUNSPOTS AND EXCHANGE RATES WITH CONNECTIONIST NETWORKS  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2413\nTitle: Title: On-Line Adaptation of a Signal Predistorter through Dual Reinforcement Learning  \nLabel: Neural Networks\n\nPaper id: 18\nTitle: Title: Topography And Ocular Dominance: A Model Exploring Positive Correlations  \nLabel: Neural Networks\n\nPaper id: 526\nTitle: Title: MML mixture modelling of multi-state, Poisson, von Mises circular and Gaussian distributions  \nLabel: Neural Networks\n\nPaper id: 461\nTitle: Title: Product Unit Learning constructive algorithm is then introduced which adds product units to a network\nLabel: Neural Networks\n\nPaper id: 304\nTitle: Title: Boltzmann Machine learning using mean field theory and linear response correction  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 268\nTitle: Title: Finding Genes in DNA with a Hidden Markov Model  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 14\nTitle: Title: Hidden Markov Models in Computational Biology: Applications to Protein Modeling UCSC-CRL-93-32 Keywords: Hidden Markov Models,\nLabel: Neural Networks\n\nPaper id: 232\nTitle: Title: Stochastic Decomposition of DNA Sequences Using Hidden Markov Models  \nLabel: Neural Networks\n\nPaper id: 2046\nTitle: Title: A Method for Identifying Splice Sites and Translational Start Sites in  \nLabel: Neural Networks\n\nPaper id: 258\nTitle: Title: Using Dirichlet Mixture Priors to Derive Hidden Markov Models for Protein Families  \nLabel: Neural Networks\n\nPaper id: 616\nTitle: Title: A Decision Tree System for Finding Genes in DNA  \n\nPaper id: 613\nTitle: Title: A Generalized Hidden Markov Model for the Recognition of Human Genes in DNA  \nLabel: Neural Networks\n\nPaper id: 2571\nTitle: Title: Non-Deterministic, Constraint-Based Parsing of Human Genes  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 438\nTitle: Title: A System for Induction of Oblique Decision Trees  \nLabel: Theory\n\nPaper id: 437\nTitle: Title: A Gentle Guide to Multiple Alignment Version Please send comments, critique, flames and praise Instructions\nLabel: Neural Networks\n\nPaper id: 242\nTitle: Title: Learning Markov chains with variable memory length from noisy output  \nLabel: Theory\n\nPaper id: 751\nTitle: Title: Dirichlet Mixtures: A Method for Improving Detection of Weak but Significant Protein Sequence Homology  \nLabel: Neural Networks\n\nPaper id: 384\nTitle: Title: Hidden Markov Model Analysis of Motifs in Steroid Dehydrogenases and their Homologs  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2143\nTitle: Title: MULTIPLE SCALES OF BRAIN-MIND INTERACTIONS  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2181\nTitle: Title: Statistical mechanics of neocortical interactions: Training and testing canonical momenta indicators of EEG  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1793\nTitle: Title: STATISTICAL MECHANICS OF COMBAT WITH HUMAN FACTORS  \nLabel: Neural Networks\n\nPaper id: 2178\nTitle: Title: Statistical Mechanics of Nonlinear Nonequilibrium Financial Markets: Applications to Optimized Trading  \nLabel: Neural Networks\n\nPaper id: 1788\nTitle: Title: Path-integral evolution of chaos embedded in noise: Duffing neocortical analog  \nLabel: Neural Networks\n\nPaper id: 1795\nTitle: Title: Application of statistical mechanics methodol- ogy to term-structure bond-pricing models, Mathl. Comput. Modelling Application of\nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 779\nTitle: Title: Monte Carlo Comparison of Non-hierarchical Unsupervised Classifiers  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 638\nTitle: Title: Learning a set of primitive actions with an Induction of decision trees. Machine Learning, 1(1):81-106,\nLabel: Theory\n\nPaper id: 1203\nTitle: Title: A Quantitative Study of Experimental Evaluations of Neural Network Learning Algorithms: Current Research Practice  \nLabel: Neural Networks\n\nPaper id: 684\nTitle: Title: Finding Overlapping Distributions with MML  \n\nPaper id: 542\nTitle: Title: Comparison of Bayesian and Neural Net Unsupervised Classification Techniques  \nLabel: Neural Networks\n\nPaper id: 747\nTitle: Title: Cholinergic suppression of transmission may allow combined associative memory function and self-organization in the neocortex.  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 369\nTitle: Title: Limitations of self-organizing maps for vector quantization and multidimensional scaling  \n\nPaper id: 386\nTitle: Title: Temporal Compositional Processing by a DSOM Hierarchical Model  \nLabel: Neural Networks\n\nPaper id: 73\nTitle: Title: LEARNING TO GENERATE ARTIFICIAL FOVEA TRAJECTORIES FOR TARGET DETECTION  \nLabel: Reinforcement Learning\n\nPaper id: 521\nTitle: Title: Covering vs. Divide-and-Conquer for Top-Down Induction of Logic Programs  \nLabel: Rule Learning\n\nPaper id: 227\nTitle: Title: Induction of Oblique Decision Trees  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2597\nTitle: Title: Improved Heterogeneous Distance Functions  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2256\nTitle: Title: Improved Center Point Selection for Probabilistic Neural Networks  \nLabel: Neural Networks\n\nPaper id: 1698\nTitle: Title: CBET: a Case Base Exploration Tool  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 430\nTitle: Title: Irrelevant Features and the Subset Selection Problem  \nLabel: Theory\n\nPaper id: 686\nTitle: Title: Prototype and Feature Selection by Sampling and Random Mutation Hill Climbing Algorithms  \nLabel: Case Based\n\nPaper id: 66\nTitle: Title: (1994); Case-Based Reasoning: Foundational Issues, Methodological Variations, and System Approaches. Case-Based Reasoning: Foundational Issues, Methodological\nLabel: Case Based\n\nPaper id: 1626\nTitle: Title: A Review and Empirical Evaluation of Feature Weighting Methods for a Class of Lazy Learning Algorithms  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 956\nTitle: Title: Modeling Distributed Search via Social Insects  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1178\nTitle: Title: Strongly Typed Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 1231\nTitle: Title: Type Inheritance in Strongly Typed Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 995\nTitle: Title: Evolving a Team  \n\nPaper id: 2598\nTitle: Title: Duplication of Coding Segments in Genetic Programming  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1476\nTitle: Title: Program Optimization for Faster Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 1985\nTitle: Title: ABSTRACT  \nLabel: Genetic Algorithms\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 2139\nTitle: Title: Evolving Teamwork and Coordination with Genetic Programming  \n\nPaper id: 1688\nTitle: Title: Co-Evolving Soccer Softbot Team Coordination with Genetic Programming  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1156\nTitle: Title: A NEW SEQUENTIAL SIMULATED ANNEALING METHOD  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1013\nTitle: Title: A SEQUENTIAL METROPOLIS-HASTINGS ALGORITHM  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1899\nTitle: Title: Logarithmic Time Parallel Bayesian Inference  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2292\nTitle: Title: Logarithmic-Time Updates and Queries in Probabilistic Networks  \nLabel: Probabilistic Methods\n\nPaper id: 327\nTitle: Title: Global Conditioning for Probabilistic Inference in Belief Networks  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 324\nTitle: Title: BUCKET ELIMINATION: A UNIFYING FRAMEWORK FOR PROBABILISTIC INFERENCE  \nLabel: Probabilistic Methods\n\nPaper id: 326\nTitle: Title: Topological Parameters for time-space tradeoff  \nLabel: Probabilistic Methods\n\nPaper id: 2140\nTitle: Title: Sonderforschungsbereich 314 K unstliche Intelligenz Wissensbasierte Systeme KI-Labor am Lehrstuhl f ur Informatik IV Numerical\nLabel: Probabilistic Methods\n\nPaper id: 945\nTitle: Title: Structured Representation of Complex Stochastic Systems  \nLabel: Probabilistic Methods\n\nPaper id: 1532\nTitle: Title: Automated Decomposition of Model-based Learning Problems  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1051\nTitle: Title: Interpreting neuronal population activity by reconstruction: A unified framework with application to hippocampal place cells  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2576\nTitle: Title: A Neural Model of the Cortical Representation of Egocentric Distance  \nLabel: Neural Networks\n\nPaper id: 1052\nTitle: Title: Representation of spatial orientation by the intrinsic dynamics of the head-direction cell ensemble: A theory  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 832\nTitle: Title: Learning Continuous Attractors in Recurrent Networks  \nLabel: Neural Networks\n\nPaper id: 1066\nTitle: Title: The Rectified Gaussian Distribution  \n\nPaper id: 600\nTitle: Title: Separating hippocampal maps  Spatial Functions of the Hippocampal Formation and the  \n\nPaper id: 2678\nTitle: Title: Egocentric spatial representation in early vision  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2556\nTitle: Title: A Case-Based Approach to Reactive Control for Autonomous Robots  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1904\nTitle: Title: Using Case-Based Reasoning for Mobile Robot Navigation  \nLabel: Case Based\n\nPaper id: 858\nTitle: Title: MULTISTRATEGY LEARNING IN REACTIVE CONTROL SYSTEMS FOR AUTONOMOUS ROBOTIC NAVIGATION  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 566\nTitle: Title: Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming  \nLabel: Reinforcement Learning\n\nPaper id: 2035\nTitle: Title: Knowledge Compilation and Speedup Learning in Continuous Task Domains  \nLabel: Case Based\n\nPaper id: 281\nTitle: Title: Clay: Integrating Motor Schemas and Reinforcement Learning  \nLabel: Reinforcement Learning\n\nPaper id: 2303\nTitle: Title: Case-based reactive navigation: A case-based method for on-line selection and adaptation of reactive control parameters\nLabel: Case Based\n\nPaper id: 643\nTitle: Title: Modeling Case-based Planning for Repairing Reasoning Failures  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 487\nTitle: Title: Language as a dynamical system  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 538\nTitle: Title: Learning and evolution in neural networks  \nLabel: Genetic Algorithms\n\nPaper id: 291\nTitle: Title: NETWORKS WITH REAL WEIGHTS: ANALOG COMPUTATIONAL COMPLEXITY In contrast to classical computational models, the models\nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2193\nTitle: Title: Growing neural networks  \nLabel: Genetic Algorithms\n\nPaper id: 402\nTitle: Title: The Evolutionary Cost of Learning  \nLabel: Genetic Algorithms\n\nPaper id: 1689\nTitle: Title: Selection for Wandering Behavior in a Small Robot  \nLabel: Genetic Algorithms\n\nPaper id: 2165\nTitle: Title: Auto-teaching: networks that develop their own teaching input  \nLabel: Genetic Algorithms\n\nPaper id: 1036\nTitle: Title: Adaptive Behavior in Competing Co-Evolving Species  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1955\nTitle: Title: Abstract  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2149\nTitle: Title: Scheduling and Mapping: Software Pipelining in the Presence of Structural Hazards proposed formulation and a\nLabel: Rule Learning\n\nPaper id: 2190\nTitle: Title: Minimum Register Requirements for a Modulo Schedule  \nLabel: Rule Learning\n\nPaper id: 2194\nTitle: Title: Minimizing Register Requirements under Resource-Constrained Rate-Optimal Software Pipelining  \nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2189\nTitle: Title: Stage Scheduling: A Technique to Reduce the Register Requirements of a Modulo Schedule  \nLabel: Rule Learning\n\nPaper id: 2188\nTitle: Title: Improving Software Pipelining With Unroll-and-Jam  \nLabel: Rule Learning\n\nPaper id: 2365\nTitle: Title: A Reduced Multipipeline Machine Description that Preserves Scheduling Constraints  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1077\nTitle: Title: A Search Space Analysis of the Job Shop Scheduling Problem  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1153\nTitle: Title: Evolution in Time and Space The Parallel Genetic Algorithm  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 856\nTitle: Title: Hierarchical priors and mixture models, with application in regression and density estimation  \nLabel: Genetic Algorithms\n\nPaper id: 1070\nTitle: Title: Extended Selection Mechanisms in Genetic Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 1611\nTitle: Title: Island Model Genetic Algorithms and Linearly Separable Problems  \nLabel: Genetic Algorithms\n\nPaper id: 1455\nTitle: Title: Self-Adaptation in Genetic Algorithms of external parameters of a GA is seen as a first\nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2267\nTitle: Title: Evolving Optimal Neural Networks Using Genetic Algorithms with Occam's Razor  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2196\nTitle: Title: Effects of Occam's Razor in Evolving Sigma-Pi Neural Nets  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 938\nTitle: Title: Genetic Programming of Minimal Neural Nets Using Occam's Razor  \nLabel: Genetic Algorithms\n\nPaper id: 380\nTitle: Title: Fitness Landscapes and Difficulty in Genetic Programming  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2198\nTitle: Title: An Incremental Interactive Algorithm for Regular Grammar Inference  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1560\nTitle: Title: DESIGN AND ANALYSIS OF EFFICIENT REINFORCEMENT LEARNING ALGORITHMS  \nLabel: Reinforcement Learning\n\nPaper id: 2537\nTitle: Title: Toward Learning Systems That Integrate Different Strategies and Representations TR93-22  \nLabel: Neural Networks\n\nPaper id: 2695\nTitle: Title: A Polynomial Time Incremental Algorithm for Regular Grammar Inference  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1846\nTitle: Title: A Neural Network Architecture for High-Speed Database Query Processing  \nLabel: Neural Networks\n\nPaper id: 451\nTitle: Title: Parameterized Heuristics for Intelligent Adaptive Network Routing in Large Communication Networks  \nLabel: Reinforcement Learning\n\nPaper id: 791\nTitle: Title: Asking Questions to Minimize Errors  \n\nPaper id: 1927\nTitle: Title: A Neural Architecture for Content as well as Address-Based Storage and Recall: Theory and Applications  \nLabel: Neural Networks\n\nPaper id: 535\nTitle: Title: Sequential PAC Learning  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1643\nTitle: Title: Learning to coordinate without sharing information  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 566\nTitle: Title: Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming  \nLabel: Reinforcement Learning\n\nPaper id: 649\nTitle: Title: Concept Learning and Heuristic Classification in Weak-Theory Domains 1  \nLabel: Case Based\n\nPaper id: 1649\nTitle: Title: Multi-Agent Reinforcement Learning: Independent vs. Cooperative Agents  \n\nPaper id: 773\nTitle: Title: Reinforcement Learning with Imitation in Heterogeneous Multi-Agent Systems  \n\nPaper id: 1189\nTitle: Title: Figure 3: Average model size accepted from a ran-dom prefix-closed samples of various size, and\nLabel: Theory\n\nPaper id: 868\nTitle: Title: Adaptive Load Balancing: A Study in Multi-Agent Learning  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1213\nTitle: Title: Learning in Multi-Robot Systems  \nLabel: Reinforcement Learning\n\nPaper id: 173\nTitle: Title: An Upper Bound on the Loss from Approximate Optimal-Value Functions  \nLabel: Reinforcement Learning\n\nPaper id: 1228\nTitle: Title: Team-Partitioned, Opaque-Transition Reinforcement Learning  \nLabel: Reinforcement Learning\n\nPaper id: 465\nTitle: Title: Strategy Learning with Multilayer Connectionist Representations 1  \nLabel: Reinforcement Learning\n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 337\nTitle: Title: Meter as Mechanism: A Neural Network that Learns Metrical Patterns  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 143\nTitle: Title: RESONANCE AND THE PERCEPTION OF MUSICAL METER  \n\nPaper id: 363\nTitle: Title: Representing Rhythmic Patterns in a Network of Oscillators  \nLabel: Neural Networks\n\nPaper id: 77\nTitle: Title: Synchronization and Desynchronization in a Network of Locally Coupled Wilson-Cowan Oscillators  \nLabel: Neural Networks\n\nPaper id: 346\nTitle: Title: PERCEPTION OF TIME AS PHASE: TOWARD AN ADAPTIVE-OSCILLATOR MODEL OF RHYTHMIC PATTERN PROCESSING 1  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 201\nTitle: Title: Neural net architectures for temporal sequence processing  \n\nPaper id: 132\nTitle: Title: TOWARDS PLANNING: INCREMENTAL INVESTIGATIONS INTO ADAPTIVE ROBOT CONTROL  \nLabel: Reinforcement Learning\n\nPaper id: 180\nTitle: Title: REDUCED MEMORY REPRESENTATIONS FOR MUSIC  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 595\nTitle: Title: LEARNING TO CONTROL FAST-WEIGHT MEMORIES: AN ALTERNATIVE TO DYNAMIC RECURRENT NETWORKS (Neural Computation, 4(1):131-139, 1992)  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 233\nTitle: Title: A `SELF-REFERENTIAL' WEIGHT MATRIX  \nLabel: Neural Networks\n\nPaper id: 121\nTitle: Title: LEARNING COMPLEX, EXTENDED SEQUENCES USING THE PRINCIPLE OF HISTORY COMPRESSION (Neural Computation, 4(2):234-242, 1992)  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1825\nTitle: Title: GUESSING CAN OUTPERFORM MANY LONG TIME LAG ALGORITHMS  \nLabel: Neural Networks\n\nPaper id: 1990\nTitle: Title: A FIXED SIZE STORAGE O(n 3 TIME COMPLEXITY LEARNING ALGORITHM FOR FULLY RECURRENT CONTINUALLY RUNNING\nLabel: Neural Networks\n\nPaper id: 731\nTitle: Title: LEARNING FACTORIAL CODES BY PREDICTABILITY MINIMIZATION (Neural Computation, 4(6):863-879, 1992)  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1388\nTitle: Title: A Fast, Bottom-Up Decision Tree Pruning Algorithm with Near-Optimal Generalization  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1025\nTitle: Title: Machine Learning 27(1):51-68, 1997. Predicting nearly as well as the best pruning of a decision tree  \nLabel: Theory\n\nPaper id: 1586\nTitle: Title: On the Boosting Ability of Top-Down Decision Tree Learning Algorithms provably optimal for decision tree\nLabel: Theory\n\nPaper id: 848\nTitle: Title: An Experimental and Theoretical Comparison of Model Selection Methods on simple model selection problems, the\nLabel: Theory\n\nPaper id: 1027\nTitle: Title: Pessimistic decision tree pruning based on tree size  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 876\nTitle: Title: Using and combining predictors that specialize  \n\nPaper id: 1336\nTitle: Title: Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid  \nLabel: Probabilistic Methods\n\nPaper id: 56\nTitle: Title: Self bounding learning algorithms  \nLabel: Theory\n\nPaper id: 1468\nTitle: Title: Preventing \"Overfitting\" of Cross-Validation Data  \nLabel: Theory\n\nPaper id: 1032\nTitle: Title: Algorithmic Stability and Sanity-Check Bounds for Leave-One-Out Cross-Validation  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 317\nTitle: Title: A dataset decomposition approach to data mining and machine discovery  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 417\nTitle: Title: Constructing Intermediate Concepts by Decomposition of Real Functions  \n\nPaper id: 2326\nTitle: Title: Pattern Theoretic Feature Extraction and Constructive Induction  \nLabel: Theory\n\nPaper id: 508\nTitle: Title: Machine Learning by Function Decomposition  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 523\nTitle: Title: Some studies in machine learning using the game of checkers. IBM Journal, 3(3):211-229, 1959. Some\nLabel: Genetic Algorithms\n\nPaper id: 2324\nTitle: Title: APPLICATION OF ESOP MINIMIZATION IN MACHINE LEARNING AND KNOWLEDGE DISCOVERY  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1540\nTitle: Title: MultiPlayer Residual Advantage Learning With General Function Approximation  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n\nPaper id: 842\nTitle: Title: Metrics for Temporal Difference Learning  \nLabel: Reinforcement Learning\n\nPaper id: 1443\nTitle: Title: Residual Q-Learning Applied to Visual Attention  \n\nPaper id: 1045\nTitle: Title: Spurious Solutions to the Bellman Equation  \n\nPaper id: 1378\nTitle: Title: Generalization in Reinforcement Learning: Safely Approximating the Value Function  \nLabel: Reinforcement Learning\n\nPaper id: 1118\nTitle: Title: Adapting Bias by Gradient Descent: An Incremental Version of Delta-Bar-Delta  \nLabel: Neural Networks\n\nPaper id: 1459\nTitle: Title: Generalized Markov Decision Processes: Dynamic-programming and Reinforcement-learning Algorithms  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 564\nTitle: Title: Reinforcement Learning with Soft State Aggregation  \nLabel: Reinforcement Learning\n\nPaper id: 306\nTitle: Title: Learning Curve Bounds for Markov Decision Processes with Undiscounted Rewards  \nLabel: Reinforcement Learning\n\nPaper id: 910\nTitle: Title: Learning Sequential Decision Rules Using Simulation Models and Competition  \nLabel: Genetic Algorithms\n\nPaper id: 1727\nTitle: Title: Machine Learning, 22(1/2/3):95-121, 1996. On the Worst-case Analysis of Temporal-difference Learning Algorithms  \nLabel: Theory\n\nPaper id: 2\nTitle: Title: Submitted to NIPS96, Section: Applications. Preference: Oral presentation Reinforcement Learning for Dynamic Channel Allocation in\nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1267\nTitle: Title: Estimating the Accuracy of Learned Concepts  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1335\nTitle: Title: A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection  \nLabel: Probabilistic Methods\n\nPaper id: 1512\nTitle: Title: Cross-Validation and the Bootstrap: Estimating the Error Rate of a Prediction Rule  \nLabel: Probabilistic Methods\n\nPaper id: 344\nTitle: Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In\nLabel: Rule Learning\n\nPaper id: 1500\nTitle: Title: On the Induction of Intelligible Ensembles  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2291\nTitle: Title: Top-Down Pruning in Relational Learning  \nLabel: Rule Learning\n\nPaper id: 2215\nTitle: Title: Learning Approximate Control Rules Of High Utility  \nLabel: Case Based\n\nPaper id: 2441\nTitle: Title: Distance Induction in First Order Logic used for classification via a k-nearest-neighbor process. Experiments on\nLabel: Rule Learning\n\nPaper id: 1024\nTitle: Title: On learning hierarchical classifications  \nLabel: Theory\n\nPaper id: 1337\nTitle: Title: MLC A Machine Learning Library in C  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 563\nTitle: Title: Evolving Obstacle Avoidance Behavior in a Robot Arm  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 37\nTitle: Title: Hierarchical Evolution of Neural Networks  \nLabel: Reinforcement Learning\n\nPaper id: 38\nTitle: Title: HOW TO EVOLVE AUTONOMOUS ROBOTS: DIFFERENT APPROACHES IN EVOLUTIONARY ROBOTICS  \n\nPaper id: 500\nTitle: Title: 2-D Pole Balancing with Recurrent Evolutionary Networks  \nLabel: Reinforcement Learning\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 247\nTitle: Title: Machine Learning,  Efficient Reinforcement Learning through Symbiotic Evolution  \nLabel: Reinforcement Learning\n\nPaper id: 219\nTitle: Title: Issues in Evolutionary Robotics  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1675\nTitle: Title: A Study of Genetic Algorithms to Find Approximate Solutions to Hard 3CNF Problems  \nLabel: Genetic Algorithms\n\nPaper id: 2444\nTitle: Title: Symbiotic Evolution of Neural Networks in Sequential Decision Tasks  \nLabel: Reinforcement Learning\n\nPaper id: 2554\nTitle: Title: Genetic Programming Estimates of Kolmogorov Complexity  \nLabel: Genetic Algorithms\n\nPaper id: 1530\nTitle: Title: Performance of Multi-Parent Crossover Operators on Numerical Function Optimization Problems  \nLabel: Genetic Algorithms\n\nPaper id: 1515\nTitle: Title: Evolving Optimal Populations with XCS Classifier Systems  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1597\nTitle: Title: an Opportunistic Enterprise  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1138\nTitle: Title: Learning Generic Mechanisms from Experiences for Analogical Reasoning  \nLabel: Case Based\n\nPaper id: 1534\nTitle: Title: The Use of Explicit Goals for Knowledge to Guide Inference and Learning  \n\nPaper id: 486\nTitle: Title: CASE-BASED CREATIVE DESIGN  \nLabel: Case Based\n\nPaper id: 1148\nTitle: Title: Opportunistic Reasoning: A Design Perspective  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 30\nTitle: Title: Towards More Creative Case-Based Design Systems  \nLabel: Case Based\n\nPaper id: 2706\nTitle: Title: Functional Representation as Design Rationale  \nLabel: Case Based\n\nPaper id: 1556\nTitle: Title: A Goal-Based Approach to Intelligent Information Retrieval  \nLabel: Case Based\n\nPaper id: 64\nTitle: Title: Integrating Creativity and Reading: A Functional Approach  \n\nPaper id: 1122\nTitle: Title: A Comparative Utility Analysis of Case-Based Reasoning and Control-Rule Learning Systems  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2199\nTitle: Title: Position Paper, Workshop on Evolutionary Computation with Variable Size Representation, ICGA, Fitness Causes Bloat in\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1184\nTitle: Title: Causality in Genetic Programming  \n\nPaper id: 1784\nTitle: Title: Genetic Programming and Redundancy  \nLabel: Genetic Algorithms\n\nPaper id: 2133\nTitle: Title: Genetic Programming Bloat with Dynamic Fitness  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 55\nTitle: Title: A Comparison of Selection Schemes used in Genetic Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 120\nTitle: Title: Genetic Programming Exploratory Power and the Discovery of Functions  \nLabel: Genetic Algorithms\n\nPaper id: 781\nTitle: Title: Evolving Visual Routines  Architecture and Planning,  \nLabel: Genetic Algorithms\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 2688\nTitle: Title: An Adverse Interaction between the Crossover Operator and a Restriction on Tree Depth of Crossover\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1021\nTitle: Title: Lemma 2.3 The system is reachable and observable and realizes the same input/output behavior as\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1464\nTitle: Title: LINEAR SYSTEMS WITH SIGN-OBSERVATIONS  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1100\nTitle: Title: Observability of Linear Systems with Saturated Outputs  \nLabel: Neural Networks\n\nPaper id: 1470\nTitle: Title: Interconnected Automata and Linear Systems: A Theoretical Framework in Discrete-Time In Hybrid Systems III: Verification\n\nPaper id: 200\nTitle: Title: Sample Complexity for Learning Recurrent Perceptron Mappings  \n\nPaper id: 1254\nTitle: Title: BACKPROPAGATION SEPARATES WHERE PERCEPTRONS DO  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1440\nTitle: Title: Value Function Approximations and Job-Shop Scheduling  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 82\nTitle: Title: A Reinforcement Learning Approach to Job-shop Scheduling  \nLabel: Reinforcement Learning\n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n\nPaper id: 1378\nTitle: Title: Generalization in Reinforcement Learning: Safely Approximating the Value Function  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 523\nTitle: Title: Some studies in machine learning using the game of checkers. IBM Journal, 3(3):211-229, 1959. Some\nLabel: Genetic Algorithms\n\nPaper id: 2\nTitle: Title: Submitted to NIPS96, Section: Applications. Preference: Oral presentation Reinforcement Learning for Dynamic Channel Allocation in\nLabel: Reinforcement Learning\n\nPaper id: 410\nTitle: Title: High-Performance Job-Shop Scheduling With A Time-Delay TD() Network  \nLabel: Reinforcement Learning\n\nPaper id: 548\nTitle: Title: Value Function Based Production Scheduling  \nLabel: Reinforcement Learning\n\nPaper id: 306\nTitle: Title: Learning Curve Bounds for Markov Decision Processes with Undiscounted Rewards  \nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 50\nTitle: Title: Abstract  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 581\nTitle: Title: Representing Self-knowledge for Introspection about Memory Search  \nLabel: Case Based\n\nPaper id: 643\nTitle: Title: Modeling Case-based Planning for Repairing Reasoning Failures  \nLabel: Case Based\n\nPaper id: 150\nTitle: Title: Using Knowledge of Cognitive Behavior to Learn from Failure  \nLabel: Case Based\n\nPaper id: 583\nTitle: Title: Introspective reasoning using meta-explanations for multistrategy learning  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 49\nTitle: Title: Abstract  \nLabel: Case Based\n\nPaper id: 64\nTitle: Title: Integrating Creativity and Reading: A Functional Approach  \n\nPaper id: 1121\nTitle: Title: Generic Teleological Mechanisms and their Use in Case Adaptation  \nLabel: Case Based\n\nPaper id: 284\nTitle: Title: Role of Ontology in Creative Understanding  \n\nPaper id: 2398\nTitle: Title: Issues in Goal-Driven Explanation  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1243\nTitle: Title: BLIND SEPARATION OF REAL WORLD AUDIO SIGNALS USING OVERDETERMINED MIXTURES  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 570\nTitle: Title: A New Learning Algorithm for Blind Signal Separation  \nLabel: Neural Networks\n\nPaper id: 1245\nTitle: Title: Blind separation of delayed and convolved sources.  \nLabel: Neural Networks\n\nPaper id: 1524\nTitle: Title: BLIND SEPARATION OF DELAYED SOURCES BASED ON INFORMATION MAXIMIZATION  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 59\nTitle: Title: SELF-ADAPTIVE NEURAL NETWORKS FOR BLIND SEPARATION OF SOURCES  \nLabel: Neural Networks\n\nPaper id: 169\nTitle: Title: LEARNING LINEAR, SPARSE, FACTORIAL CODES  \nLabel: Neural Networks\n\nPaper id: 1246\nTitle: Title: NIPS*97 Multiplicative Updating Rule for Blind Separation Derived from the Method of Scoring  \nLabel: Neural Networks\n\nPaper id: 874\nTitle: Title: LOCAL ADAPTIVE LEARNING ALGORITHMS FOR BLIND SEPARATION OF NATURAL IMAGES  \nLabel: Neural Networks\n\nPaper id: 576\nTitle: Title: An information-maximisation approach to blind separation and blind deconvolution  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2591\nTitle: Title: Lookahead and Discretization in ILP  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2253\nTitle: Title: Top-down Induction of Logical Decision Trees  \n\nPaper id: 2431\nTitle: Title: Multi-class problems and discretization in ICL Extended abstract  \n\nPaper id: 2126\nTitle: Title: Applying ILP to Diterpene Structure Elucidation from 13 C NMR Spectra  \nLabel: Rule Learning\n\nPaper id: 2427\nTitle: Title: Solving the Multiple-Instance Problem with Axis-Parallel Rectangles  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1888\nTitle: Title: Approximating Hyper-Rectangles: Learning and Pseudo-random Sets  \nLabel: Theory\n\nPaper id: 2426\nTitle: Title: Inductive Constraint Logic  \nLabel: Rule Learning\n\nPaper id: 318\nTitle: Title: Generalizing from Case Studies: A Case Study  \nLabel: Case Based\n\nPaper id: 2394\nTitle: Title: A Comparison of Dynamic Reposing and Tangent Distance for Drug Activity Prediction  \nLabel: Neural Networks\n\nPaper id: 2213\nTitle: Title: Generating Declarative Language Bias for Top-Down ILP Algorithms  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2637\nTitle: Title: A Computational Environment for Exhaust Nozzle Design  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2652\nTitle: Title: Knowledge-Based Re-engineering of Legacy Programs for Robustness in Automated Design  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2308\nTitle: Title: Problem Formulation, Program Synthesis and Program Transformation Techniques for Simulation, Optimization and Constraint Satisfaction (Research Statement)  \n\nPaper id: 240\nTitle: Title: A Transformation System for Interactive Reformulation of Design Optimization Strategies  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2617\nTitle: Title: Predicting Ordinal Classes in ILP  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 344\nTitle: Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In\nLabel: Rule Learning\n\nPaper id: 2091\nTitle: Title: The Utility of Knowledge in Inductive Learning  Running Head: Knowledge in Inductive Learning  \nLabel: Case Based\n\nPaper id: 1275\nTitle: Title: Fossil: A Robust Relational Learner  \n\nPaper id: 228\nTitle: Title: Cost-Sensitive Classification: Empirical Evaluation of a Hybrid Genetic Decision Tree Induction Algorithm  \nLabel: Genetic Algorithms\n\nPaper id: 1428\nTitle: Title: Inverse entailment and Progol  \nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 585\nTitle: Title: An investigation of noise-tolerant relational concept learning algorithms  \nLabel: Rule Learning\n\nPaper id: 2441\nTitle: Title: Distance Induction in First Order Logic used for classification via a k-nearest-neighbor process. Experiments on\nLabel: Rule Learning\n\nPaper id: 1622\nTitle: Title: Stochastic Propositionalization of Non-Determinate Background Knowledge  \nLabel: Rule Learning\n\nPaper id: 259\nTitle: Title: How to Get a Free Lunch: A Simple Cost Model for Machine Learning Applications  \nLabel: Case Based\n\nPaper id: 1312\nTitle: Title: Learning Trees and Rules with Set-valued Features  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1354\nTitle: Title: The Structure-Mapping Engine: Algorithm and Examples  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1304\nTitle: Title: Concept Sharing: A Means to Improve Multi-Concept Learning  \nLabel: Case Based\n\nPaper id: 1040\nTitle: Title: Learning from Examples: Reminding or Heuristic Switching?  \nLabel: Case Based\n\nPaper id: 75\nTitle: Title: A Memory Model for Case Retrieval by Activation Passing  \n\nPaper id: 1039\nTitle: Title: Functional Programming by Analogy  \nLabel: Case Based\n\nPaper id: 1420\nTitle: Title: Design, Analogy, and Creativity  \nLabel: Case Based\n\nPaper id: 1123\nTitle: Title: MAC/FAC: A Model of Similarity-based Retrieval  \nLabel: Case Based\n\nPaper id: 313\nTitle: Title: The Case for Graph-Structured Representations  \nLabel: Case Based\n\nPaper id: 1176\nTitle: Title: Distributed Representations and Nested Compositional Structure  \nLabel: Neural Networks\n\nPaper id: 992\nTitle: Title: Adapting Abstract Knowledge  \n\nPaper id: 479\nTitle: Title: Learning physical descriptions from functional definitions, examples, Learning from examples: The effect of different conceptual\nLabel: Case Based\n\nPaper id: 1089\nTitle: Title: Modeling Analogical Problem Solving in a Production System Architecture  \nLabel: Case Based\n\nPaper id: 1674\nTitle: Title: Proceedings of CogSci89 Structural Evaluation of Analogies: What Counts?  \nLabel: Case Based\n\nPaper id: 806\nTitle: Title: The Role of Generic Models in Conceptual Change  \nLabel: Case Based\n\nPaper id: 911\nTitle: Title: Utilizing Prior Concepts for Learning  \nLabel: Theory\n\nPaper id: 1426\nTitle: Title: REPRESENTING PHYSICAL AND DESIGN KNOWLEDGE IN INNOVATIVE DESIGN  \nLabel: Case Based\n\nPaper id: 1317\nTitle: Title: Use of Analogy in Automated Theorem Proving  \nLabel: Case Based\n\nPaper id: 1680\nTitle: Title: Making SME greedy and pragmatic  \n\nPaper id: 1695\nTitle: Title: Analogical Problem Solving by Adaptation of Schemes  \n\nPaper id: 1001\nTitle: Title: Is analogical problem solving always analogical? The case for imitation. Second draft Is analogical problem\nLabel: Case Based\n\nPaper id: 1047\nTitle: Title: GIT-CC-92/60 A Model-Based Approach to Analogical Reasoning and Learning in Design  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1642\nTitle: Title: CHIRON: Planning in an Open-Textured Domain  \nLabel: Case Based\n\nPaper id: 1285\nTitle: Title: Learning Context-free Grammars: Capabilities and Limitations of a Recurrent Neural Network with an External Stack Memory  \nLabel: Neural Networks\n\nPaper id: 1627\nTitle: Title: Inductive Learning of Characteristic Concept Descriptions from Small Sets of Classified Examples  \nLabel: Rule Learning\n\nPaper id: 449\nTitle: Title: Correcting Imperfect Domain Theories: A Knowledge-Level Analysis  \nLabel: Case Based\n\nPaper id: 1483\nTitle: Title: Context-Based Similarity Applied to Retrieval of Relevant Cases  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1162\nTitle: Title: Signal Processing and Communications Reversible Jump Sampler for Autoregressive Time Series, Employing Full Conditionals to\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1613\nTitle: Title: Priors and Component Structures in Autoregressive Time Series Models  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 784\nTitle: Title: Studies of Neurological Transmission Analysis using Hierarchical Bayesian Mixture Models  \n\nPaper id: 1619\nTitle: Title: Exploratory Modelling of Multiple Non-Stationary Time Series: Latent Process Structure and Decompositions  \nLabel: Probabilistic Methods\n\nPaper id: 99\nTitle: Title: Bayesian Forecasting of Multinomial Time Series through Conditionally Gaussian Dynamic Models  \nLabel: Probabilistic Methods\n\nPaper id: 1614\nTitle: Title: Bayesian Inference on Periodicities and Component Spectral Structure in Time Series  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 717\nTitle: Title: Information filtering: Selection mechanisms in learning systems. Machine Learning, 10:113-151, 1993. Generalization as search. Artificial\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1122\nTitle: Title: A Comparative Utility Analysis of Case-Based Reasoning and Control-Rule Learning Systems  \n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 188\nTitle: Title: Coevolving High-Level Representations  \nLabel: Genetic Algorithms\n\nPaper id: 2568\nTitle: Title: Abstract  \n\nPaper id: 2502\nTitle: Title: Modeling Ill-Structured Optimization Tasks through Cases  \nLabel: Case Based\n\nPaper id: 1877\nTitle: Title: Learning High Utility Rules by Incorporating Search Control  Guidance Committee  \nLabel: Case Based\n\nPaper id: 523\nTitle: Title: Some studies in machine learning using the game of checkers. IBM Journal, 3(3):211-229, 1959. Some\nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2039\nTitle: Title: A Case Study on Tuning of Genetic Algorithms by Using Performance Evaluation Based on Experimental Design  \nLabel: Genetic Algorithms\n\nPaper id: 251\nTitle: Title: A Statistical Approach to Solving the EBL Utility Problem  \nLabel: Theory\n\nPaper id: 966\nTitle: Title: Using a Genetic Algorithm to Learn Strategies for Collision Avoidance and Local Navigation  \nLabel: Genetic Algorithms\n\nPaper id: 1207\nTitle: Title: Data Analyses Using Simulated Breeding and Inductive Learning Methods  \nLabel: Genetic Algorithms\n\nPaper id: 2177\nTitle: Title: Analyzing Social Network Structures in the Iterated Prisoner's Dilemma with Choice and Refusal  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1369\nTitle: Title: STRUCTURAL LEARNING OF FUZZY RULES FROM NOISED EXAMPLES  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1333\nTitle: Title: Using Genetic Algorithms for Supervised Concept Learning  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1224\nTitle: Title: Using Real-Valued Genetic Algorithms to Evolve Rule Sets for Classification  \nLabel: Genetic Algorithms\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 1708\nTitle: Title: A Simpler Look at Consistency  \nLabel: Theory\n\nPaper id: 1225\nTitle: Title: Knowledge-Based Genetic Learning  \nLabel: Genetic Algorithms\n\nPaper id: 793\nTitle: Title: A Survey of Evolution Strategies  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2433\nTitle: Title: Robust Sound Localization: An Application of an Auditory Perception System for a Humanoid Robot  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2437\nTitle: Title: Embodiment and Manipulation Learning Process for a Humanoid Hand  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 745\nTitle: Title: References \"Using Neural Networks to Identify Jets\", Kohonen, \"Self Organized Formation of Topologically Correct Feature\nLabel: Neural Networks\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1802\nTitle: Title: Toward a Market Model for Bayesian Inference  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2064\nTitle: Title: A Market Framework for Pooling Opinions  \nLabel: Probabilistic Methods\n\nPaper id: 1777\nTitle: Title: Representing Aggregate Belief through the Competitive Equilibrium of a Securities Market  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1843\nTitle: Title: Goal-based Explanation Evaluation 1  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2626\nTitle: Title: Focusing Construction and Selection of Abductive Hypotheses  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2399\nTitle: Title: Abduction, Experience, and Goals: A Model of Everyday Abductive Explanation*  \nLabel: Case Based\n\nPaper id: 2656\nTitle: Title: ADAPtER: an Integrated Diagnostic System Combining Case-Based and Abductive Reasoning  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2281\nTitle: Title: GENE REGULATION AND BIOLOGICAL DEVELOPMENT IN NEURAL NETWORKS: AN EXPLORATORY MODEL  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2429\nTitle: Title: Automatic Definition of Modular Neural Networks  \nLabel: Genetic Algorithms\n\nPaper id: 1134\nTitle: Title: Discontinuity in evolution: how different levels of organization imply pre-adaptation  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1143\nTitle: Title: Neural Networks in an Artificial Life Perspective  \nLabel: Genetic Algorithms\n\nPaper id: 1264\nTitle: Title: An Artificial Life Model for Investigating the Evolution of Modularity  \nLabel: Genetic Algorithms\n\nPaper id: 2667\nTitle: Title: Biological metaphors and the design of modular artificial neural networks Master's thesis of  \nLabel: Genetic Algorithms\n\nPaper id: 2152\nTitle: Title: Cellular Encoding for Interactive Evolutionary Robotics  \nLabel: Genetic Algorithms\n\nPaper id: 2624\nTitle: Title: A Comparison between Cellular Encoding and Direct Encoding for Genetic Neural Networks  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2391\nTitle: Title: A Note on Learning from Multiple-Instance Examples  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 507\nTitle: Title: PAC Learning Axis-aligned Rectangles with Respect to Product Distributions from Multiple-instance Examples  \nLabel: Theory\n\nPaper id: 2427\nTitle: Title: Solving the Multiple-Instance Problem with Axis-Parallel Rectangles  \nLabel: Neural Networks\n\nPaper id: 2548\nTitle: Title: A Framework for Multiple-Instance Learning  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 798\nTitle: Title: Composite Geometric Concepts and Polynomial Predictability  \nLabel: Theory\n\nPaper id: 318\nTitle: Title: Generalizing from Case Studies: A Case Study  \nLabel: Case Based\n\nPaper id: 2394\nTitle: Title: A Comparison of Dynamic Reposing and Tangent Distance for Drug Activity Prediction  \nLabel: Neural Networks\n\nPaper id: 109\nTitle: Title: A General Lower Bound on the Number of Examples Needed for Learning  \nLabel: Theory\n\nPaper id: 2591\nTitle: Title: Lookahead and Discretization in ILP  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1197\nTitle: Title: Why Does Bagging Work? A Bayesian Account and its Implications bagging's success, both in a\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1290\nTitle: Title: A THEORY OF LEARNING CLASSIFICATION RULES  \nLabel: Theory\n\nPaper id: 2634\nTitle: Title: Bayesian Model Averaging  \nLabel: Probabilistic Methods\n\nPaper id: 1053\nTitle: Title: Bias Plus Variance Decomposition for Zero-One Loss Functions  \nLabel: Theory\n\nPaper id: 1484\nTitle: Title: Experiments with a New Boosting Algorithm  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1712\nTitle: Title: An Efficient Extension to Mixture Techniques for Prediction and Decision Trees  \nLabel: Theory\n\nPaper id: 1191\nTitle: Title: Machine Learning Bias, Statistical Bias, and Statistical Variance of Decision Tree Algorithms  \n\nPaper id: 1644\nTitle: Title: A Comparative Study of ID3 and Backpropagation for English Text-to-Speech Mapping  \nLabel: Neural Networks\n\nPaper id: 1918\nTitle: Title: Stochastic Logic Programs  \nLabel: Theory\n\nPaper id: 1237\nTitle: Title: An Empirical Evaluation of Bagging and Boosting  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1147\nTitle: Title: Decomposable graphical Gaussian model determination  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 772\nTitle: Title: [12] J. Whittaker. Graphical Models in Applied Mathematical Multivariate Statis-  \nLabel: Probabilistic Methods\n\nPaper id: 1347\nTitle: Title: Markov Chain Monte Carlo Model Determination for Hierarchical and Graphical Log-linear Models  \nLabel: Probabilistic Methods\n\nPaper id: 1240\nTitle: Title: Model Selection and Accounting for Model Uncertainty in Linear Regression Models  \nLabel: Probabilistic Methods\n\nPaper id: 161\nTitle: Title: On Bayesian analysis of mixtures with an unknown number of components  Summary  \n\nPaper id: 1241\nTitle: Title: Bayesian Graphical Models for Discrete Data  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 996\nTitle: Title: Reparameterisation Issues in Mixture Modelling and their bearing on MCMC algorithms  \n\nPaper id: 998\nTitle: Title: Accounting for Model Uncertainty in Survival Analysis Improves Predictive Performance  \nLabel: Probabilistic Methods\n\nPaper id: 2167\nTitle: Title: Counterfactuals and Policy Analysis in Structural Models  \nLabel: Probabilistic Methods\n\nPaper id: 1086\nTitle: Title: An Algorithm for the Construction of Bayesian Network Structures from Data  \nLabel: Probabilistic Methods\n\nPaper id: 768\nTitle: Title: DYNAMIC CONDITIONAL INDEPENDENCE MODELS AND MARKOV CHAIN MONTE CARLO METHODS  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1707\nTitle: Title: Supporting Combined Human and Machine Planning: The Prodigy 4.0 User Interface Version 2.0*  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 825\nTitle: Title: Towards Mixed-Initiative Rationale-Supported Planning  \n\nPaper id: 824\nTitle: Title: Merge Strategies for Multiple Case Plan Replay  \nLabel: Case Based\n\nPaper id: 1215\nTitle: Title: Supporting Combined Human and Machine Planning: An Interface for Planning by Analogical Reasoning  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1621\nTitle: Title: Evaluating the Effectiveness of Derivation Replay in Partial-order vs State-space Planning  \nLabel: Case Based\n\nPaper id: 819\nTitle: Title: A Case Study of Case-Based CBR  \nLabel: Case Based\n\nPaper id: 818\nTitle: Title: Learning to Integrate Multiple Knowledge Sources for Case-Based Reasoning  \nLabel: Case Based\n\nPaper id: 580\nTitle: Title: Learning to Improve Case Adaptation by Introspective Reasoning and CBR  \n\nPaper id: 1209\nTitle: Title: S o l u t i o n Relevant A b s t r a\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1012\nTitle: Title: TDLeaf(): Combining Temporal Difference learning with game-tree search.  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 295\nTitle: Title: A Neuro-Dynamic Programming Approach to Retailer Inventory Management 1  \nLabel: Reinforcement Learning\n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n\nPaper id: 882\nTitle: Title: Learning To Play the Game of Chess  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 492\nTitle: Title: Approximating Optimal Policies for Partially Observable Stochastic Domains  \n\nPaper id: 2\nTitle: Title: Submitted to NIPS96, Section: Applications. Preference: Oral presentation Reinforcement Learning for Dynamic Channel Allocation in\nLabel: Reinforcement Learning\n\nPaper id: 385\nTitle: Title: Modeling the Student with Reinforcement Learning  \nLabel: Reinforcement Learning\n\nPaper id: 502\nTitle: Title: Fast Online Q()  \n\nPaper id: 305\nTitle: Title: Solving Combinatorial Optimization Tasks by Reinforcement Learning: A General Methodology Applied to Resource-Constrained Scheduling  \nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2652\nTitle: Title: Knowledge-Based Re-engineering of Legacy Programs for Robustness in Automated Design  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 240\nTitle: Title: A Transformation System for Interactive Reformulation of Design Optimization Strategies  \nLabel: Genetic Algorithms\n\nPaper id: 2308\nTitle: Title: Problem Formulation, Program Synthesis and Program Transformation Techniques for Simulation, Optimization and Constraint Satisfaction (Research Statement)  \n\nPaper id: 2637\nTitle: Title: A Computational Environment for Exhaust Nozzle Design  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 61\nTitle: Title: Program Synthesis and Transformation Techniques for Simpuation, Optimization and Constraint Satisfaction Deductive Synthesis of Numerical\nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1346\nTitle: Title: References Linear Controller Design, Limits of Performance, \"The parallel projection operators of a nonlinear feedback\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1272\nTitle: Title: Input-Output Analysis of Feedback Loops with Saturation Nonlinearities  \nLabel: Neural Networks\n\nPaper id: 1281\nTitle: Title: On Finite Gain Stabilizability of Linear Systems Subject to Input Saturation  \nLabel: Neural Networks\n\nPaper id: 1451\nTitle: Title: On the Computation of the Induced L 2 Norm of Single Input Linear Systems with Saturation  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1282\nTitle: Title: Global Stabilization of Linear Discrete-Time Systems with Bounded Feedback  \n\nPaper id: 1604\nTitle: Title: Analytic Comparison of Nonlinear H 1 -Norm Bounding Techniques for Low Order Systems with Saturation  \nLabel: Neural Networks\n\nPaper id: 1471\nTitle: Title: New Characterizations of Input to State Stability  \nLabel: Neural Networks\n\nPaper id: 948\nTitle: Title: An Optimal Weighting Criterion of Case Indexing for Both Numeric and Symbolic Attributes  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 379\nTitle: Title: In: Machine Learning, Meta-reasoning and Logics, pp207-232,  Learning from Imperfect Data  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 756\nTitle: Title: Knowledge Acquisition via Knowledge Integration  \nLabel: Rule Learning\n\nPaper id: 176\nTitle: Title: Knowledge Integration and Learning  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1759\nTitle: Title: Belief Maintenance in Bayesian Networks  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2288\nTitle: Title: Anytime Influence Diagrams  \nLabel: Probabilistic Methods\n\nPaper id: 2697\nTitle: Title: Belief Maintenance with Probabilistic Logic  \nLabel: Probabilistic Methods\n\nPaper id: 2698\nTitle: Title: Forecasting Glucose Concentration in Diabetic Patients using Ignorant Belief Networks  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2700\nTitle: Title: Probabilistic Reasoning under Ignorance  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1522\nTitle: Title: Improving Bagging Performance by Increasing Decision Tree Diversity  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1484\nTitle: Title: Experiments with a New Boosting Algorithm  \n\nPaper id: 569\nTitle: Title: A decision-theoretic generalization of on-line learning and an application to boosting how the weight-update rule\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1692\nTitle: Title: Boosting Trees for Cost-Sensitive Classifications  \nLabel: Theory\n\nPaper id: 255\nTitle: Title: An Efficient Boosting Algorithm for Combining Preferences  \nLabel: Theory\n\nPaper id: 1500\nTitle: Title: On the Induction of Intelligible Ensembles  \n\nPaper id: 456\nTitle: Title: Boosting a weak learning algorithm by majority To be published in Information and Computation  \nLabel: Theory\n\nPaper id: 1482\nTitle: Title: Generalizations of the Bias/Variance Decomposition for Prediction Error  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 36\nTitle: Title: Generative Models for Discovering Sparse Distributed Representations  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2072\nTitle: Title: Data Mining for Association Rules with Unsupervised Neural Networks  \nLabel: Neural Networks\n\nPaper id: 745\nTitle: Title: References \"Using Neural Networks to Identify Jets\", Kohonen, \"Self Organized Formation of Topologically Correct Feature\nLabel: Neural Networks\n\nPaper id: 1933\nTitle: Title: Continuous sigmoidal belief networks trained using slice sampling  \nLabel: Probabilistic Methods\n\nPaper id: 257\nTitle: Title: Factor Analysis Using Delta-Rule Wake-Sleep Learning  \nLabel: Neural Networks\n\nPaper id: 2390\nTitle: Title: A HIERARCHICAL COMMUNITY OF EXPERTS  \nLabel: Neural Networks\n\nPaper id: 1066\nTitle: Title: The Rectified Gaussian Distribution  \n\nPaper id: 1701\nTitle: Title: Pattern analysis and synthesis in attractor neural networks  \nLabel: Neural Networks\n\nPaper id: 1591\nTitle: Title: Unsupervised Learning by Convex and Conic Coding  \nLabel: Neural Networks\n\nPaper id: 1974\nTitle: Title: Data Mining for Association Rules with Unsupervised Neural Networks  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 687\nTitle: Title: Growing Cell Structures A Self-organizing Network for Unsupervised and Supervised Learning  \nLabel: Neural Networks\n\nPaper id: 2325\nTitle: Title: Incremental Polynomial Model-Controller Network: a self organising non-linear controller  \nLabel: Neural Networks\n\nPaper id: 124\nTitle: Title: Self-Organization and Segmentation in a Laterally Connected Orientation Map of Spiking Neurons  \nLabel: Neural Networks\n\nPaper id: 458\nTitle: Title: Quantifying neighbourhood preservation in topographic mappings  \nLabel: Neural Networks\n\nPaper id: 2437\nTitle: Title: Embodiment and Manipulation Learning Process for a Humanoid Hand  \nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2686\nTitle: Title: Penalisation multiple adaptative un nouvel algorithme de regression, la penalisation multiple adapta-tive. Cet algorithme represente\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 101\nTitle: Title: Adaptive Noise Injection for Input Variables Relevance Determination  \nLabel: Neural Networks\n\nPaper id: 916\nTitle: Title: A comparison of some error estimates for neural network models  Summary  \nLabel: Neural Networks\n\nPaper id: 2596\nTitle: Title: Regression shrinkage and selection via the lasso  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2373\nTitle: Title: Evaluating Neural Network Predictors by Bootstrapping  \nLabel: Neural Networks\n\nPaper id: 157\nTitle: Title: A Practical Bayesian Framework for Backprop Networks  \nLabel: Theory\n\nPaper id: 1038\nTitle: Title: Brief Papers Computing Second Derivatives in Feed-Forward Networks: A Review  \n\nPaper id: 2374\nTitle: Title: Predictions with Confidence Intervals (Local Error Bars)  \nLabel: Neural Networks\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2253\nTitle: Title: Top-down Induction of Logical Decision Trees  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2591\nTitle: Title: Lookahead and Discretization in ILP  \n\nPaper id: 2213\nTitle: Title: Generating Declarative Language Bias for Top-Down ILP Algorithms  \nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1259\nTitle: Title: Finding Accurate Frontiers: A Knowledge-Intensive Approach to Relational Learning  \nLabel: Rule Learning\n\nPaper id: 2126\nTitle: Title: Applying ILP to Diterpene Structure Elucidation from 13 C NMR Spectra  \nLabel: Rule Learning\n\nPaper id: 2539\nTitle: Title: Mining for Causes of Cancer: Machine Learning Experiments at Various Levels of Detail  \n\nPaper id: 2290\nTitle: Title: A Comparison of Pruning Methods for Relational Concept Learning  \nLabel: Rule Learning\n\nPaper id: 2431\nTitle: Title: Multi-class problems and discretization in ICL Extended abstract  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1069\nTitle: Title: Extended Selection Mechanisms in Genetic Algorithms  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 422\nTitle: Title: Genetic Self-Learning  \nLabel: Genetic Algorithms\n\nPaper id: 1685\nTitle: Title: Optimization by Means of Genetic Algorithms  \n\nPaper id: 793\nTitle: Title: A Survey of Evolution Strategies  \nLabel: Genetic Algorithms\n\nPaper id: 1455\nTitle: Title: Self-Adaptation in Genetic Algorithms of external parameters of a GA is seen as a first\nLabel: Genetic Algorithms\n\nPaper id: 1096\nTitle: Title: Pruning backpropagation neural networks using modern stochastic optimization techniques  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2200\nTitle: Title: Adaptation in constant utility non-stationary environments  \n\nPaper id: 658\nTitle: Title: Hill Climbing with Learning (An Abstraction of Genetic Algorithm)  \n\nPaper id: 1734\nTitle: Title: A Stochastic Search Approach to Grammar Induction  \n\nPaper id: 624\nTitle: Title: Measuring the Difficulty of Specific Learning Problems  \nLabel: Theory\n\nPaper id: 2251\nTitle: Title: A PARALLEL ISLAND MODEL GENETIC ALGORITHM FOR THE MULTIPROCESSOR SCHEDULING PROBLEM  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1129\nTitle: Title: A Self-Organizing Binary Decision Tree For Incrementally Defined Rule Based  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 26\nTitle: Title: Neural Network Applicability: Classifying the Problem Space  \nLabel: Neural Networks\n\nPaper id: 809\nTitle: Title: A Self-Adjusting Dynamic Logic Module  \nLabel: Neural Networks\n\nPaper id: 1190\nTitle: Title: Analysis of the Convergence and Generalization of AA1  \nLabel: Neural Networks\n\nPaper id: 814\nTitle: Title: A VLSI Implementation of a Parallel, Self-Organizing Learning Model  \nLabel: Neural Networks\n\nPaper id: 1080\nTitle: Title: A Multi-Chip Module Implementation of a Neural Network  \nLabel: Neural Networks\n\nPaper id: 919\nTitle: Title: A Generalizing Adaptive Discriminant Network  \nLabel: Neural Networks\n\nPaper id: 1222\nTitle: Title: Towards a General Distributed Platform for Learning and Generalization and Word Perfect Corp. 1 Introduction\nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 908\nTitle: Title: Eclectic Machine Learning  \nLabel: Neural Networks\n\nPaper id: 1639\nTitle: Title: The Effect of Decision Surface Fitness on Dynamic Multilayer Perceptron Networks (DMP1)  \nLabel: Neural Networks\n\nPaper id: 297\nTitle: Title: Automatic Feature Extraction in Machine Learning  \nLabel: Neural Networks\n\nPaper id: 1615\nTitle: Title: A Provably Convergent Dynamic Training Method for Multilayer Perceptron Networks  \nLabel: Neural Networks\n\nPaper id: 1229\nTitle: Title: Using Multiple Node Types to Improve the Performance of DMP (Dynamic Multilayer Perceptron)  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 172\nTitle: Title: Efficient Feature Selection in Conceptual Clustering  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 245\nTitle: Title: ICML-96 Workshop \"Learning in context-sensitive domains\" Bari, Italy. Dynamically Adjusting Concepts to Accommodate Changing Contexts  \n\nPaper id: 430\nTitle: Title: Irrelevant Features and the Subset Selection Problem  \nLabel: Theory\n\nPaper id: 635\nTitle: Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2197\nTitle: Title: MLC Tutorial A Machine Learning library of C classes.  \n\nPaper id: 1020\nTitle: Title: Error-Based and Entropy-Based Discretization of Continuous Features  \n\nPaper id: 1165\nTitle: Title: Discovering Compressive Partial Determinations in Mixed Numerical and Symbolic Domains  \nLabel: Rule Learning\n\nPaper id: 2593\nTitle: Title: Induction of Condensed Determinations  \nLabel: Case Based\n\nPaper id: 1698\nTitle: Title: CBET: a Case Base Exploration Tool  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1119\nTitle: Title: Adaptive Parameter Pruning in Neural Networks  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 881\nTitle: Title: Proben1 A Set of Neural Network Benchmark Problems and Benchmarking Rules  \nLabel: Neural Networks\n\nPaper id: 1203\nTitle: Title: A Quantitative Study of Experimental Evaluations of Neural Network Learning Algorithms: Current Research Practice  \nLabel: Neural Networks\n\nPaper id: 2405\nTitle: Title: A Parallel Programming Model for Irregular Dynamic Neural Networks a programming model that allows to\nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 74\nTitle: Title: Hierarchical Mixtures of Experts and the EM Algorithm  \nLabel: Probabilistic Methods\n\nPaper id: 2203\nTitle: Title: CuPit-2: Portable and Efficient High-Level Parallel Programming of Neural Networks for the Systems Analysis Modelling\nLabel: Neural Networks\n\nPaper id: 2702\nTitle: Title: An Evolutionary Method to Find Good Building-Blocks for Architectures of Artificial Neural Networks  \nLabel: Genetic Algorithms\n\nPaper id: 112\nTitle: Title: Interpretable Neural Networks with BP-SOM  \nLabel: Neural Networks\n\nPaper id: 1411\nTitle: Title: Connection Pruning with Static and Adaptive Pruning Schedules  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2257\nTitle: Title: Real-time Interactive Neuro-evolution  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 247\nTitle: Title: Machine Learning,  Efficient Reinforcement Learning through Symbiotic Evolution  \nLabel: Reinforcement Learning\n\nPaper id: 2444\nTitle: Title: Symbiotic Evolution of Neural Networks in Sequential Decision Tasks  \nLabel: Reinforcement Learning\n\nPaper id: 1767\nTitle: Title: Incremental Evolution of Complex General Behavior  \nLabel: Reinforcement Learning\n\nPaper id: 22\nTitle: Title: Discovering Complex Othello Strategies Through Evolutionary Neural Networks  \nLabel: Genetic Algorithms\n\nPaper id: 1768\nTitle: Title: Evolving Neural Networks to Play Go  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1973\nTitle: Title: ON MCMC METHODS IN BAYESIAN REGRESSION ANALYSIS AND MODEL SELECTION  \nLabel: Genetic Algorithms\n\nPaper id: 2446\nTitle: Title: Simulation of Reduced Precision Arithmetic for Digital Neural Networks Using the RAP Machine  \nLabel: Genetic Algorithms\n\nPaper id: 129\nTitle: Title: Evolving Networks: Using the Genetic Algorithm with Connectionist Learning  \nLabel: Genetic Algorithms\n\nPaper id: 500\nTitle: Title: 2-D Pole Balancing with Recurrent Evolutionary Networks  \nLabel: Reinforcement Learning\n\nPaper id: 982\nTitle: Title: Evolutionary Neural Networks for Value Ordering in Constraint Satisfaction Problems  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 4\nTitle: Note: c Massachusetts Institute of Technology  The thesis consists of the development of this  Michael I. Jordan Title: Professor  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 170\nTitle: Title: Large Deviation Methods for Approximate Probabilistic Inference, with Rates of Convergence a free parameter. The\nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 250\nTitle: Title: Mean Field Theory for Sigmoid Belief Networks  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1799\nTitle: Title: On the Effectiveness of Evolutionary Search in High-Dimensional NK-Landscapes  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 727\nTitle: Title: Using Problem Generators to Explore the Effects of Epistasis  \nLabel: Genetic Algorithms\n\nPaper id: 2205\nTitle: Title: A Genetic Local Search Approach to the Quadratic Assignment Problem  \n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 1424\nTitle: Title: Multi-parent's niche: n-ary crossovers on NK-landscapes  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2232\nTitle: Title: Facing The Facts: Necessary Requirements For The Artificial Evolution of Complex Behaviour  \nLabel: Genetic Algorithms\n\nPaper id: 658\nTitle: Title: Hill Climbing with Learning (An Abstraction of Genetic Algorithm)  \n\nPaper id: 1784\nTitle: Title: Genetic Programming and Redundancy  \nLabel: Genetic Algorithms\n\nPaper id: 624\nTitle: Title: Measuring the Difficulty of Specific Learning Problems  \nLabel: Theory\n\nPaper id: 2274\nTitle: Title: Specialization in Populations of Artificial Neural Networks  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 928\nTitle: Title: Learning to Refine Case Libraries:  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 256\nTitle: Title: Using Decision Trees to Improve Case-Based Learning  \nLabel: Case Based\n\nPaper id: 983\nTitle: Title: Refining Conversational Case Libraries  \nLabel: Case Based\n\nPaper id: 1636\nTitle: Title: Context-Sensitive Feature Selection for Lazy Learners  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 245\nTitle: Title: ICML-96 Workshop \"Learning in context-sensitive domains\" Bari, Italy. Dynamically Adjusting Concepts to Accommodate Changing Contexts  \n\nPaper id: 430\nTitle: Title: Irrelevant Features and the Subset Selection Problem  \nLabel: Theory\n\nPaper id: 1002\nTitle: Title: A Model-Based Approach for Supporting Dialogue Inferencing in a Conversational Case-Based Reasoner  \nLabel: Case Based\n\nPaper id: 635\nTitle: Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features  \n\nPaper id: 2369\nTitle: Title: Case-Based Sonogram Classification  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 540\nTitle: Title: A Model-Based Approach to Blame-Assignment in Design  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 543\nTitle: Title: Meta-Cases: Explaining Case-Based Reasoning  \nLabel: Case Based\n\nPaper id: 1640\nTitle: Title: KRITIK: AN EARLY CASE-BASED DESIGN SYSTEM  \nLabel: Case Based\n\nPaper id: 603\nTitle: Title: METHOD-SPECIFIC KNOWLEDGE COMPILATION: TOWARDS PRACTICAL DESIGN SUPPORT SYSTEMS  \nLabel: Case Based\n\nPaper id: 523\nTitle: Title: Some studies in machine learning using the game of checkers. IBM Journal, 3(3):211-229, 1959. Some\nLabel: Genetic Algorithms\n\nPaper id: 1121\nTitle: Title: Generic Teleological Mechanisms and their Use in Case Adaptation  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1355\nTitle: Title: Modeling Invention by Analogy in ACT-R  \nLabel: Case Based\n\nPaper id: 717\nTitle: Title: Information filtering: Selection mechanisms in learning systems. Machine Learning, 10:113-151, 1993. Generalization as search. Artificial\n\nPaper id: 508\nTitle: Title: Machine Learning by Function Decomposition  \nLabel: Theory\n\nPaper id: 1616\nTitle: Title: NeuroDraughts: the role of representation, search, training regime and architecture in a TD draughts player  \nLabel: Reinforcement Learning\n\nPaper id: 283\nTitle: Title: A Local Learning Algorithm for Dynamic Feedforward and Recurrent Networks  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 34\nTitle: Title: Using a Case Base of Surfaces to Speed-Up Reinforcement Learning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 66\nTitle: Title: (1994); Case-Based Reasoning: Foundational Issues, Methodological Variations, and System Approaches. Case-Based Reasoning: Foundational Issues, Methodological\nLabel: Case Based\n\nPaper id: 566\nTitle: Title: Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming  \nLabel: Reinforcement Learning\n\nPaper id: 559\nTitle: Title: Scaling Up Average Reward Reinforcement Learning by Approximating the Domain Models and the Value Function  \n\nPaper id: 35\nTitle: Title: A Teaching Strategy for Memory-Based Control  \n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 733\nTitle: Title: Evolutionary Differentiation of Learning Abilities a case study on optimizing parameter values in Q-learning by\nLabel: Reinforcement Learning\n\nPaper id: 1816\nTitle: Title: Generalized Prioritized Sweeping  \n\nPaper id: 69\nTitle: Title: SaxEx a case-based reasoning system for generating expressive musical performances  \nLabel: Case Based\n\nPaper id: 564\nTitle: Title: Reinforcement Learning with Soft State Aggregation  \nLabel: Reinforcement Learning\n\nPaper id: 321\nTitle: Title: Planning with Closed-Loop Macro Actions  \nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1649\nTitle: Title: Multi-Agent Reinforcement Learning: Independent vs. Cooperative Agents  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 691\nTitle: Title: Reinforcement Learning in the Multi-Robot Domain  \nLabel: Reinforcement Learning\n\nPaper id: 1557\nTitle: Title: Using Communication to Reduce Locality in Distributed Multi-Agent Learning  \nLabel: Reinforcement Learning\n\nPaper id: 148\nTitle: Title: Multiagent Reinforcement Learning: Theoretical Framework and an Algorithm  \nLabel: Reinforcement Learning\n\nPaper id: 1687\nTitle: Title: Markov games as a framework for multi-agent reinforcement learning  \n\nPaper id: 868\nTitle: Title: Adaptive Load Balancing: A Study in Multi-Agent Learning  \nLabel: Reinforcement Learning\n\nPaper id: 1228\nTitle: Title: Team-Partitioned, Opaque-Transition Reinforcement Learning  \nLabel: Reinforcement Learning\n\nPaper id: 1213\nTitle: Title: Learning in Multi-Robot Systems  \nLabel: Reinforcement Learning\n\nPaper id: 1643\nTitle: Title: Learning to coordinate without sharing information  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 650\nTitle: Title: Learning to Use Selective Attention and Short-Term Memory in Sequential Tasks  \nLabel: Reinforcement Learning\n\nPaper id: 1459\nTitle: Title: Generalized Markov Decision Processes: Dynamic-programming and Reinforcement-learning Algorithms  \nLabel: Reinforcement Learning\n\nPaper id: 54\nTitle: Title: A Competitive Approach to Game Learning  \nLabel: Theory\n\nPaper id: 1693\nTitle: Title: INCREMENTAL SELF-IMPROVEMENT FOR LIFE-TIME MULTI-AGENT REINFORCEMENT LEARNING  \n\nPaper id: 773\nTitle: Title: Reinforcement Learning with Imitation in Heterogeneous Multi-Agent Systems  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 633\nTitle: Title: Chapter 1 Reinforcement Learning for Planning and Control  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 566\nTitle: Title: Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming  \nLabel: Reinforcement Learning\n\nPaper id: 197\nTitle: Title: Optimal Navigation in a Probibalistic World  \n\nPaper id: 294\nTitle: Title: References elements that can solve difficult learning control problems. on Simulation of Adaptive Behavior, pages\nLabel: Reinforcement Learning\n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n\nPaper id: 1459\nTitle: Title: Generalized Markov Decision Processes: Dynamic-programming and Reinforcement-learning Algorithms  \nLabel: Reinforcement Learning\n\nPaper id: 611\nTitle: Title: Learning networks for face analysis and synthesis  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2230\nTitle: Title: In Advances in Neural Information Processing Systems 8  Gaussian Processes for Regression  \nLabel: Neural Networks\n\nPaper id: 295\nTitle: Title: A Neuro-Dynamic Programming Approach to Retailer Inventory Management 1  \nLabel: Reinforcement Learning\n\nPaper id: 1676\nTitle: Title: TD Learning of Game Evaluation Functions with Hierarchical Neural Architectures  \n\nPaper id: 283\nTitle: Title: A Local Learning Algorithm for Dynamic Feedforward and Recurrent Networks  \nLabel: Neural Networks\n\nPaper id: 2378\nTitle: Title: Priors, Stabilizers and Basis Functions: from regularization to radial, tensor and additive splines  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 122\nTitle: Title: Tilt Aftereffects in a Self-Organizing Model of the Primary Visual Cortex  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 127\nTitle: Title: Self-Organization and Functional Role of Lateral Connections and Multisize Receptive Fields in the Primary Visual Cortex  \n\nPaper id: 2400\nTitle: Title: A Neural Network Model of Visual Tilt Aftereffects  \nLabel: Neural Networks\n\nPaper id: 124\nTitle: Title: Self-Organization and Segmentation in a Laterally Connected Orientation Map of Spiking Neurons  \nLabel: Neural Networks\n\nPaper id: 1093\nTitle: Title: The role of afferent excitatory and lateral inhibitory synaptic plasticity in visual cortical ocular dominance\nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1916\nTitle: Title: Modeling Cortical Plasticity Based on Adapting Lateral Interaction  \nLabel: Neural Networks\n\nPaper id: 18\nTitle: Title: Topography And Ocular Dominance: A Model Exploring Positive Correlations  \nLabel: Neural Networks\n\nPaper id: 747\nTitle: Title: Cholinergic suppression of transmission may allow combined associative memory function and self-organization in the neocortex.  \n\nPaper id: 2228\nTitle: Title: Modeling dynamic receptive field changes in primary visual cortex using inhibitory learning  \nLabel: Neural Networks\n\nPaper id: 355\nTitle: Title: Generalization and Exclusive Allocation of Credit in Unsupervised Category Learning  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1679\nTitle: Title: Machine learning in prognosis of the femoral neck fracture recovery examples, estimating attributes, explanation ability,\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 627\nTitle: Title: Learning Symbolic Rules Using Artificial Neural Networks  \n\nPaper id: 1569\nTitle: Title: Estimating Attributes: Analysis and Extensions of RELIEF  \nLabel: Rule Learning\n\nPaper id: 1726\nTitle: Title: Prognosing the Survival Time of the Patients with the Anaplastic Thyroid Carcinoma with Machine Learning  \nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1182\nTitle: Title: Overcoming the myopia of inductive learning algorithms with RELIEFF  \nLabel: Rule Learning\n\nPaper id: 1011\nTitle: Title: Discretization of continuous attributes using ReliefF  \nLabel: Rule Learning\n\nPaper id: 208\nTitle: Title: Feature Subset Selection as Search with Probabilistic Estimates  \nLabel: Theory\n\nPaper id: 338\nTitle: Title: Knowledge Integration and Rule Extraction in Neural Networks Ph.D. Proposal  \nLabel: Neural Networks\n\nPaper id: 1008\nTitle: Title: Induction of decision trees using RELIEFF  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 880\nTitle: Title: Control of Parallel Population Dynamics by Social-Like Behavior of GA-Individuals  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 815\nTitle: Title: Genetic Algorithm based Scheduling in a Dynamic Manufacturing Environment  \n\nPaper id: 1523\nTitle: Title: A Generalized Permutation Approach to Job Shop Scheduling with Genetic Algorithms  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 813\nTitle: Title: The Application of a Parallel Genetic Algorithm to the n=m=P=C max Flowshop Problem  \nLabel: Genetic Algorithms\n\nPaper id: 1060\nTitle: Title: An Overview of Genetic Algorithms Part 1, Fundamentals  \n\nPaper id: 1136\nTitle: Title: Using Neural Networks and Genetic Algorithms as Heuristics for NP-Complete Problems  \n\nPaper id: 343\nTitle: Title: A Promising genetic Algorithm Approach to Job-Shop Scheduling, Rescheduling, and Open-Shop Scheduling Problems  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1415\nTitle: Title: A New Approach for Induction: From a Non-Axiomatic Logical Point of View  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1504\nTitle: Title: From Inheritance Relation to Non-Axiomatic Logic  \n\nPaper id: 1506\nTitle: Title: Non-Axiomatic Reasoning System (Version 2.2) used to show how the system works. The limitations of\nLabel: Probabilistic Methods\n\nPaper id: 1525\nTitle: Title: Reference Classes and Multiple Inheritances  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1108\nTitle: Title: Confidence as Higher Order Uncertainty proposed for handling higher order uncertainty, including the Bayesian approach,\nLabel: Probabilistic Methods\n\nPaper id: 1276\nTitle: Title: Heuristics and Normative Models of Judgment under Uncertainty  \nLabel: Probabilistic Methods\n\nPaper id: 1503\nTitle: Title: Belief Revision in Probability Theory  \nLabel: Probabilistic Methods\n\nPaper id: 1308\nTitle: Title: A Defect in Dempster-Shafer Theory  \nLabel: Probabilistic Methods\n\nPaper id: 1507\nTitle: Title: A Unified Treatment of Uncertainties  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1139\nTitle: Title: Optimal Mutation Rates in Genetic Search  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 780\nTitle: Title: Between-host evolution of mutation-rate and within-host evolution of virulence.  \nLabel: Genetic Algorithms\n\nPaper id: 1598\nTitle: Title: Mutation Rates as Adaptations  \nLabel: Genetic Algorithms\n\nPaper id: 793\nTitle: Title: A Survey of Evolution Strategies  \nLabel: Genetic Algorithms\n\nPaper id: 1572\nTitle: Title: The Coevolution of Mutation Rates  \nLabel: Genetic Algorithms\n\nPaper id: 1018\nTitle: Title: Simulated Annealing for Hard Satisfiability Problems  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2298\nTitle: Title: Convergence Analysis of Canonical Genetic Algorithms  \n\nPaper id: 2204\nTitle: Title: University of Nevada Reno Design Strategies for Evolutionary Robotics  \nLabel: Genetic Algorithms\n\nPaper id: 1530\nTitle: Title: Performance of Multi-Parent Crossover Operators on Numerical Function Optimization Problems  \nLabel: Genetic Algorithms\n\nPaper id: 1807\nTitle: Title: A Preliminary Investigation of Evolution as a Form Design Strategy  \nLabel: Genetic Algorithms\n\nPaper id: 2177\nTitle: Title: Analyzing Social Network Structures in the Iterated Prisoner's Dilemma with Choice and Refusal  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 955\nTitle: Title: Separating Formal Bounds from Practical Performance in Learning Systems  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 109\nTitle: Title: A General Lower Bound on the Number of Examples Needed for Learning  \nLabel: Theory\n\nPaper id: 560\nTitle: Title: Bayesian Methods for Adaptive Models  \nLabel: Theory\n\nPaper id: 1280\nTitle: Title: Theory and Practice of Vector Quantizers Trained on Small Training Sets  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 635\nTitle: Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features  \n\nPaper id: 884\nTitle: Title: PAC Learning of One-Dimensional Patterns  \n\nPaper id: 640\nTitle: Title: Learning in the Presence of Malicious Errors  \n\nPaper id: 1888\nTitle: Title: Approximating Hyper-Rectangles: Learning and Pseudo-random Sets  \nLabel: Theory\n\nPaper id: 78\nTitle: Title: Probabilistic Networks: New Models and New Methods  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2431\nTitle: Title: Multi-class problems and discretization in ICL Extended abstract  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1919\nTitle: Title: Inductive Constraint Logic and the Mutagenesis Problem  \n\nPaper id: 2591\nTitle: Title: Lookahead and Discretization in ILP  \n\nPaper id: 426\nTitle: Title: Rule Induction with CN2: Some Recent Improvements  \nLabel: Rule Learning\n\nPaper id: 2426\nTitle: Title: Inductive Constraint Logic  \nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2493\nTitle: Title: Relational Knowledge Discovery in Databases  \nLabel: Rule Learning\n\nPaper id: 1528\nTitle: Title: Using Qualitative Models to Guide Inductive Learning  \n\nPaper id: 1187\nTitle: Title: Rationality and Intelligence  \nLabel: Theory\n\nPaper id: 335\nTitle: Title: Incremental Reduced Error Pruning  \n\nPaper id: 2126\nTitle: Title: Applying ILP to Diterpene Structure Elucidation from 13 C NMR Spectra  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1158\nTitle: Title: Stochastic Complexity Based Estimation of Missing Elements in Questionnaire Data  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1555\nTitle: Title: Bayesian and Information-Theoretic Priors for Bayesian Network Parameters  \nLabel: Probabilistic Methods\n\nPaper id: 1550\nTitle: Title: MDL and MML Similarities and Differences (Introduction to Minimum Encoding Inference Part III)  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1238\nTitle: Title: On Pruning and Averaging Decision Trees  \n\nPaper id: 84\nTitle: Title: Approximate Bayes Factors and Accounting for Model Uncertainty in Generalized Linear Models  \nLabel: Probabilistic Methods\n\nPaper id: 1624\nTitle: Title: Causal Discovery via MML  \nLabel: Probabilistic Methods\n\nPaper id: 1419\nTitle: Title: BAYESIAN ESTIMATION OF THE VON MISES CONCENTRATION PARAMETER  \nLabel: Probabilistic Methods\n\nPaper id: 558\nTitle: Title: A Tutorial on Learning With Bayesian Networks  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1219\nTitle: Title: Putting the Genetics back into Genetic Algorithms  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1153\nTitle: Title: Evolution in Time and Space The Parallel Genetic Algorithm  \n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1558\nTitle: Title: How good are genetic algorithms at finding large cliques: an experimental study  \nLabel: Genetic Algorithms\n\nPaper id: 1063\nTitle: Title: An Analysis of the Effects of Neighborhood Size and Shape on Local Selection Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 1065\nTitle: Title: A Survey of Parallel Genetic Algorithms  \n\nPaper id: 2200\nTitle: Title: Adaptation in constant utility non-stationary environments  \n\nPaper id: 2451\nTitle: Title: Automatic Design of Cellular Neural Networks by means of Genetic Algorithms: Finding a Feature Detector\nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1981\nTitle: Title: Task and Spatial Frequency Effects on Face Specialization  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2491\nTitle: Title: Prosopagnosia in Modular Neural Network Models  \nLabel: Neural Networks\n\nPaper id: 1915\nTitle: Title: A Mixture of Experts Model Exhibiting Prosopagnosia  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2497\nTitle: Title: Learning a Specialization for Face Recognition: The Effect of Spatial Frequency  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 75\nTitle: Title: A Memory Model for Case Retrieval by Activation Passing  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 288\nTitle: Title: A Formal Analysis of Case Base Retrieval  \nLabel: Case Based\n\nPaper id: 1123\nTitle: Title: MAC/FAC: A Model of Similarity-based Retrieval  \nLabel: Case Based\n\nPaper id: 2122\nTitle: Title: Preparing Case Retrieval Nets for Distributed Processing  \nLabel: Case Based\n\nPaper id: 1354\nTitle: Title: The Structure-Mapping Engine: Algorithm and Examples  \n\nPaper id: 1855\nTitle: Title: Applying Case Retrieval Nets to Diagnostic Tasks in Technical Domains  \nLabel: Case Based\n\nPaper id: 1854\nTitle: Title: Case Retrieval Nets: Basic Ideas and Extensions  \nLabel: Case Based\n\nPaper id: 2299\nTitle: Title: Case Retrieval Nets Applied to Large Case Bases  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1317\nTitle: Title: Use of Analogy in Automated Theorem Proving  \nLabel: Case Based\n\nPaper id: 1089\nTitle: Title: Modeling Analogical Problem Solving in a Production System Architecture  \nLabel: Case Based\n\nPaper id: 541\nTitle: Title: Task-Oriented Knowledge Acquisition and Reasoning for Design Support Systems  \nLabel: Case Based\n\nPaper id: 2048\nTitle: Title: Technical Diagnosis: Fallexperte-D of further knowledge sources (domain knowledge, common knowledge) is investigated in the\nLabel: Case Based\n\nPaper id: 1176\nTitle: Title: Distributed Representations and Nested Compositional Structure  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 11\nTitle: Title: Simple Genetic Programming for Supervised Learning Problems  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 659\nTitle: Title: Trading Spaces: Computation, Representation and the Limits of Uninformed Learning  \n\nPaper id: 624\nTitle: Title: Measuring the Difficulty of Specific Learning Problems  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 695\nTitle: Title: There is No Free Lunch but the Starter is Cheap: Generalisation from First Principles  \nLabel: Theory\n\nPaper id: 112\nTitle: Title: Interpretable Neural Networks with BP-SOM  \nLabel: Neural Networks\n\nPaper id: 700\nTitle: Title: Is Transfer Inductive?  \nLabel: Theory\n\nPaper id: 397\nTitle: Title: Truth-from-Trash Learning and the Mobot  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2088\nTitle: Title: A Probabilistic Calculus of Actions  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 248\nTitle: Title: Probabilistic evaluation of sequential plans from causal models with hidden variables  \nLabel: Probabilistic Methods\n\nPaper id: 776\nTitle: Title: CAUSATION, ACTION, AND COUNTERFACTUALS  \nLabel: Probabilistic Methods\n\nPaper id: 2525\nTitle: Title: Bayesian Networks  \nLabel: Probabilistic Methods\n\nPaper id: 1527\nTitle: Title: A THEORY OF INFERRED CAUSATION perceive causal relationships in uncon trolled observations. 2. the task\n\nPaper id: 2524\nTitle: Title: ADAPTIVE LOOK-AHEAD PLANNING problem of finding good initial plans is solved by the use of\nLabel: Probabilistic Methods\n\nPaper id: 2167\nTitle: Title: Counterfactuals and Policy Analysis in Structural Models  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2166\nTitle: Title: Probabilistic evaluation of counterfactual queries  \nLabel: Probabilistic Methods\n\nPaper id: 1086\nTitle: Title: An Algorithm for the Construction of Bayesian Network Structures from Data  \nLabel: Probabilistic Methods\n\nPaper id: 827\nTitle: Title: Two Algorithms for Inducing Structural Equation Models from Data  \nLabel: Probabilistic Methods\n\nPaper id: 1326\nTitle: Title: Causal diagrams for empirical research  \nLabel: Probabilistic Methods\n\nPaper id: 2561\nTitle: Title: MDL Learning of Probabilistic Neural Networks for Discrete Problem Domains  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2633\nTitle: Title: Learning Using Group Representations (Extended Abstract)  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2182\nTitle: Title: Weakly Learning DNF and Characterizing Statistical Query Learning Using Fourier Analysis  \n\nPaper id: 2011\nTitle: Title: An O(n log log n Learning Algorithm for DNF under the Uniform Distribution  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 591\nTitle: Title: Toward Efficient Agnostic Learning  \nLabel: Theory\n\nPaper id: 2146\nTitle: Title: On Learning Read-k-Satisfy-j DNF  \n\nPaper id: 1748\nTitle: Title: A Quantum Computational Learning Algorithm  \nLabel: Theory\n\nPaper id: 1897\nTitle: Title: On Learning Visual Concepts and DNF Formulae  \nLabel: Theory\n\nPaper id: 1835\nTitle: Title: Implementation Issues in the Fourier Transform Algorithm  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2301\nTitle: Title: editors. Representing Preferences as Ceteris Paribus Comparatives  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1901\nTitle: Title: Learning Convex Sets of Probability from Data  \nLabel: Probabilistic Methods\n\nPaper id: 1907\nTitle: Title: Toward Rational Planning and Replanning Rational Reason Maintenance, Reasoning Economies, and Qualitative Preferences formal notions\nLabel: Probabilistic Methods\n\nPaper id: 2588\nTitle: Title: Some recent ideas on utility (and probability) (not for distribution or reference)  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1995\nTitle: Title: Rationality and its Roles in Reasoning  \nLabel: Probabilistic Methods\n\nPaper id: 1800\nTitle: Title: Rational Belief Revision (Preliminary Report)  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 884\nTitle: Title: PAC Learning of One-Dimensional Patterns  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1658\nTitle: Title: Learning One-Dimensional Geometric Patterns Under One-Sided Random Misclassification Noise  \nLabel: Theory\n\nPaper id: 109\nTitle: Title: A General Lower Bound on the Number of Examples Needed for Learning  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2053\nTitle: Title: On the Complexity of Learning from Drifting Distributions  \nLabel: Theory\n\nPaper id: 672\nTitle: Title: Cryptographic Limitations on Learning Boolean Formulae and Finite Automata  \nLabel: Theory\n\nPaper id: 640\nTitle: Title: Learning in the Presence of Malicious Errors  \n\nPaper id: 488\nTitle: Title: Prediction, Learning, Uniform Convergence, and Scale-sensitive Dimensions  \n\nPaper id: 778\nTitle: Title: On the Sample Complexity of Noise-Tolerant Learning  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 496\nTitle: Title: BRAINSTRUCTURED CONNECTIONIST NETWORKS THAT PERCEIVE AND LEARN  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 663\nTitle: Title: Perceptual Development and Learning: From Behavioral, Neurophysiological, and Morphological Evidence To Computational Models  \n\nPaper id: 2393\nTitle: Title: Coordination and Control Structures and Processes: Possibilities for Connectionist Networks (CN)  \n\nPaper id: 501\nTitle: Title: Some Biases for Efficient Learning of Spatial, Temporal, and Spatio-Temporal Patterns  \nLabel: Neural Networks\n\nPaper id: 1896\nTitle: Title: Experiments with the Cascade-Correlation Algorithm  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1851\nTitle: Title: Faster Learning in Multi-Layer Networks by Handling  \nLabel: Neural Networks\n\nPaper id: 503\nTitle: Title: Generative Learning Structures and Processes for Generalized Connectionist Networks  \nLabel: Neural Networks\n\nPaper id: 2029\nTitle: Title: A Simple Randomized Quantization Algorithm for Neural Network Pattern Classifiers  \nLabel: Neural Networks\n\nPaper id: 174\nTitle: Title: Symbolic and Subsymbolic Learning for Vision: Some Possibilities  \nLabel: Neural Networks\n\nPaper id: 1952\nTitle: Title: Analysis of Decision Boundaries Generated by Constructive Neural Network Learning Algorithms  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1819\nTitle: Title: The Difficulties of Learning Logic Programs with Cut  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 224\nTitle: Title: on Inductive Logic Programming (ILP-95) Inducing Logic Programs without Explicit Negative Examples  \nLabel: Rule Learning\n\nPaper id: 1781\nTitle: Title: Learning Singly-Recursive Relations from Small Datasets  \n\nPaper id: 2580\nTitle: Title: The Challenge of Revising an Impure Theory  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 136\nTitle: Title: Theory Refinement Combining Analytical and Empirical Methods  \nLabel: Rule Learning\n\nPaper id: 2663\nTitle: Title: Inverting Implication with Small Training Sets  \nLabel: Rule Learning\n\nPaper id: 52\nTitle: Title: Theory Revision in Fault Hierarchies  \nLabel: Theory\n\nPaper id: 1601\nTitle: Title: Learning the Past Tense of English Verbs: The Symbolic Pattern Associator vs. Connectionist Models  \nLabel: Neural Networks\n\nPaper id: 597\nTitle: Title: Learning Semantic Grammars with Constructive Inductive Logic Programming  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1515\nTitle: Title: Evolving Optimal Populations with XCS Classifier Systems  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 936\nTitle: Title: XCS Classifier System Reliably Evolves Accurate, Complete, and Minimal Representations for Boolean Functions more complex\nLabel: Reinforcement Learning\n\nPaper id: 1581\nTitle: Title: A Study of the Generalization Capabilities of XCS  \nLabel: Reinforcement Learning\n\nPaper id: 961\nTitle: Title: CFS-C: A Package of Domain Independent Subroutines for Implementing Classifier Systems in Arbitrary, User-Defined Environments.  \nLabel: Genetic Algorithms\n\nPaper id: 1447\nTitle: Title: Model of the Environment to Avoid Local Learning  \nLabel: Reinforcement Learning\n\nPaper id: 988\nTitle: Title: A COMPARISON OF Q-LEARNING AND CLASSIFIER SYSTEMS  \nLabel: Reinforcement Learning\n\nPaper id: 1711\nTitle: Title: Environments with Classifier Systems (Experiments on Adding Memory to XCS)  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2077\nTitle: Title: An Adaptive Penalty Approach for Constrained Genetic-Algorithm Optimization  \nLabel: Genetic Algorithms\n\nPaper id: 2286\nTitle: Title: A Genetic Algorithm for File and Task Placement in a Distributed System  \nLabel: Genetic Algorithms\n\nPaper id: 1410\nTitle: Title: Genetic Algorithm Programming Environments  \nLabel: Genetic Algorithms\n\nPaper id: 982\nTitle: Title: Evolutionary Neural Networks for Value Ordering in Constraint Satisfaction Problems  \nLabel: Genetic Algorithms\n\nPaper id: 346\nTitle: Title: PERCEPTION OF TIME AS PHASE: TOWARD AN ADAPTIVE-OSCILLATOR MODEL OF RHYTHMIC PATTERN PROCESSING 1  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 663\nTitle: Title: Perceptual Development and Learning: From Behavioral, Neurophysiological, and Morphological Evidence To Computational Models  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 496\nTitle: Title: BRAINSTRUCTURED CONNECTIONIST NETWORKS THAT PERCEIVE AND LEARN  \n\nPaper id: 501\nTitle: Title: Some Biases for Efficient Learning of Spatial, Temporal, and Spatio-Temporal Patterns  \nLabel: Neural Networks\n\nPaper id: 2393\nTitle: Title: Coordination and Control Structures and Processes: Possibilities for Connectionist Networks (CN)  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1896\nTitle: Title: Experiments with the Cascade-Correlation Algorithm  \nLabel: Neural Networks\n\nPaper id: 174\nTitle: Title: Symbolic and Subsymbolic Learning for Vision: Some Possibilities  \nLabel: Neural Networks\n\nPaper id: 503\nTitle: Title: Generative Learning Structures and Processes for Generalized Connectionist Networks  \nLabel: Neural Networks\n\nPaper id: 1813\nTitle: Title: Pruning Strategies for the MTiling Constructive Learning Algorithm  \nLabel: Neural Networks\n\nPaper id: 2029\nTitle: Title: A Simple Randomized Quantization Algorithm for Neural Network Pattern Classifiers  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2443\nTitle: Title: Issues in the Integration of Data Mining and Data Visualization Visualizing the Simple Bayesian Classifier  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1339\nTitle: Title: An Analysis of Bayesian Classifiers (1988), involves the formulation of average-case models for specific algorithms\nLabel: Theory\n\nPaper id: 2338\nTitle: Title: Beyond Independence: Conditions for the Optimality of the Simple Bayesian Classifier  \nLabel: Case Based\n\nPaper id: 2343\nTitle: Title: Feature Subset Selection Using the Wrapper Method: Overfitting and Dynamic Search Space Topology  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1618\nTitle: Title: Selection of Relevant Features and Examples in Machine Learning  \nLabel: Theory\n\nPaper id: 1986\nTitle: Title: BOOSTING AND NAIVE BAYESIAN LEARNING  \n\nPaper id: 208\nTitle: Title: Feature Subset Selection as Search with Probabilistic Estimates  \nLabel: Theory\n\nPaper id: 2127\nTitle: Title: NAIVE BAYESIAN LEARNING  Adapted from  \nLabel: Probabilistic Methods\n\nPaper id: 1335\nTitle: Title: A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2432\nTitle: Title: Learning the Peg-into-Hole Assembly Operation with a Connectionist Reinforcement Technique  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1755\nTitle: Title: Learning Controllers from Examples  a motivation for searching alternative, empirical techniques for generating controllers.  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 611\nTitle: Title: Learning networks for face analysis and synthesis  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2076\nTitle: Title: Automated Discovery of Linear Feedback Models 1  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 772\nTitle: Title: [12] J. Whittaker. Graphical Models in Applied Mathematical Multivariate Statis-  \nLabel: Probabilistic Methods\n\nPaper id: 2559\nTitle: Title: \"Linear Dependencies Represented by Chain Graphs,\" \"Graphical Modelling With MIM,\" Manual. \"Identifying Independence in Bayesian\n\nPaper id: 1324\nTitle: Title: [6] D. Geiger. Graphoids: a qualitative framework for probabilistic inference. An introduction to algorithms for\n\nPaper id: 211\nTitle: Title: Using Path Diagrams as a Structural Equation Modelling Tool  \nLabel: Probabilistic Methods\n\nPaper id: 1527\nTitle: Title: A THEORY OF INFERRED CAUSATION perceive causal relationships in uncon trolled observations. 2. the task\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 841\nTitle: Title: Bayesian inference for nondecomposable graphical Gaussian models  \nLabel: Probabilistic Methods\n\nPaper id: 2524\nTitle: Title: ADAPTIVE LOOK-AHEAD PLANNING problem of finding good initial plans is solved by the use of\nLabel: Probabilistic Methods\n\nPaper id: 827\nTitle: Title: Two Algorithms for Inducing Structural Equation Models from Data  \nLabel: Probabilistic Methods\n\nPaper id: 2166\nTitle: Title: Probabilistic evaluation of counterfactual queries  \nLabel: Probabilistic Methods\n\nPaper id: 51\nTitle: Title: An Alternative Markov Property for Chain Graphs  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2331\nTitle: Title: Improved Hoeffding-Style Performance Guarantees for Accurate Classifiers  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2694\nTitle: Title: Partition-Based Uniform Error Bounds  \nLabel: Theory\n\nPaper id: 571\nTitle: Title: The Central Classifier Bound ANew Error Bound for the Classifier Chosen by Early Stopping Key\nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 424\nTitle: Title: Validation of Voting Committees  \nLabel: Theory\n\nPaper id: 2495\nTitle: Title: Similar Classifiers and VC Error Bounds  \nLabel: Theory\n\nPaper id: 1762\nTitle: Title: Improved Uniform Test Error Bounds  \nLabel: Theory\n\nPaper id: 19\nTitle: Title: Validation of Average Error Rate Over Classifiers  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 683\nTitle: Title: On the Greediness of Feature Selection Algorithms  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 632\nTitle: Title: Toward Optimal Feature Selection  \nLabel: Probabilistic Methods\n\nPaper id: 1860\nTitle: Title: Efficient Locally Weighted Polynomial Regression Predictions  \nLabel: Case Based\n\nPaper id: 635\nTitle: Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features  \n\nPaper id: 430\nTitle: Title: Irrelevant Features and the Subset Selection Problem  \nLabel: Theory\n\nPaper id: 686\nTitle: Title: Prototype and Feature Selection by Sampling and Random Mutation Hill Climbing Algorithms  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2430\nTitle: Title: Category: Control, Navigation and Planning Preference: Oral presentation Exploiting Model Uncertainty Estimates for Safe Dynamic\nLabel: Reinforcement Learning\n\nPaper id: 2658\nTitle: Title: Control Systems Magazine, 14, 1, pp.57-71. Robot Juggling: An Implementation of Memory-based Learning  \n\nPaper id: 44\nTitle: Title: Competitive Anti-Hebbian Learning of Invariants  \nLabel: Case Based\n\nPaper id: 1698\nTitle: Title: CBET: a Case Base Exploration Tool  \n\nPaper id: 119\nTitle: Title: Cost-sensitive feature reduction applied to a hybrid genetic algorithm  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2534\nTitle: Title: Data Value Prediction Methods and Performance  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2009\nTitle: Title: The Predictability of Data Values  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1294\nTitle: Title: Representation Requirements for Supporting Decision Model Formulation  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 915\nTitle: Title: Abstract  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1172\nTitle: Title: Introduction to the Special Section on Knowledge-Based Construction of Probabilistic and Decision Models (IEEE Transactions\nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 396\nTitle: Title: Geometric Comparison of Classifications and Rule Sets*  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 478\nTitle: Title: An Improved Algorithm for Incremental Induction of Decision Trees  \nLabel: Case Based\n\nPaper id: 378\nTitle: Title: Mingers, 1989 J. Mingers. An empirical comparison of pruning methods for decision tree induction. Machine\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 692\nTitle: Title: Decision Tree Induction: How Effective is the Greedy Heuristic?  \nLabel: Theory\n\nPaper id: 568\nTitle: Title: Online Learning with Random Representations  \nLabel: Reinforcement Learning\n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n\nPaper id: 1275\nTitle: Title: Fossil: A Robust Relational Learner  \n\nPaper id: 218\nTitle: Title: Learning Classification Trees  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1734\nTitle: Title: A Stochastic Search Approach to Grammar Induction  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 793\nTitle: Title: A Survey of Evolution Strategies  \nLabel: Genetic Algorithms\n\nPaper id: 1715\nTitle: Title: A Sampling-Based Heuristic for Tree Search Applied to Grammar Induction  \n\nPaper id: 1249\nTitle: Title: Evolution of Non-Deterministic Incremental Algorithms as a New Approach for Search in State Spaces  \nLabel: Genetic Algorithms\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 1592\nTitle: Title: A Unified Gradient-Descent/Clustering Architecture for Finite State Machine Induction  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 309\nTitle: Title: The Power of Self-Directed Learning  \nLabel: Genetic Algorithms\n\nPaper id: 191\nTitle: Title: USING MARKER-BASED GENETIC ENCODING OF NEURAL NETWORKS TO EVOLVE FINITE-STATE BEHAVIOUR  \nLabel: Genetic Algorithms\n\nPaper id: 1572\nTitle: Title: The Coevolution of Mutation Rates  \nLabel: Genetic Algorithms\n\nPaper id: 1206\nTitle: Title: Learning Monitoring Strategies: A Difficult Genetic Programming Application  \nLabel: Genetic Algorithms\n\nPaper id: 1113\nTitle: Title: Staged Hybrid Genetic Search for Seismic Data Imaging  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2061\nTitle: Title: Inductive Learning and Case-Based Reasoning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 96\nTitle: Title: Lazy Induction Triggered by CBR  \nLabel: Case Based\n\nPaper id: 215\nTitle: Title: Integration of Case-Based Reasoning and Neural Networks Approaches for Classification  \nLabel: Case Based\n\nPaper id: 2062\nTitle: Title: A Case-Based Reasoning Approach  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2066\nTitle: Title: On the Informativeness of the DNA Promoter Sequences Domain Theory  \nLabel: Theory\n\nPaper id: 438\nTitle: Title: A System for Induction of Oblique Decision Trees  \nLabel: Theory\n\nPaper id: 2052\nTitle: Title: Applying Case-Based Reasoning to Control in Robotics  \nLabel: Case Based\n\nPaper id: 66\nTitle: Title: (1994); Case-Based Reasoning: Foundational Issues, Methodological Variations, and System Approaches. Case-Based Reasoning: Foundational Issues, Methodological\nLabel: Case Based\n\nPaper id: 2380\nTitle: Title: Massively Parallel Case-Based Reasoning with Probabilistic Similarity Metrics  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1823\nTitle: Title: The Complexity of Theory Revision  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2580\nTitle: Title: The Challenge of Revising an Impure Theory  \nLabel: Theory\n\nPaper id: 2487\nTitle: Title: An Optimized Theory Revision Module  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 136\nTitle: Title: Theory Refinement Combining Analytical and Empirical Methods  \nLabel: Rule Learning\n\nPaper id: 430\nTitle: Title: Irrelevant Features and the Subset Selection Problem  \nLabel: Theory\n\nPaper id: 1819\nTitle: Title: The Difficulties of Learning Logic Programs with Cut  \n\nPaper id: 52\nTitle: Title: Theory Revision in Fault Hierarchies  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1974\nTitle: Title: Data Mining for Association Rules with Unsupervised Neural Networks  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 36\nTitle: Title: Generative Models for Discovering Sparse Distributed Representations  \n\nPaper id: 667\nTitle: Title: Recognizing Handwritten Digits Using Mixtures of Linear Models  \nLabel: Neural Networks\n\nPaper id: 2227\nTitle: Title: The EM Algorithm for Mixtures of Factor Analyzers  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 257\nTitle: Title: Factor Analysis Using Delta-Rule Wake-Sleep Learning  \nLabel: Neural Networks\n\nPaper id: 480\nTitle: Title: Modelling the Manifolds of Images of Handwritten Digits  \nLabel: Neural Networks\n\nPaper id: 1356\nTitle: Title: Constraint Tangent Distance for On-line Character Recognition  \nLabel: Neural Networks\n\nPaper id: 867\nTitle: Title: Comparison of Neural and Statistical Classifiers| Theory and Practice  \nLabel: Neural Networks\n\nPaper id: 2072\nTitle: Title: Data Mining for Association Rules with Unsupervised Neural Networks  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2214\nTitle: Title: Behavior Near Zero of the Distribution of GCV Smoothing Parameter Estimates 1  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2223\nTitle: Title: Smoothing Spline Models With Correlated Random Errors 1  \nLabel: Neural Networks\n\nPaper id: 420\nTitle: Title: Sample Size Calculations for Smoothing Splines Based on Bayesian Confidence Intervals  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2590\nTitle: Title: Backfitting in Smoothing Spline ANOVA  \nLabel: Probabilistic Methods\n\nPaper id: 190\nTitle: Title: Spline Smoothing For Bivariate Data With Applications To Association Between Hormones  \n\nPaper id: 510\nTitle: Title: The Bayesian Approach to Tree-Structured Regression  \n\nPaper id: 10\nTitle: Title: GRKPACK: FITTING SMOOTHING SPLINE ANOVA MODELS FOR EXPONENTIAL FAMILIES  \nLabel: Neural Networks\n\nPaper id: 519\nTitle: Title: Smoothing Spline ANOVA for Exponential Families, with Application to the Wisconsin Epidemiological Study of Diabetic\nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1892\nTitle: Title: Abstraction and Decomposition in Hillclimbing Design Optimization  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2131\nTitle: Title: Learning Prototype-Selection Rules for Case-Based Iterative Design seen as a case-based reasoning system [4], in\nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2030\nTitle: Title: Using Modeling Knowledge to Guide Design Space Search  \nLabel: Genetic Algorithms\n\nPaper id: 2319\nTitle: Title: Learning When Reformulation is Appropriate for Iterative Design  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1439\nTitle: Title: Minimum-Perimeter Domain Assignment  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 803\nTitle: Title: Optimal and Asymptotically Optimal Equi-partition of Rectangular Domains via Stripe Decomposition  \nLabel: Genetic Algorithms\n\nPaper id: 53\nTitle: Title: DISTRIBUTED GENETIC ALGORITHMS FOR PARTITIONING UNIFORM GRIDS  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 357\nTitle: Title: Genetic Algorithms as Multi-Coordinators in Large-Scale Optimization  \nLabel: Genetic Algorithms\n\nPaper id: 243\nTitle: Title: Distribution Category:  Users Guide to the PGAPack Parallel Genetic Algorithm Library  \nLabel: Genetic Algorithms\n\nPaper id: 1563\nTitle: Title: Fast EquiPartitioning of Rectangular Domains using Stripe Decomposition  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2435\nTitle: Title: Identification in H 1 with Nonuniformly Spaced Frequency Response Measurements  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2262\nTitle: Title: OPTIMAL ASYMPTOTIC IDENTIFICATION UNDER BOUNDED DISTURBANCES  \nLabel: Neural Networks\n\nPaper id: 2236\nTitle: Title: Robust Convergence of Two-Stage Nonlinear Algorithms for Identification in H 1  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2542\nTitle: Title: Worst-Case Identification of Nonlinear Fading Memory Systems  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2255\nTitle: Title: Evolutionary Learning of the Crossover Operator  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2412\nTitle: Title: On-Line Adaptation of a Signal Predistorter through Dual Reinforcement Learning  \nLabel: Reinforcement Learning\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1914\nTitle: Title: Local Feedforward Networks  \nLabel: Neural Networks\n\nPaper id: 2658\nTitle: Title: Control Systems Magazine, 14, 1, pp.57-71. Robot Juggling: An Implementation of Memory-based Learning  \n\nPaper id: 946\nTitle: Title: Constructive Learning of Recurrent Neural Networks: Limitations of Recurrent Casade Correlation and a Simple Solution  \nLabel: Neural Networks\n\nPaper id: 493\nTitle: Title: Parallel Search for Neural Network  Under the guidance of  \nLabel: Genetic Algorithms\n\nPaper id: 205\nTitle: Title: Beyond the Cognitive Map: Contributions to a Computational Neuroscience Theory of Rodent Navigation for the\nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1821\nTitle: Title: One-unit Learning Rules for Independent Component Analysis  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1801\nTitle: Title: A FAMILY OF FIXED-POINT ALGORITHMS FOR INDEPENDENT COMPONENT ANALYSIS  \nLabel: Neural Networks\n\nPaper id: 834\nTitle: Title: Simple Neuron Models for Independent Component Analysis  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 576\nTitle: Title: An information-maximisation approach to blind separation and blind deconvolution  \nLabel: Neural Networks\n\nPaper id: 1067\nTitle: Title: A Fast Fixed-Point Algorithm for Independent Component Analysis  \nLabel: Neural Networks\n\nPaper id: 1520\nTitle: Title: Equivariant adaptive source separation  \n\nPaper id: 1814\nTitle: Title: Independent Component Analysis by General Non-linear Hebbian-like Learning Rules  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2602\nTitle: Title: A Method for Partial-Memory Incremental Learning and its Application to Computer Intrusion Detection Machine Learning\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2070\nTitle: Title: A Partial Memory Incremental Learning Methodology And Its Application To Computer Intrusion Detection  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2640\nTitle: Title: Learning Evolving Concepts Using Partial-Memory Approach  Machine Learning and Inference Laboratory  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1982\nTitle: Title: Theoretical rates of convergence for Markov chain Monte Carlo  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1713\nTitle: Title: A simulation approach to convergence rates for Markov chain Monte Carlo algorithms  \nLabel: Probabilistic Methods\n\nPaper id: 1716\nTitle: Title: Analysis of the Gibbs sampler for a model related to James-Stein estimators  \nLabel: Probabilistic Methods\n\nPaper id: 41\nTitle: Title: Markov Chain Monte Carlo Convergence Diagnostics: A Comparative Review  \nLabel: Probabilistic Methods\n\nPaper id: 2153\nTitle: Title: Rates of convergence of the Hastings and Metropolis algorithms  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1977\nTitle: Title: A note on acceptance rate criteria for CLTs for Hastings-Metropolis algorithms  \nLabel: Probabilistic Methods\n\nPaper id: 1978\nTitle: Title: Two convergence properties of hybrid samplers  \nLabel: Probabilistic Methods\n\nPaper id: 2699\nTitle: Title: EXACT BOUND FOR THE CONVERGENCE OF METROPOLIS CHAINS  \nLabel: Probabilistic Methods\n\nPaper id: 1992\nTitle: Title: Estimating L 1 Error of Kernel Estimator: Monitoring Convergence of Markov Samplers  \nLabel: Probabilistic Methods\n\nPaper id: 725\nTitle: Title: Maximum Working Likelihood Inference with Markov Chain Monte Carlo  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 253\nTitle: Title: Hyperplane Dynamics as a Means to Understanding Back-Propagation Learning and Network Plasticity  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 15\nTitle: Title: Back Propagation is Sensitive to Initial Conditions  \nLabel: Neural Networks\n\nPaper id: 1815\nTitle: Title: Submitted to Circuits, Systems and Signal Processing Neural Network Constructive Algorithms: Trading Generalization for Learning Efficiency?  \nLabel: Neural Networks\n\nPaper id: 2670\nTitle: Title: A proposal for variable selection in the Cox model  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 489\nTitle: Title: Multiple Network Systems (Minos) Modules: Task Division and Module Discrimination 1  \nLabel: Neural Networks\n\nPaper id: 152\nTitle: Title: Replicability of Neural Computing Experiments  \nLabel: Neural Networks\n\nPaper id: 322\nTitle: Title: Statistical Tests for Comparing Supervised Classification Learning Algorithms  \nLabel: Theory\n\nPaper id: 538\nTitle: Title: Learning and evolution in neural networks  \nLabel: Genetic Algorithms\n\nPaper id: 254\nTitle: Title: Scaling-up RAAMs  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 46\nTitle: Title: The Pandemonium System of Reflective Agents  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 301\nTitle: Title: Data Exploration with Reflective Adaptive Models  \n\nPaper id: 867\nTitle: Title: Comparison of Neural and Statistical Classifiers| Theory and Practice  \nLabel: Neural Networks\n\nPaper id: 238\nTitle: Title: Learning from Examples, Agent Teams and the Concept of Reflection  \nLabel: Neural Networks\n\nPaper id: 489\nTitle: Title: Multiple Network Systems (Minos) Modules: Task Division and Module Discrimination 1  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 747\nTitle: Title: Cholinergic suppression of transmission may allow combined associative memory function and self-organization in the neocortex.  \n\nPaper id: 74\nTitle: Title: Hierarchical Mixtures of Experts and the EM Algorithm  \nLabel: Probabilistic Methods\n\nPaper id: 193\nTitle: Title: Soft Classification, a.k.a. Risk Estimation, via Penalized Log Likelihood and Smoothing Spline Analysis of Variance  \nLabel: Neural Networks\n\nPaper id: 2670\nTitle: Title: A proposal for variable selection in the Cox model  \nLabel: Neural Networks\n\nPaper id: 1815\nTitle: Title: Submitted to Circuits, Systems and Signal Processing Neural Network Constructive Algorithms: Trading Generalization for Learning Efficiency?  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 728\nTitle: Title: On the Virtues of Parameterized Uniform Crossover  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 243\nTitle: Title: Distribution Category:  Users Guide to the PGAPack Parallel Genetic Algorithm Library  \nLabel: Genetic Algorithms\n\nPaper id: 943\nTitle: Title: Crossover or Mutation?  \nLabel: Genetic Algorithms\n\nPaper id: 1466\nTitle: Title: A STUDY OF CROSSOVER OPERATORS IN GENETIC PROGRAMMING  \nLabel: Genetic Algorithms\n\nPaper id: 1016\nTitle: Title: An Analysis of the Interacting Roles of Population Size and Crossover in Genetic Algorithms  \n\nPaper id: 1305\nTitle: Title: Distribution Category:  A Parallel Genetic Algorithm for the Set Partitioning Problem  \nLabel: Genetic Algorithms\n\nPaper id: 1127\nTitle: Title: Recombination Operator, its Correlation to the Fitness Landscape and Search Performance  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1070\nTitle: Title: Extended Selection Mechanisms in Genetic Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 1646\nTitle: Title: Generation Gaps Revisited  \nLabel: Genetic Algorithms\n\nPaper id: 53\nTitle: Title: DISTRIBUTED GENETIC ALGORITHMS FOR PARTITIONING UNIFORM GRIDS  \nLabel: Genetic Algorithms\n\nPaper id: 1729\nTitle: Title: Adapting Crossover in a Genetic Algorithm  \nLabel: Genetic Algorithms\n\nPaper id: 1110\nTitle: Title: On The State of Evolutionary Computation  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2700\nTitle: Title: Probabilistic Reasoning under Ignorance  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2698\nTitle: Title: Forecasting Glucose Concentration in Diabetic Patients using Ignorant Belief Networks  \nLabel: Probabilistic Methods\n\nPaper id: 2697\nTitle: Title: Belief Maintenance with Probabilistic Logic  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1759\nTitle: Title: Belief Maintenance in Bayesian Networks  \n\nPaper id: 2288\nTitle: Title: Anytime Influence Diagrams  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1884\nTitle: Title: Using Neural Networks to Identify Jets  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1885\nTitle: Title: LU TP 90-3 Finding Gluon Jets with a Neural Trigger  \nLabel: Neural Networks\n\nPaper id: 1902\nTitle: Title: LU TP 91-25 Mass Reconstruction with a Neural Network  \nLabel: Neural Networks\n\nPaper id: 745\nTitle: Title: References \"Using Neural Networks to Identify Jets\", Kohonen, \"Self Organized Formation of Topologically Correct Feature\nLabel: Neural Networks\n\nPaper id: 1886\nTitle: Title: LU TP 91-4 Self-organizing Networks for Extracting Jet Features  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2336\nTitle: Title: A Fast Kohonen Net Implementation for  \n\nPaper id: 1564\nTitle: Title: GROWING RADIAL BASIS FUNCTION NETWORKS  \nLabel: Neural Networks\n\nPaper id: 72\nTitle: Title: SCRIPT RECOGNITION WITH HIERARCHICAL FEATURE MAPS  \nLabel: Neural Networks\n\nPaper id: 1887\nTitle: Title: LU TP 93-13 On Langevin Updating in Multilayer Perceptrons  \nLabel: Neural Networks\n\nPaper id: 124\nTitle: Title: Self-Organization and Segmentation in a Laterally Connected Orientation Map of Spiking Neurons  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1153\nTitle: Title: Evolution in Time and Space The Parallel Genetic Algorithm  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 856\nTitle: Title: Hierarchical priors and mixture models, with application in regression and density estimation  \nLabel: Genetic Algorithms\n\nPaper id: 1070\nTitle: Title: Extended Selection Mechanisms in Genetic Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 1611\nTitle: Title: Island Model Genetic Algorithms and Linearly Separable Problems  \nLabel: Genetic Algorithms\n\nPaper id: 1219\nTitle: Title: Putting the Genetics back into Genetic Algorithms  \n\nPaper id: 1455\nTitle: Title: Self-Adaptation in Genetic Algorithms of external parameters of a GA is seen as a first\nLabel: Genetic Algorithms\n\nPaper id: 1127\nTitle: Title: Recombination Operator, its Correlation to the Fitness Landscape and Search Performance  \nLabel: Genetic Algorithms\n\nPaper id: 1410\nTitle: Title: Genetic Algorithm Programming Environments  \nLabel: Genetic Algorithms\n\nPaper id: 942\nTitle: Title: Genetic Programming Methodology, Parallelization and Applications  par  \nLabel: Genetic Algorithms\n\nPaper id: 1204\nTitle: Title: The Role of Development in Genetic Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 1675\nTitle: Title: A Study of Genetic Algorithms to Find Approximate Solutions to Hard 3CNF Problems  \nLabel: Genetic Algorithms\n\nPaper id: 1065\nTitle: Title: A Survey of Parallel Genetic Algorithms  \n\nPaper id: 1113\nTitle: Title: Staged Hybrid Genetic Search for Seismic Data Imaging  \nLabel: Genetic Algorithms\n\nPaper id: 1205\nTitle: Title: The Role of Development in Genetic Algorithms  \n\nPaper id: 1257\nTitle: Title: The Schema Theorem and Price's Theorem  \n\nPaper id: 1063\nTitle: Title: An Analysis of the Effects of Neighborhood Size and Shape on Local Selection Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 1077\nTitle: Title: A Search Space Analysis of the Job Shop Scheduling Problem  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1594\nTitle: Title: An Evolutionary Approach to Vector Quantizer Design  \nLabel: Genetic Algorithms\n\nPaper id: 1696\nTitle: Title: The Royal Road for Genetic Algorithms: Fitness Landscapes and GA Performance  \n\nPaper id: 1279\nTitle: Title: Speeding up Genetic Programming: A Parallel BSP implementation the Bulk Synchronous Parallel Pro gramming (BSP)\nLabel: Genetic Algorithms\n\nPaper id: 1016\nTitle: Title: An Analysis of the Interacting Roles of Population Size and Crossover in Genetic Algorithms  \n\nPaper id: 1573\nTitle: Title: Genetics-based Machine Learning and Behaviour Based Robotics: A New Synthesis complexity grows, the learning task\nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1209\nTitle: Title: S o l u t i o n Relevant A b s t r a\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1215\nTitle: Title: Supporting Combined Human and Machine Planning: An Interface for Planning by Analogical Reasoning  \n\nPaper id: 539\nTitle: Title: Structural Similarity as Guidance in Case-Based Design  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1210\nTitle: Title: Structural Similarity and Adaptation  \nLabel: Case Based\n\nPaper id: 1665\nTitle: Title: Conceptual Analogy: Conceptual clustering for informed and efficient analogical reasoning  \nLabel: Case Based\n\nPaper id: 183\nTitle: Title: Conceptual Analogy  \nLabel: Case Based\n\nPaper id: 1699\nTitle: Title: On the Usefulness of Re-using Diagnostic Solutions  \nLabel: Case Based\n\nPaper id: 819\nTitle: Title: A Case Study of Case-Based CBR  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2510\nTitle: Title: Geometric Ergodicity and Hybrid Markov Chains  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 416\nTitle: Title: A note on convergence rates of Gibbs sampling for nonparametric mixtures  \nLabel: Probabilistic Methods\n\nPaper id: 1713\nTitle: Title: A simulation approach to convergence rates for Markov chain Monte Carlo algorithms  \nLabel: Probabilistic Methods\n\nPaper id: 2002\nTitle: Title: Geometric Ergodicity of Gibbs and Block Gibbs Samplers for a Hierarchical Random Effects Model  \nLabel: Probabilistic Methods\n\nPaper id: 1977\nTitle: Title: A note on acceptance rate criteria for CLTs for Hastings-Metropolis algorithms  \nLabel: Probabilistic Methods\n\nPaper id: 1991\nTitle: Title: APPLICATIONS OF CHEEGER'S CONSTANT TO THE CONVERGENCE RATE OF MARKOV CHAINS ON R n  \nLabel: Probabilistic Methods\n\nPaper id: 1978\nTitle: Title: Two convergence properties of hybrid samplers  \nLabel: Probabilistic Methods\n\nPaper id: 2362\nTitle: Title: Outperforming the Gibbs sampler empirical estimator for nearest neighbor random fields  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1982\nTitle: Title: Theoretical rates of convergence for Markov chain Monte Carlo  \n\nPaper id: 1913\nTitle: Title: A Note on the Dirichlet Process Prior in Bayesian Nonparametric Inference with Partial Exchangeability 1  \nLabel: Probabilistic Methods\n\nPaper id: 468\nTitle: Title: Adaptive Markov Chain Monte Carlo through Regeneration  Summary  \nLabel: Probabilistic Methods\n\nPaper id: 2318\nTitle: Title: EXACT TRANSITION PROBABILITIES FOR THE INDEPENDENCE METROPOLIS SAMPLER  \nLabel: Probabilistic Methods\n\nPaper id: 889\nTitle: Title: Bounding Convergence Time of the Gibbs Sampler in Bayesian Image Restoration  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1445\nTitle: Title: Theory-guided Empirical Speedup Learning of Goal Decomposition Rules  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 414\nTitle: Title: Acquiring Recursive and Iterative Concepts with Explanation-Based Learning explanation-based generalization, generalizing explanation structures, generalizing to\nLabel: Case Based\n\nPaper id: 1442\nTitle: Title: Learning Goal-Decomposition Rules using Exercises  \nLabel: Rule Learning\n\nPaper id: 344\nTitle: Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In\nLabel: Rule Learning\n\nPaper id: 675\nTitle: Title: Combining FOIL and EBG to Speed-up Logic Programs  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1\nTitle: Title: Applications of machine learning: a medical follow up study  \n\nPaper id: 521\nTitle: Title: Covering vs. Divide-and-Conquer for Top-Down Induction of Logic Programs  \nLabel: Rule Learning\n\nPaper id: 2339\nTitle: Title: An intelligent search method using Inductive Logic Programming  \nLabel: Rule Learning\n\nPaper id: 1260\nTitle: Title: Transferring and Retraining Learned Information Filters  \nLabel: Theory\n\nPaper id: 2609\nTitle: Title: ILP with Noise and Fixed Example Size: A Bayesian Approach  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 960\nTitle: Title: Proceedings of the First International Workshop on Intelligent Adaptive Systems (IAS-95) Constructive Induction-based Learning Agents:\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 378\nTitle: Title: Mingers, 1989 J. Mingers. An empirical comparison of pruning methods for decision tree induction. Machine\n\nPaper id: 1292\nTitle: Title: CONSTRUCTIVE INDUCTION FROM DATA IN AQ17-DCI: Further Experiments  \nLabel: Rule Learning\n\nPaper id: 1301\nTitle: Title: Discovering Representation Space Transformations for Learning Concept Descriptions Combining DNF and M-of-N Rules  \nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2447\nTitle: Title: New Roles for Machine Learning in Design for Design of Educational Computing New roles for\nLabel: Case Based\n\nPaper id: 1266\nTitle: Title: A Hypothesis-driven Constructive Induction Approach to Expanding Neural Networks  \nLabel: Neural Networks\n\nPaper id: 2042\nTitle: Title: Fast Bounded Smooth Regression with Lazy Neural Trees  \nLabel: Neural Networks\n\nPaper id: 1290\nTitle: Title: A THEORY OF LEARNING CLASSIFICATION RULES  \nLabel: Theory\n\nPaper id: 1027\nTitle: Title: Pessimistic decision tree pruning based on tree size  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 515\nTitle: Title: Sensitivities: An Alternative to Conditional Probabilities for Bayesian Belief Networks  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2164\nTitle: Title: Efficient Inference in Bayes Networks As A Combinatorial Optimization Problem  \nLabel: Probabilistic Methods\n\nPaper id: 637\nTitle: Title: Computational complexity reduction for BN2O networks using similarity of states  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 5\nTitle: Title: Some Experiments with Real-time Decision Algorithms  \nLabel: Probabilistic Methods\n\nPaper id: 623\nTitle: Title: State-Space Abstraction for Anytime Evaluation of Probabilistic Networks  \n\nPaper id: 2094\nTitle: Title: Interpretation of Complex Scenes Using Bayesian Networks  \nLabel: Probabilistic Methods\n\nPaper id: 1749\nTitle: Title: Algebraic Techniques for Efficient Inference in Bayesian Networks  \nLabel: Probabilistic Methods\n\nPaper id: 2521\nTitle: Title: Case-Based Probability Factoring in Bayesian Belief Networks  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 466\nTitle: Title: On the Computational Economics of Reinforcement Learning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 16\nTitle: Title: Exploration in Active Learning  \n\nPaper id: 294\nTitle: Title: References elements that can solve difficult learning control problems. on Simulation of Adaptive Behavior, pages\nLabel: Reinforcement Learning\n\nPaper id: 566\nTitle: Title: Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming  \nLabel: Reinforcement Learning\n\nPaper id: 465\nTitle: Title: Strategy Learning with Multilayer Connectionist Representations 1  \nLabel: Reinforcement Learning\n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n\nPaper id: 552\nTitle: Title: Learning to Act using Real-Time Dynamic Programming  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 298\nTitle: Title: How to Dynamically Merge Markov Decision Processes  \nLabel: Reinforcement Learning\n\nPaper id: 2221\nTitle: Title: Reasoning about Time and Probability  \nLabel: Probabilistic Methods\n\nPaper id: 1316\nTitle: Title: KnightCap: A chess program that learns by combining TD() with minimax search  \nLabel: Reinforcement Learning\n\nPaper id: 575\nTitle: Title: Issues in Using Function Approximation for Reinforcement Learning  \nLabel: Reinforcement Learning\n\nPaper id: 473\nTitle: Title: Improving Policies without Measuring Merits  \nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2414\nTitle: Title: On-Line Adaptation of a Signal Predistorter through Dual Reinforcement Learning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1366\nTitle: Title: ``Learning Local Error Bars for Nonlinear Regression.''  Learning Local Error Bars for Nonlinear Regression  \nLabel: Neural Networks\n\nPaper id: 2373\nTitle: Title: Evaluating Neural Network Predictors by Bootstrapping  \nLabel: Neural Networks\n\nPaper id: 1718\nTitle: Title: PREDICTING SUNSPOTS AND EXCHANGE RATES WITH CONNECTIONIST NETWORKS  \nLabel: Neural Networks\n\nPaper id: 668\nTitle: Title: Nonlinear gated experts for time series: discovering regimes and avoiding overfitting  \nLabel: Neural Networks\n\nPaper id: 2239\nTitle: Title: Predicting Conditional Probability Distributions: A Connectionist Approach  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 916\nTitle: Title: A comparison of some error estimates for neural network models  Summary  \nLabel: Neural Networks\n\nPaper id: 2374\nTitle: Title: Predictions with Confidence Intervals (Local Error Bars)  \nLabel: Neural Networks\n\nPaper id: 28\nTitle: Title: A Delay Damage Model Selection Algorithm for NARX Neural Networks  \nLabel: Neural Networks\n\nPaper id: 2513\nTitle: Title: Avoiding overfitting by locally matching the noise level of the data gating network discovers the\n\nPaper id: 1315\nTitle: Title: Modeling Volatility using State Space Models  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1676\nTitle: Title: TD Learning of Game Evaluation Functions with Hierarchical Neural Architectures  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 207\nTitle: Title: LEARNING BY ERROR-DRIVEN DECOMPOSITION  \nLabel: Neural Networks\n\nPaper id: 1146\nTitle: Title: The optimal number of learning samples and hidden units in function approximation with a feedforward network  \nLabel: Neural Networks\n\nPaper id: 523\nTitle: Title: Some studies in machine learning using the game of checkers. IBM Journal, 3(3):211-229, 1959. Some\nLabel: Genetic Algorithms\n\nPaper id: 74\nTitle: Title: Hierarchical Mixtures of Experts and the EM Algorithm  \nLabel: Probabilistic Methods\n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 975\nTitle: Title: State Reconstruction for Determining Predictability in Driven Nonlinear Acoustical Systems  \n\nPaper id: 1634\nTitle: Title: Combining Linear Discriminant Functions with Neural Networks for Supervised Learning  \n\nPaper id: 367\nTitle: Title: Machine Learning,  Explanation-Based Learning and Reinforcement Learning: A Unified View  \nLabel: Reinforcement Learning\n\nPaper id: 333\nTitle: Title: A Comparison of Action Selection Learning Methods  \nLabel: Reinforcement Learning\n\nPaper id: 2124\nTitle: Title: A Hierarchical Latent Variable Model for Data Visualization  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2352\nTitle: Title: Power System Security Margin Prediction Using Radial Basis Function Networks  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2055\nTitle: Title: 1 FEATURE SUBSET SELECTION USING A GENETIC ALGORITHM time needed for learning a sufficiently accurate\nLabel: Genetic Algorithms\n\nPaper id: 611\nTitle: Title: Learning networks for face analysis and synthesis  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1668\nTitle: Title: Space-Frequency Localized Basis Function Networks for Nonlinear System Estimation and Control  \nLabel: Neural Networks\n\nPaper id: 2505\nTitle: Title: Three-Dimensional Object Recognition Using an Unsupervised BCM Network: The Usefulness of Distinguishing Features  \nLabel: Neural Networks\n\nPaper id: 179\nTitle: Title: for Projective Basis Function Networks 2m1 Global Form 2m Local Form With appropriate constant factors,\nLabel: Neural Networks\n\nPaper id: 1103\nTitle: Reference: [39] <author> Yoda, M. </author> <year> (1994). </year> <title> Predicting the Tokyo stock market. </title> <editor> In Deboeck, G.J. (Ed.) </editor> <year> (1994). </year> <title> Trading on the Edge. </title> <address> New York: </address> <publisher> Wiley., </publisher> <pages> 66-79. </pages> <institution> VITA Graduate School Southern Illinois University Daniel Nikolaev Nikovski Date of Birth: </institution> <address> April 13, 1969 606 West College Street, Apt.4, Rm. 6, Carbondale, Illinois 62901 150 Hristo Botev Boulevard, Apt. </address> <month> 54, </month> <title> 4004 Plovdiv, Bulgaria Technical University - Sofia, Bulgaria Engineer of Computer Systems and Control Thesis Title: Adaptive Computation Techniques for Time Series Analysis Major Professor: </title> <journal> Dr. Mehdi Zargham </journal>\nLabel: Neural Networks\n\nPaper id: 1755\nTitle: Title: Learning Controllers from Examples  a motivation for searching alternative, empirical techniques for generating controllers.  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1519\nTitle: Title: What online Machine Learning can do for Knowledge Acquisition A Case Study  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1177\nTitle: Title: An Efficient Subsumption Algorithm for Inductive Logic Programming  \nLabel: Rule Learning\n\nPaper id: 963\nTitle: Title: Cooperation of Data-driven and Model-based Induction Methods for Relational Learning  \nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1180\nTitle: Title: Efficient Algorithms for -Subsumption  \n\nPaper id: 1627\nTitle: Title: Inductive Learning of Characteristic Concept Descriptions from Small Sets of Classified Examples  \nLabel: Rule Learning\n\nPaper id: 344\nTitle: Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In\nLabel: Rule Learning\n\nPaper id: 1620\nTitle: Title: Efficient -Subsumption based on Graph Algorithms  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 825\nTitle: Title: Towards Mixed-Initiative Rationale-Supported Planning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1707\nTitle: Title: Supporting Combined Human and Machine Planning: The Prodigy 4.0 User Interface Version 2.0*  \n\nPaper id: 1215\nTitle: Title: Supporting Combined Human and Machine Planning: An Interface for Planning by Analogical Reasoning  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1699\nTitle: Title: On the Usefulness of Re-using Diagnostic Solutions  \nLabel: Case Based\n\nPaper id: 580\nTitle: Title: Learning to Improve Case Adaptation by Introspective Reasoning and CBR  \n\nPaper id: 824\nTitle: Title: Merge Strategies for Multiple Case Plan Replay  \nLabel: Case Based\n\nPaper id: 1209\nTitle: Title: S o l u t i o n Relevant A b s t r a\n\nPaper id: 819\nTitle: Title: A Case Study of Case-Based CBR  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1214\nTitle: Title: Learning Problem-Solving Concepts by Reflecting on Problem Solving  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 523\nTitle: Title: Some studies in machine learning using the game of checkers. IBM Journal, 3(3):211-229, 1959. Some\nLabel: Genetic Algorithms\n\nPaper id: 583\nTitle: Title: Introspective reasoning using meta-explanations for multistrategy learning  \nLabel: Case Based\n\nPaper id: 1635\nTitle: Title: Redesigning control knowledge of knowledge-based systems: machine learning meets knowledge engineering  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 910\nTitle: Title: Learning Sequential Decision Rules Using Simulation Models and Competition  \nLabel: Genetic Algorithms\n\nPaper id: 478\nTitle: Title: An Improved Algorithm for Incremental Induction of Decision Trees  \nLabel: Case Based\n\nPaper id: 284\nTitle: Title: Role of Ontology in Creative Understanding  \n\nPaper id: 540\nTitle: Title: A Model-Based Approach to Blame-Assignment in Design  \n\nPaper id: 1278\nTitle: Title: A Functional Theory of Creative Reading  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1685\nTitle: Title: Optimization by Means of Genetic Algorithms  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 422\nTitle: Title: Genetic Self-Learning  \nLabel: Genetic Algorithms\n\nPaper id: 1455\nTitle: Title: Self-Adaptation in Genetic Algorithms of external parameters of a GA is seen as a first\nLabel: Genetic Algorithms\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 1069\nTitle: Title: Extended Selection Mechanisms in Genetic Algorithms  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2232\nTitle: Title: Facing The Facts: Necessary Requirements For The Artificial Evolution of Complex Behaviour  \nLabel: Genetic Algorithms\n\nPaper id: 659\nTitle: Title: Trading Spaces: Computation, Representation and the Limits of Uninformed Learning  \n\nPaper id: 1792\nTitle: Title: 21 Using n 2 classifier in constructive induction  \nLabel: Theory\n\nPaper id: 658\nTitle: Title: Hill Climbing with Learning (An Abstraction of Genetic Algorithm)  \n\nPaper id: 2274\nTitle: Title: Specialization in Populations of Artificial Neural Networks  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1443\nTitle: Title: Residual Q-Learning Applied to Visual Attention  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1540\nTitle: Title: MultiPlayer Residual Advantage Learning With General Function Approximation  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 842\nTitle: Title: Metrics for Temporal Difference Learning  \nLabel: Reinforcement Learning\n\nPaper id: 1459\nTitle: Title: Generalized Markov Decision Processes: Dynamic-programming and Reinforcement-learning Algorithms  \nLabel: Reinforcement Learning\n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n\nPaper id: 1118\nTitle: Title: Adapting Bias by Gradient Descent: An Incremental Version of Delta-Bar-Delta  \nLabel: Neural Networks\n\nPaper id: 1045\nTitle: Title: Spurious Solutions to the Bellman Equation  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1482\nTitle: Title: Generalizations of the Bias/Variance Decomposition for Prediction Error  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1484\nTitle: Title: Experiments with a New Boosting Algorithm  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1522\nTitle: Title: Improving Bagging Performance by Increasing Decision Tree Diversity  \n\nPaper id: 1521\nTitle: Title: Improving Bagging Performance by Increasing Decision Tree Diversity  \nLabel: Theory\n\nPaper id: 822\nTitle: Title: Achieving High-Accuracy Text-to-Speech with Machine Learning  \nLabel: Theory\n\nPaper id: 1500\nTitle: Title: On the Induction of Intelligible Ensembles  \n\nPaper id: 1220\nTitle: Title: A Method of Combining Multiple Probabilistic Classifiers through Soft Competition on Different Feature Sets  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1827\nTitle: Title: Efficient Algorithms for Inverting Evolution  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 299\nTitle: Title: On the Approximability of Numerical Taxonomy (Fitting Distances by Tree Metrics)  \nLabel: Theory\n\nPaper id: 574\nTitle: Title: On the Learnability of Discrete Distributions (extended abstract)  \n\nPaper id: 2224\nTitle: Title: Design of Optimization Criteria for Multiple Sequence Alignment  \n\nPaper id: 1962\nTitle: Title: Learning Distributions from Random Walks  \nLabel: Theory\n\nPaper id: 2110\nTitle: Title: Constructing Big Trees from Short Sequences  \nLabel: Theory\n\nPaper id: 2083\nTitle: Title: TREE CONTRACTIONS AND EVOLUTIONARY TREES  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2509\nTitle: Title: Applying Winnow to Context-Sensitive Spelling Correction  \nLabel: Theory\n\nPaper id: 2475\nTitle: Title: Learning polynomials with queries: The highly noisy case  task for the case when F  \nLabel: Theory\n\nPaper id: 242\nTitle: Title: Learning Markov chains with variable memory length from noisy output  \nLabel: Theory\n\nPaper id: 2360\nTitle: Title: Efficient Learning of Typical Finite Automata from Random Walks (Extended Abstract)  \nLabel: Theory\n\nPaper id: 746\nTitle: Title: A New Look at Tree Models for Multiple Sequence Alignment  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 153\nTitle: Title: Living in a partially structured environment: How to bypass the limitations of classical reinforcement techniques  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 63\nTitle: Title: Machine Learning,  Reinforcement Learning with Replacing Eligibility Traces  \nLabel: Reinforcement Learning\n\nPaper id: 294\nTitle: Title: References elements that can solve difficult learning control problems. on Simulation of Adaptive Behavior, pages\nLabel: Reinforcement Learning\n\nPaper id: 747\nTitle: Title: Cholinergic suppression of transmission may allow combined associative memory function and self-organization in the neocortex.  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 203\nTitle: Title: Theory of Synaptic Plasticity in Visual Cortex  \nLabel: Neural Networks\n\nPaper id: 771\nTitle: Title: SELF-ORGANIZING PROCESS BASED ON LATERAL INHIBITION AND SYNAPTIC RESOURCE REDISTRIBUTION  \nLabel: Neural Networks\n\nPaper id: 665\nTitle: Title: Requirements and use of neural networks for industrial appli-  \nLabel: Neural Networks\n\nPaper id: 229\nTitle: Title: Understanding Musical Sound with Forward Models and Physical Models  \nLabel: Neural Networks\n\nPaper id: 579\nTitle: Title: Comparison of Kernel Estimators, Perceptrons, and Radial-Basis Functions for OCR and Speech Classification  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1548\nTitle: Title: Free energy coding  In  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 76\nTitle: Title: A VIEW OF THE EM ALGORITHM THAT JUSTIFIES INCREMENTAL, SPARSE, AND OTHER VARIANTS  \nLabel: Probabilistic Methods\n\nPaper id: 1291\nTitle: Title: Bits-back coding software guide  \n\nPaper id: 1374\nTitle: Title: A simple algorithm that discovers efficient perceptual codes  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 131\nTitle: Title: The Expectation-Maximization Algorithm for MAP Estimation  \nLabel: Probabilistic Methods\n\nPaper id: 181\nTitle: Title: Ensemble Learning and Evidence Maximization  \nLabel: Theory\n\nPaper id: 518\nTitle: Title: Developments in Probabilistic Modelling with Neural Networks|Ensemble Learning  \nLabel: Theory\n\nPaper id: 345\nTitle: Title: On Convergence Properties of the EM Algorithm for Gaussian Mixtures  \nLabel: Probabilistic Methods\n\nPaper id: 1934\nTitle: Title: Sequential Update of Bayesian Network Structure  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1585\nTitle: Title: Q-Learning for Bandit Problems  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n\nPaper id: 738\nTitle: Title: On the Convergence of Stochastic Iterative Dynamic Programming Algorithms  \nLabel: Reinforcement Learning\n\nPaper id: 804\nTitle: Title: Exploration Bonuses and Dual Control  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2480\nTitle: Title: Planning by Incremental Dynamic Programming  \nLabel: Reinforcement Learning\n\nPaper id: 2\nTitle: Title: Submitted to NIPS96, Section: Applications. Preference: Oral presentation Reinforcement Learning for Dynamic Channel Allocation in\nLabel: Reinforcement Learning\n\nPaper id: 477\nTitle: Title: Forward models: Supervised learning with a distal teacher  \nLabel: Reinforcement Learning\n\nPaper id: 410\nTitle: Title: High-Performance Job-Shop Scheduling With A Time-Delay TD() Network  \nLabel: Reinforcement Learning\n\nPaper id: 239\nTitle: Title: Robust Value Function Approximation by Working Backwards Computing an accurate value function is the key\nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 189\nTitle: Title: An Evolutionary Algorithm that Constructs Recurrent Neural Networks  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 42\nTitle: Title: Evolutionary Module Acquisition  \nLabel: Genetic Algorithms\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 2664\nTitle: Title: Coevolving Communicative Behavior in a Linear Pursuer-Evader Game  \nLabel: Genetic Algorithms\n\nPaper id: 188\nTitle: Title: Coevolving High-Level Representations  \nLabel: Genetic Algorithms\n\nPaper id: 2102\nTitle: Title: The Evolution of Communication Schemes Over Continuous Channels  \nLabel: Genetic Algorithms\n\nPaper id: 395\nTitle: Title: Evolving Graphs and Networks with Edge Encoding: Preliminary Report  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2361\nTitle: Title: Program Search with a Hierarchical Variable Length Representation: Genetic Programming, Simulated Annealing and Hill Climbing  \nLabel: Genetic Algorithms\n\nPaper id: 2248\nTitle: Title: Heuristic for Improved Genetic Bin Packing  \nLabel: Genetic Algorithms\n\nPaper id: 1544\nTitle: Title: Monitoring in Embedded Agents  \nLabel: Genetic Algorithms\n\nPaper id: 1850\nTitle: Title: Genetic Programming for Pedestrians  \nLabel: Genetic Algorithms\n\nPaper id: 2200\nTitle: Title: Adaptation in constant utility non-stationary environments  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2532\nTitle: Title: Ensemble Learning for Hidden Markov Models  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 518\nTitle: Title: Developments in Probabilistic Modelling with Neural Networks|Ensemble Learning  \nLabel: Theory\n\nPaper id: 766\nTitle: Title: Keeping Neural Networks Simple by Minimizing the Description Length of the Weights  \n\nPaper id: 2417\nTitle: Title: Choice of Basis for Laplace Approximation  \nLabel: Probabilistic Methods\n\nPaper id: 76\nTitle: Title: A VIEW OF THE EM ALGORITHM THAT JUSTIFIES INCREMENTAL, SPARSE, AND OTHER VARIANTS  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 78\nTitle: Title: Probabilistic Networks: New Models and New Methods  \nLabel: Theory\n\nPaper id: 345\nTitle: Title: On Convergence Properties of the EM Algorithm for Gaussian Mixtures  \nLabel: Probabilistic Methods\n\nPaper id: 975\nTitle: Title: State Reconstruction for Determining Predictability in Driven Nonlinear Acoustical Systems  \n\nPaper id: 131\nTitle: Title: The Expectation-Maximization Algorithm for MAP Estimation  \nLabel: Probabilistic Methods\n\nPaper id: 662\nTitle: Title: Free Energy Minimization Algorithm for Decoding and Cryptanalysis three binary vectors: s of length N\nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2507\nTitle: Title: The Observer-Observation Dilemma in Neuro-Forecasting: Reliable Models From Unreliable Data Through CLEARNING  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2239\nTitle: Title: Predicting Conditional Probability Distributions: A Connectionist Approach  \n\nPaper id: 2374\nTitle: Title: Predictions with Confidence Intervals (Local Error Bars)  \nLabel: Neural Networks\n\nPaper id: 371\nTitle: Title: Selecting Input Variables Using Mutual Information and Nonparametric Density Estimation  \nLabel: Probabilistic Methods\n\nPaper id: 2373\nTitle: Title: Evaluating Neural Network Predictors by Bootstrapping  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 157\nTitle: Title: A Practical Bayesian Framework for Backprop Networks  \nLabel: Theory\n\nPaper id: 2413\nTitle: Title: On-Line Adaptation of a Signal Predistorter through Dual Reinforcement Learning  \nLabel: Neural Networks\n\nPaper id: 88\nTitle: Title: Hoeffding Races: Accelerating Model Selection Search for Classification and Function Approximation  \nLabel: Theory\n\nPaper id: 2513\nTitle: Title: Avoiding overfitting by locally matching the noise level of the data gating network discovers the\n\nPaper id: 587\nTitle: Title: NONPARAMETRIC SELECTION OF INPUT VARIABLES FOR CONNECTIONIST LEARNING  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 262\nTitle: Title: EVOLVING REPRESENTATIONS OF DESIGN CASES AND THEIR USE IN CREATIVE DESIGN  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 266\nTitle: Title: EMERGENT BEHAVIOUR IN CO-EVOLUTIONARY DESIGN  \nLabel: Case Based\n\nPaper id: 1980\nTitle: Title: An Overview of Evolutionary Computation  \nLabel: Genetic Algorithms\n\nPaper id: 188\nTitle: Title: Coevolving High-Level Representations  \nLabel: Genetic Algorithms\n\nPaper id: 793\nTitle: Title: A Survey of Evolution Strategies  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 42\nTitle: Title: Evolutionary Module Acquisition  \nLabel: Genetic Algorithms\n\nPaper id: 144\nTitle: Title: The Observers Paradox: Apparent Computational Complexity in Physical Systems  \nLabel: Neural Networks\n\nPaper id: 2202\nTitle: Title: An Evolutionary Approach to Combinatorial Optimization Problems  \nLabel: Genetic Algorithms\n\nPaper id: 1380\nTitle: Title: Evaluating Evolutionary Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 755\nTitle: Title: of a simulator for evolving morphology are: Universal the simulator should cover an infinite gen\nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 853\nTitle: Title: Error-Correcting Output Codes for Local Learners  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1053\nTitle: Title: Bias Plus Variance Decomposition for Zero-One Loss Functions  \nLabel: Theory\n\nPaper id: 2423\nTitle: Title: Error-Correcting Output Codes: A General Method for Improving Multiclass Inductive Learning Programs  \nLabel: Theory\n\nPaper id: 1019\nTitle: Title: Bibliography \"SMART: Support Management Automated Reasoning Technology for COMPAQ Customer Service,\" \"Instance-Based Learning Algorithms,\" Machine\nLabel: Theory\n\nPaper id: 1732\nTitle: Title: Improving the Performance of Radial Basis Function Networks by Learning Center Locations  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1607\nTitle: Title: Characterizing the generalization performance of model selection strategies  \nLabel: Theory\n\nPaper id: 1463\nTitle: Title: Bias, variance and prediction error for classification rules  \nLabel: Probabilistic Methods\n\nPaper id: 906\nTitle: Title: Memory-based Time Series Recognition  A New Methodology and Real World Applications  \nLabel: Neural Networks\n\nPaper id: 1290\nTitle: Title: A THEORY OF LEARNING CLASSIFICATION RULES  \nLabel: Theory\n\nPaper id: 1191\nTitle: Title: Machine Learning Bias, Statistical Bias, and Statistical Variance of Decision Tree Algorithms  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1528\nTitle: Title: Using Qualitative Models to Guide Inductive Learning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 151\nTitle: Title: Rerepresenting and Restructuring Domain Theories: A Constructive Induction Approach  \nLabel: Theory\n\nPaper id: 426\nTitle: Title: Rule Induction with CN2: Some Recent Improvements  \nLabel: Rule Learning\n\nPaper id: 1487\nTitle: Title: A Divide-and-Conquer Approach to Learning from Prior Knowledge  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1275\nTitle: Title: Fossil: A Robust Relational Learner  \n\nPaper id: 2126\nTitle: Title: Applying ILP to Diterpene Structure Elucidation from 13 C NMR Spectra  \nLabel: Rule Learning\n\nPaper id: 1187\nTitle: Title: Rationality and Intelligence  \nLabel: Theory\n\nPaper id: 937\nTitle: Title: The RISE System: Conquering Without Separating  \nLabel: Case Based\n\nPaper id: 29\nTitle: Title: Stochastically Guided Disjunctive Version Space Learning  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1365\nTitle: Title: Word Perfect Corp. A TRANSFORMATION FOR IMPLEMENTING NEURAL NETWORKS WITH LOCALIST PROPERTIES  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 812\nTitle: Title: Word Perfect Corp. A TRANSFORMATION FOR IMPLEMENTING EFFICIENT DYNAMIC BACKPROPAGATION NEURAL NETWORKS  \nLabel: Neural Networks\n\nPaper id: 1044\nTitle: Title: Word Perfect Corp. LIA: A Location-Independent Transformation for ASOCS Adaptive Algorithm 2  \nLabel: Neural Networks\n\nPaper id: 809\nTitle: Title: A Self-Adjusting Dynamic Logic Module  \nLabel: Neural Networks\n\nPaper id: 814\nTitle: Title: A VLSI Implementation of a Parallel, Self-Organizing Learning Model  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1615\nTitle: Title: A Provably Convergent Dynamic Training Method for Multilayer Perceptron Networks  \nLabel: Neural Networks\n\nPaper id: 1341\nTitle: Title: Growing Layers of Perceptrons: Introducing the Extentron Algorithm  \nLabel: Neural Networks\n\nPaper id: 297\nTitle: Title: Automatic Feature Extraction in Machine Learning  \nLabel: Neural Networks\n\nPaper id: 1321\nTitle: Title: Priority ASOCS  ASOCS models have two significant advantages over other learning models:  \nLabel: Neural Networks\n\nPaper id: 1190\nTitle: Title: Analysis of the Convergence and Generalization of AA1  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1715\nTitle: Title: A Sampling-Based Heuristic for Tree Search Applied to Grammar Induction  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 793\nTitle: Title: A Survey of Evolution Strategies  \nLabel: Genetic Algorithms\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 1734\nTitle: Title: A Stochastic Search Approach to Grammar Induction  \n\nPaper id: 1386\nTitle: Title: New Evidence Driven State Merging Algorithm  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 395\nTitle: Title: Evolving Graphs and Networks with Edge Encoding: Preliminary Report  \n\nPaper id: 813\nTitle: Title: The Application of a Parallel Genetic Algorithm to the n=m=P=C max Flowshop Problem  \nLabel: Genetic Algorithms\n\nPaper id: 2175\nTitle: Title: The Troubling Aspects of a Building Block Hypothesis for Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 624\nTitle: Title: Measuring the Difficulty of Specific Learning Problems  \nLabel: Theory\n\nPaper id: 1127\nTitle: Title: Recombination Operator, its Correlation to the Fitness Landscape and Search Performance  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1205\nTitle: Title: The Role of Development in Genetic Algorithms  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 793\nTitle: Title: A Survey of Evolution Strategies  \nLabel: Genetic Algorithms\n\nPaper id: 1016\nTitle: Title: An Analysis of the Interacting Roles of Population Size and Crossover in Genetic Algorithms  \n\nPaper id: 1153\nTitle: Title: Evolution in Time and Space The Parallel Genetic Algorithm  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 395\nTitle: Title: Evolving Graphs and Networks with Edge Encoding: Preliminary Report  \n\nPaper id: 813\nTitle: Title: The Application of a Parallel Genetic Algorithm to the n=m=P=C max Flowshop Problem  \nLabel: Genetic Algorithms\n\nPaper id: 2039\nTitle: Title: A Case Study on Tuning of Genetic Algorithms by Using Performance Evaluation Based on Experimental Design  \nLabel: Genetic Algorithms\n\nPaper id: 624\nTitle: Title: Measuring the Difficulty of Specific Learning Problems  \nLabel: Theory\n\nPaper id: 1113\nTitle: Title: Staged Hybrid Genetic Search for Seismic Data Imaging  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 474\nTitle: Title: Protein Structure Prediction: Selecting Salient Features from Large Candidate Pools  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 698\nTitle: Title: Learning to Predict Reading Frames in E. coli DNA Sequences  \n\nPaper id: 635\nTitle: Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 632\nTitle: Title: Toward Optimal Feature Selection  \nLabel: Probabilistic Methods\n\nPaper id: 634\nTitle: Title: Oblivious Decision Trees and Abstract Cases  \nLabel: Case Based\n\nPaper id: 264\nTitle: Title: On Learning More Concepts  \n\nPaper id: 651\nTitle: Title: A Monotonic Measure for Optimal Feature Selection  \nLabel: Neural Networks\n\nPaper id: 375\nTitle: Title: Constructive Induction Using a Non-Greedy Strategy for Feature Selection  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2265\nTitle: Title: AN APPROACH TO A PROBLEM IN NETWORK DESIGN USING GENETIC ALGORITHMS  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2347\nTitle: Title: Chapter 4 Empirical comparison of stochastic algorithms Empirical comparison of stochastic algorithms in a graph\nLabel: Genetic Algorithms\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2200\nTitle: Title: Adaptation in constant utility non-stationary environments  \n\nPaper id: 658\nTitle: Title: Hill Climbing with Learning (An Abstraction of Genetic Algorithm)  \n\nPaper id: 1784\nTitle: Title: Genetic Programming and Redundancy  \nLabel: Genetic Algorithms\n\nPaper id: 624\nTitle: Title: Measuring the Difficulty of Specific Learning Problems  \nLabel: Theory\n\nPaper id: 2251\nTitle: Title: A PARALLEL ISLAND MODEL GENETIC ALGORITHM FOR THE MULTIPROCESSOR SCHEDULING PROBLEM  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 977\nTitle: Title: Pessimistic and Optimistic Induction  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1234\nTitle: Title: Concept Learning and the Problem of Small  \nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 13\nTitle: Title: Unifying Empirical and Explanation-Based Learning by Modeling the Utility of Learned Knowledge  \nLabel: Case Based\n\nPaper id: 1510\nTitle: Title: The Problem with Noise and Small Disjuncts  \nLabel: Theory\n\nPaper id: 1226\nTitle: Title: On Learning Multiple Descriptions of a Concept  \nLabel: Rule Learning\n\nPaper id: 1263\nTitle: Title: Using Partitioning to Speed Up Specific-to-General Rule Induction  \nLabel: Case Based\n\nPaper id: 937\nTitle: Title: The RISE System: Conquering Without Separating  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 562\nTitle: Title: Transfer of Learning by Composing Solutions of Elemental Sequential Tasks  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1117\nTitle: Title: A Coevolutionary Approach to Learning Sequential Decision Rules  \nLabel: Genetic Algorithms\n\nPaper id: 60\nTitle: Title: The Efficient Learning of Multiple Task Sequences  \nLabel: Reinforcement Learning\n\nPaper id: 2014\nTitle: Title: Emergent Hierarchical Control Structures: Learning Reactive/Hierarchical Relationships in Reinforcement Environments  \nLabel: Reinforcement Learning\n\nPaper id: 2018\nTitle: Title: Learning Hierarchical Control Structures for Multiple Tasks and Changing Environments  \nLabel: Reinforcement Learning\n\nPaper id: 370\nTitle: Title: Robust Reinforcement Learning in Motion Planning  \nLabel: Reinforcement Learning\n\nPaper id: 252\nTitle: Title: A Modular Q-Learning Architecture for Manipulator Task Decomposition `Data storage in the cerebellar model ar\nLabel: Reinforcement Learning\n\nPaper id: 1889\nTitle: Title: The Functional Transfer of Knowledge for Coronary Artery Disease Diagnosis  \nLabel: Neural Networks\n\nPaper id: 671\nTitle: Title: Learning to Achieve Goals  \nLabel: Reinforcement Learning\n\nPaper id: 1401\nTitle: Title: Using Case-Based Reasoning as a Reinforcement Learning Framework for Optimization with Changing Criteria  \nLabel: Case Based\n\nPaper id: 440\nTitle: Title: Hierarchical Explanation-Based Reinforcement Learning  \nLabel: Reinforcement Learning\n\nPaper id: 1183\nTitle: Title: Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1193\nTitle: Title: Reinforcement Learning with Hierarchies of Machines  \nLabel: Reinforcement Learning\n\nPaper id: 1202\nTitle: Title: Between MDPs and Semi-MDPs: Learning, Planning, and Representing Knowledge at Multiple Temporal Scales  \nLabel: Reinforcement Learning\n\nPaper id: 414\nTitle: Title: Acquiring Recursive and Iterative Concepts with Explanation-Based Learning explanation-based generalization, generalizing explanation structures, generalizing to\nLabel: Case Based\n\nPaper id: 730\nTitle: Title: Learning Sequential Tasks by Incrementally Adding Higher Orders  \nLabel: Neural Networks\n\nPaper id: 2605\nTitle: Title: Case-based Acquisition of User Preferences for Solution Improvement in Ill-Structured Domains  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 675\nTitle: Title: Combining FOIL and EBG to Speed-up Logic Programs  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 344\nTitle: Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In\nLabel: Rule Learning\n\nPaper id: 597\nTitle: Title: Learning Semantic Grammars with Constructive Inductive Logic Programming  \nLabel: Rule Learning\n\nPaper id: 2215\nTitle: Title: Learning Approximate Control Rules Of High Utility  \nLabel: Case Based\n\nPaper id: 1429\nTitle: Title: Learning First-Order Definitions of Functions  \nLabel: Rule Learning\n\nPaper id: 1445\nTitle: Title: Theory-guided Empirical Speedup Learning of Goal Decomposition Rules  \n\nPaper id: 1442\nTitle: Title: Learning Goal-Decomposition Rules using Exercises  \nLabel: Rule Learning\n\nPaper id: 2339\nTitle: Title: An intelligent search method using Inductive Logic Programming  \nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2032\nTitle: Title: Learning Action-oriented Perceptual Features for Robot Navigation  \nLabel: Rule Learning\n\nPaper id: 1275\nTitle: Title: Fossil: A Robust Relational Learner  \n\nPaper id: 1881\nTitle: Title: Integrity Constraints in ILP using a Monte Carlo approach  \n\nPaper id: 414\nTitle: Title: Acquiring Recursive and Iterative Concepts with Explanation-Based Learning explanation-based generalization, generalizing explanation structures, generalizing to\nLabel: Case Based\n\nPaper id: 1671\nTitle: Title: From: Computational Learning Theory and Natural Systems, Chapter 18, \"Cross-validation and Modal Theories\", Cross-Validation and\nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1919\nTitle: Title: Inductive Constraint Logic and the Mutagenesis Problem  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1007\nTitle: Title: Applications of a logical discovery engine  \nLabel: Rule Learning\n\nPaper id: 2431\nTitle: Title: Multi-class problems and discretization in ICL Extended abstract  \n\nPaper id: 638\nTitle: Title: Learning a set of primitive actions with an Induction of decision trees. Machine Learning, 1(1):81-106,\nLabel: Theory\n\nPaper id: 2426\nTitle: Title: Inductive Constraint Logic  \nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1468\nTitle: Title: Preventing \"Overfitting\" of Cross-Validation Data  \nLabel: Theory\n\nPaper id: 618\nTitle: Title: 0 Inductive learning of compact rule sets by using efficient hypotheses reduction  \nLabel: Theory\n\nPaper id: 383\nTitle: Title: Constructing Fuzzy Graphs from Examples  \nLabel: Neural Networks\n\nPaper id: 1539\nTitle: Title: Finding new rules for incomplete theories: Explicit biases for induction with contextual information. In Proceedings\nLabel: Rule Learning\n\nPaper id: 296\nTitle: Title: Lookahead and Pathology in Decision Tree Induction  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2420\nTitle: Title: A Parallel Learning Algorithm for Bayesian Inference Networks  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2169\nTitle: Title: Theory Refinement on Bayesian Networks  \n\nPaper id: 1527\nTitle: Title: A THEORY OF INFERRED CAUSATION perceive causal relationships in uncon trolled observations. 2. the task\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1747\nTitle: Title: FROM BAYESIAN NETWORKS TO CAUSAL NETWORKS  \nLabel: Probabilistic Methods\n\nPaper id: 2524\nTitle: Title: ADAPTIVE LOOK-AHEAD PLANNING problem of finding good initial plans is solved by the use of\nLabel: Probabilistic Methods\n\nPaper id: 2076\nTitle: Title: Automated Discovery of Linear Feedback Models 1  \n\nPaper id: 1086\nTitle: Title: An Algorithm for the Construction of Bayesian Network Structures from Data  \nLabel: Probabilistic Methods\n\nPaper id: 1290\nTitle: Title: A THEORY OF LEARNING CLASSIFICATION RULES  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 186\nTitle: Title: Adaptive state space quantisation: adding and removing neurons  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 566\nTitle: Title: Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming  \nLabel: Reinforcement Learning\n\nPaper id: 747\nTitle: Title: Cholinergic suppression of transmission may allow combined associative memory function and self-organization in the neocortex.  \n\nPaper id: 294\nTitle: Title: References elements that can solve difficult learning control problems. on Simulation of Adaptive Behavior, pages\nLabel: Reinforcement Learning\n\nPaper id: 588\nTitle: Title: LEARNING TO AVOID COLLISIONS: A REINFORCEMENT LEARNING PARADIGM FOR MOBILE ROBOT NAVIGATION  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 472\nTitle: Title: Category: Control, Navigation and Planning. Key words: Reinforcement learning, Exploration, Hidden state. Prefer oral presentation.\nLabel: Reinforcement Learning\n\nPaper id: 699\nTitle: Title: Adaptive state space quantisation for reinforcement learning of collision-free navigation  \n\nPaper id: 34\nTitle: Title: Using a Case Base of Surfaces to Speed-Up Reinforcement Learning  \n\nPaper id: 349\nTitle: Title: Measuring Organization and Asymmetry in Bihemispheric Topographic Maps  \nLabel: Neural Networks\n\nPaper id: 203\nTitle: Title: Theory of Synaptic Plasticity in Visual Cortex  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1016\nTitle: Title: An Analysis of the Interacting Roles of Population Size and Crossover in Genetic Algorithms  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 728\nTitle: Title: On the Virtues of Parameterized Uniform Crossover  \n\nPaper id: 943\nTitle: Title: Crossover or Mutation?  \nLabel: Genetic Algorithms\n\nPaper id: 1070\nTitle: Title: Extended Selection Mechanisms in Genetic Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 1670\nTitle: Title: Raising GA Performance by Simultaneous Tuning of Selective Pressure and Recombination Disruptiveness  \nLabel: Genetic Algorithms\n\nPaper id: 1110\nTitle: Title: On The State of Evolutionary Computation  \nLabel: Genetic Algorithms\n\nPaper id: 856\nTitle: Title: Hierarchical priors and mixture models, with application in regression and density estimation  \nLabel: Genetic Algorithms\n\nPaper id: 1205\nTitle: Title: The Role of Development in Genetic Algorithms  \n\nPaper id: 1466\nTitle: Title: A STUDY OF CROSSOVER OPERATORS IN GENETIC PROGRAMMING  \nLabel: Genetic Algorithms\n\nPaper id: 1729\nTitle: Title: Adapting Crossover in a Genetic Algorithm  \nLabel: Genetic Algorithms\n\nPaper id: 727\nTitle: Title: Using Problem Generators to Explore the Effects of Epistasis  \nLabel: Genetic Algorithms\n\nPaper id: 1305\nTitle: Title: Distribution Category:  A Parallel Genetic Algorithm for the Set Partitioning Problem  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1106\nTitle: Title: Genetic Algorithms for Combinatorial Optimization: The Assembly Line Balancing Problem  \nLabel: Genetic Algorithms\n\nPaper id: 1728\nTitle: Title: Dynamic Parameter Encoding for Genetic Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 793\nTitle: Title: A Survey of Evolution Strategies  \nLabel: Genetic Algorithms\n\nPaper id: 1575\nTitle: Title: A Comparative Study of Genetic Search  \nLabel: Genetic Algorithms\n\nPaper id: 1799\nTitle: Title: On the Effectiveness of Evolutionary Search in High-Dimensional NK-Landscapes  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 418\nTitle: Title: Heterogeneous Uncertainty Sampling for Supervised Learning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 135\nTitle: Title: More Efficient Windowing  \nLabel: Rule Learning\n\nPaper id: 479\nTitle: Title: Learning physical descriptions from functional definitions, examples, Learning from examples: The effect of different conceptual\nLabel: Case Based\n\nPaper id: 1312\nTitle: Title: Learning Trees and Rules with Set-valued Features  \n\nPaper id: 740\nTitle: Title: Information-based objective functions for active data selection  \n\nPaper id: 1269\nTitle: Title: Context-sensitive learning methods for text categorization  \nLabel: Theory\n\nPaper id: 1198\nTitle: Title: Query by Committee  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2618\nTitle: Title: Mistake-Driven Learning in Text Categorization  \nLabel: Theory\n\nPaper id: 859\nTitle: Title: On-Site Learning  \nLabel: Theory\n\nPaper id: 1664\nTitle: Title: \"What is the best thing to do right now?\": getting beyond greedy exploration  \n\nPaper id: 929\nTitle: Title: In:  A Mixture Model System for Medical and Machine Diagnosis  \nLabel: Probabilistic Methods\n\nPaper id: 478\nTitle: Title: An Improved Algorithm for Incremental Induction of Decision Trees  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1184\nTitle: Title: Causality in Genetic Programming  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 141\nTitle: Title: Hierarchical Self-Organization in Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 1362\nTitle: Title: Towards Automatic Discovery of Building Blocks in Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 120\nTitle: Title: Genetic Programming Exploratory Power and the Discovery of Functions  \nLabel: Genetic Algorithms\n\nPaper id: 2199\nTitle: Title: Position Paper, Workshop on Evolutionary Computation with Variable Size Representation, ICGA, Fitness Causes Bloat in\n\nPaper id: 781\nTitle: Title: Evolving Visual Routines  Architecture and Planning,  \nLabel: Genetic Algorithms\n\nPaper id: 860\nTitle: Title: A Study in Program Response and the Negative Effects of Introns in Genetic Programming  \n\nPaper id: 844\nTitle: Title: Evolving Compact Solutions in Genetic Programming: A Case Study  \nLabel: Genetic Algorithms\n\nPaper id: 1784\nTitle: Title: Genetic Programming and Redundancy  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 55\nTitle: Title: A Comparison of Selection Schemes used in Genetic Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 934\nTitle: Title: Complexity Compression and Evolution  \nLabel: Genetic Algorithms\n\nPaper id: 2705\nTitle: Title: The MAX Problem for Genetic Programming Highlighting an Adverse Interaction between the Crossover Operator and\nLabel: Genetic Algorithms\n\nPaper id: 1959\nTitle: Title: Evolution-based Discovery of Hierarchical Behaviors  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1136\nTitle: Title: Using Neural Networks and Genetic Algorithms as Heuristics for NP-Complete Problems  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 1030\nTitle: Title: Solving Combinatorial Problems Using Evolutionary Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 1516\nTitle: Title: Solving 3-SAT by GAs Adapting Constraint Weights  \n\nPaper id: 727\nTitle: Title: Using Problem Generators to Explore the Effects of Epistasis  \nLabel: Genetic Algorithms\n\nPaper id: 1142\nTitle: Title: A NN Algorithm for Boolean Satisfiability Problems  \nLabel: Genetic Algorithms\n\nPaper id: 1740\nTitle: Title: As mentioned in the introduction, an encod-ing/crossover pair makes a spectrum of geographical linkages. A\nLabel: Genetic Algorithms\n\nPaper id: 935\nTitle: Title: Complexity Compression and Evolution  \nLabel: Genetic Algorithms\n\nPaper id: 1558\nTitle: Title: How good are genetic algorithms at finding large cliques: an experimental study  \nLabel: Genetic Algorithms\n\nPaper id: 1594\nTitle: Title: An Evolutionary Approach to Vector Quantizer Design  \nLabel: Genetic Algorithms\n\nPaper id: 1575\nTitle: Title: A Comparative Study of Genetic Search  \nLabel: Genetic Algorithms\n\nPaper id: 800\nTitle: Title: Vector Quantizer Design Using Genetic Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 1286\nTitle: Title: HGA: A Hardware-Based Genetic Algorithm  \nLabel: Genetic Algorithms\n\nPaper id: 1060\nTitle: Title: An Overview of Genetic Algorithms Part 1, Fundamentals  \n\nPaper id: 1018\nTitle: Title: Simulated Annealing for Hard Satisfiability Problems  \nLabel: Genetic Algorithms\n\nPaper id: 1523\nTitle: Title: A Generalized Permutation Approach to Job Shop Scheduling with Genetic Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 1063\nTitle: Title: An Analysis of the Effects of Neighborhood Size and Shape on Local Selection Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 1333\nTitle: Title: Using Genetic Algorithms for Supervised Concept Learning  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1572\nTitle: Title: The Coevolution of Mutation Rates  \nLabel: Genetic Algorithms\n\nPaper id: 982\nTitle: Title: Evolutionary Neural Networks for Value Ordering in Constraint Satisfaction Problems  \nLabel: Genetic Algorithms\n\nPaper id: 1016\nTitle: Title: An Analysis of the Interacting Roles of Population Size and Crossover in Genetic Algorithms  \n\nPaper id: 2200\nTitle: Title: Adaptation in constant utility non-stationary environments  \n\nPaper id: 2451\nTitle: Title: Automatic Design of Cellular Neural Networks by means of Genetic Algorithms: Finding a Feature Detector\nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 753\nTitle: Title: Analysis of Dynamical Recognizers  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 405\nTitle: Title: Finite State Machines and Recurrent Neural Networks Automata and Dynamical Systems Approaches  \nLabel: Neural Networks\n\nPaper id: 409\nTitle: Title: Extraction of Rules from Discrete-Time Recurrent Neural Networks  \nLabel: Neural Networks\n\nPaper id: 444\nTitle: Title: Fools Gold: Extracting Finite State Machines From Recurrent Network Dynamics  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1298\nTitle: Title: Rule Revision with Recurrent Neural Networks  \nLabel: Neural Networks\n\nPaper id: 2582\nTitle: Title: Noisy Time Series Prediction using Symbolic Representation and Recurrent Neural Network Grammatical Inference  \nLabel: Neural Networks\n\nPaper id: 144\nTitle: Title: The Observers Paradox: Apparent Computational Complexity in Physical Systems  \nLabel: Neural Networks\n\nPaper id: 1606\nTitle: Title: Pruning Recurrent Neural Networks for Improved Generalization Performance  \nLabel: Neural Networks\n\nPaper id: 1285\nTitle: Title: Learning Context-free Grammars: Capabilities and Limitations of a Recurrent Neural Network with an External Stack Memory  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1636\nTitle: Title: Context-Sensitive Feature Selection for Lazy Learners  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 245\nTitle: Title: ICML-96 Workshop \"Learning in context-sensitive domains\" Bari, Italy. Dynamically Adjusting Concepts to Accommodate Changing Contexts  \n\nPaper id: 928\nTitle: Title: Learning to Refine Case Libraries:  \n\nPaper id: 2074\nTitle: Title: The Management of Context-Sensitive Features: A Review of Strategies  \n\nPaper id: 983\nTitle: Title: Refining Conversational Case Libraries  \nLabel: Case Based\n\nPaper id: 1684\nTitle: Title: Context-sensitive attribute estimation in regression  \nLabel: Rule Learning\n\nPaper id: 1073\nTitle: Title: An adaptation of Relief for attribute estimation in regression  \nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1112\nTitle: Title: Flexible Metric Nearest Neighbor Classiflcation  \nLabel: Neural Networks\n\nPaper id: 1531\nTitle: Title: NACODAE: Navy Conversational Decision Aids Environment  \n\nPaper id: 1647\nTitle: Title: Recognition and Exploitation of Contextual Clues via Incremental Meta-Learning (Extended Version)  \nLabel: Theory\n\nPaper id: 887\nTitle: Title: Simplifying Decision Trees: A Survey  \nLabel: Theory\n\nPaper id: 1569\nTitle: Title: Estimating Attributes: Analysis and Extensions of RELIEF  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1663\nTitle: Title: Evolution of the Topology and the Weights of Neural Networks using Genetic Programming with a\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1266\nTitle: Title: A Hypothesis-driven Constructive Induction Approach to Expanding Neural Networks  \nLabel: Neural Networks\n\nPaper id: 1756\nTitle: Title: Soft Computing: the Convergence of Emerging Reasoning Technologies  \nLabel: Genetic Algorithms\n\nPaper id: 2504\nTitle: Title: Genetic Encoding Strategies for Neural Networks  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1576\nTitle: Title: What do Constructive Learners Really Learn?  \nLabel: Theory\n\nPaper id: 168\nTitle: Title: Dynamic Control of Genetic Algorithms using Fuzzy Logic Techniques  \nLabel: Genetic Algorithms\n\nPaper id: 1301\nTitle: Title: Discovering Representation Space Transformations for Learning Concept Descriptions Combining DNF and M-of-N Rules  \nLabel: Rule Learning\n\nPaper id: 2603\nTitle: Title: Pointer Adaptation and Pruning of Min-Max Fuzzy Inference and Estimation  \nLabel: Neural Networks\n\nPaper id: 836\nTitle: Title: Unsupervised Constructive Learning  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2408\nTitle: Title: Exploratory Learning in the Game of GO  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 523\nTitle: Title: Some studies in machine learning using the game of checkers. IBM Journal, 3(3):211-229, 1959. Some\nLabel: Genetic Algorithms\n\nPaper id: 1975\nTitle: Title: Associative Reinforcement Learning: Functions in k-DNF  \nLabel: Reinforcement Learning\n\nPaper id: 2145\nTitle: Title: Exploration in Machine Learning  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1616\nTitle: Title: NeuroDraughts: the role of representation, search, training regime and architecture in a TD draughts player  \nLabel: Reinforcement Learning\n\nPaper id: 910\nTitle: Title: Learning Sequential Decision Rules Using Simulation Models and Competition  \nLabel: Genetic Algorithms\n\nPaper id: 882\nTitle: Title: Learning To Play the Game of Chess  \nLabel: Reinforcement Learning\n\nPaper id: 2480\nTitle: Title: Planning by Incremental Dynamic Programming  \nLabel: Reinforcement Learning\n\nPaper id: 283\nTitle: Title: A Local Learning Algorithm for Dynamic Feedforward and Recurrent Networks  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2298\nTitle: Title: Convergence Analysis of Canonical Genetic Algorithms  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2518\nTitle: Title: Tracing the Behavior of Genetic Algorithms Using Expected Values of Bit and Walsh Products  \nLabel: Genetic Algorithms\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1572\nTitle: Title: The Coevolution of Mutation Rates  \nLabel: Genetic Algorithms\n\nPaper id: 1675\nTitle: Title: A Study of Genetic Algorithms to Find Approximate Solutions to Hard 3CNF Problems  \nLabel: Genetic Algorithms\n\nPaper id: 1253\nTitle: Title: USING A GENETIC ALGORITHM TO LEARN BEHAVIORS FOR AUTONOMOUS VEHICLES  \nLabel: Reinforcement Learning\n\nPaper id: 1069\nTitle: Title: Extended Selection Mechanisms in Genetic Algorithms  \n\nPaper id: 1544\nTitle: Title: Monitoring in Embedded Agents  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2323\nTitle: Title: PHONETIC CLASSIFICATION OF TIMIT SEGMENTS PREPROCESSED WITH LYON'S COCHLEAR MODEL USING A SUPERVISED/UNSUPERVISED HYBRID NEURAL NETWORK  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 788\nTitle: Title: Stochastic simulation algorithms for dynamic probabilistic networks  \nLabel: Probabilistic Methods\n\nPaper id: 1268\nTitle: Title: The BATmobile: Towards a Bayesian Automated Taxi  \nLabel: Probabilistic Methods\n\nPaper id: 492\nTitle: Title: Approximating Optimal Policies for Partially Observable Stochastic Domains  \n\nPaper id: 2419\nTitle: Title: Adaptive probabilistic networks  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 45\nTitle: Title: Acting under Uncertainty: Discrete Bayesian Models for Mobile-Robot Navigation  \nLabel: Reinforcement Learning\n\nPaper id: 213\nTitle: Title: Incremental methods for computing bounds in partially observable Markov decision processes  \nLabel: Reinforcement Learning\n\nPaper id: 1414\nTitle: Title: Tractable Inference for Complex Stochastic Processes  \nLabel: Probabilistic Methods\n\nPaper id: 945\nTitle: Title: Structured Representation of Complex Stochastic Systems  \nLabel: Probabilistic Methods\n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1191\nTitle: Title: Machine Learning Bias, Statistical Bias, and Statistical Variance of Decision Tree Algorithms  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 692\nTitle: Title: Decision Tree Induction: How Effective is the Greedy Heuristic?  \nLabel: Theory\n\nPaper id: 2423\nTitle: Title: Error-Correcting Output Codes: A General Method for Improving Multiclass Inductive Learning Programs  \nLabel: Theory\n\nPaper id: 1053\nTitle: Title: Bias Plus Variance Decomposition for Zero-One Loss Functions  \nLabel: Theory\n\nPaper id: 661\nTitle: Title: A Statistical Approach to Decision Tree Modeling  \nLabel: Probabilistic Methods\n\nPaper id: 1290\nTitle: Title: A THEORY OF LEARNING CLASSIFICATION RULES  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 893\nTitle: Title: LEARNING LOGICAL EXCEPTIONS IN CHESS  \nLabel: Rule Learning\n\nPaper id: 853\nTitle: Title: Error-Correcting Output Codes for Local Learners  \n\nPaper id: 1732\nTitle: Title: Improving the Performance of Radial Basis Function Networks by Learning Center Locations  \nLabel: Neural Networks\n\nPaper id: 429\nTitle: Title: Classifiers: A Theoretical and Empirical Study  \nLabel: Probabilistic Methods\n\nPaper id: 1025\nTitle: Title: Machine Learning 27(1):51-68, 1997. Predicting nearly as well as the best pruning of a decision tree  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 403\nTitle: Title: Landscapes, Learning Costs and Genetic Assimilation.  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2104\nTitle: Title: A study of the effects of group formation on evolutionary search  \nLabel: Genetic Algorithms\n\nPaper id: 2309\nTitle: Title: EVOLVING SENSORS IN ENVIRONMENTS OF CONTROLLED COMPLEXITY  \nLabel: Reinforcement Learning\n\nPaper id: 402\nTitle: Title: The Evolutionary Cost of Learning  \nLabel: Genetic Algorithms\n\nPaper id: 2302\nTitle: Title: Genes, Phenes and the Baldwin Effect: Learning and Evolution in a Simulated Population  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1353\nTitle: Title: Culling Teaching -1 Culling and Teaching in Neuro-evolution  \nLabel: Genetic Algorithms\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 681\nTitle: Title: Guiding or Hiding: Explorations into the Effects of Learning on the Rate of Evolution.  \n\nPaper id: 1880\nTitle: Title: On the relationship between distributed group-behaviour and the behavioural complexity of individuals [Wilson Sober 1994])\nLabel: Genetic Algorithms\n\nPaper id: 538\nTitle: Title: Learning and evolution in neural networks  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1312\nTitle: Title: Learning Trees and Rules with Set-valued Features  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1260\nTitle: Title: Transferring and Retraining Learned Information Filters  \nLabel: Theory\n\nPaper id: 344\nTitle: Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In\nLabel: Rule Learning\n\nPaper id: 418\nTitle: Title: Heterogeneous Uncertainty Sampling for Supervised Learning  \n\nPaper id: 1622\nTitle: Title: Stochastic Propositionalization of Non-Determinate Background Knowledge  \nLabel: Rule Learning\n\nPaper id: 1428\nTitle: Title: Inverse entailment and Progol  \nLabel: Rule Learning\n\nPaper id: 1269\nTitle: Title: Context-sensitive learning methods for text categorization  \nLabel: Theory\n\nPaper id: 638\nTitle: Title: Learning a set of primitive actions with an Induction of decision trees. Machine Learning, 1(1):81-106,\nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 264\nTitle: Title: On Learning More Concepts  \n\nPaper id: 1275\nTitle: Title: Fossil: A Robust Relational Learner  \n\nPaper id: 375\nTitle: Title: Constructive Induction Using a Non-Greedy Strategy for Feature Selection  \nLabel: Theory\n\nPaper id: 1\nTitle: Title: Applications of machine learning: a medical follow up study  \n\nPaper id: 1627\nTitle: Title: Inductive Learning of Characteristic Concept Descriptions from Small Sets of Classified Examples  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2598\nTitle: Title: Duplication of Coding Segments in Genetic Programming  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 854\nTitle: Title: A Comparison of Random Search versus Genetic Programming as Engines for Collective Adaptation  \n\nPaper id: 956\nTitle: Title: Modeling Distributed Search via Social Insects  \n\nPaper id: 2330\nTitle: Title: A comparison of the fixed and floating building block representation in the genetic algorithm  \nLabel: Genetic Algorithms\n\nPaper id: 1230\nTitle: Title: Entailment for Specification Refinement  \nLabel: Genetic Algorithms\n\nPaper id: 1631\nTitle: Title: A Survey of Intron Research in Genetics  \n\nPaper id: 1232\nTitle: Title: Augmenting Collective Adaptation with Simple Process Agents  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2470\nTitle: Title: Induction and Recapitulation of Deep Musical Structure  \n\nPaper id: 2604\nTitle: Title: Empirical studies of the genetic algorithm with non-coding segments  \nLabel: Genetic Algorithms\n\nPaper id: 1769\nTitle: Title: Testing the Robustness of the Genetic Algorithm on the Floating Building Block Representation.  \nLabel: Genetic Algorithms\n\nPaper id: 1696\nTitle: Title: The Royal Road for Genetic Algorithms: Fitness Landscapes and GA Performance  \n\nPaper id: 2211\nTitle: Title: Collective Memory Search 1 Collective Memory Search: Exploiting an Information Center for Exploration  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 301\nTitle: Title: Data Exploration with Reflective Adaptive Models  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 46\nTitle: Title: The Pandemonium System of Reflective Agents  \n\nPaper id: 238\nTitle: Title: Learning from Examples, Agent Teams and the Concept of Reflection  \nLabel: Neural Networks\n\nPaper id: 489\nTitle: Title: Multiple Network Systems (Minos) Modules: Task Division and Module Discrimination 1  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 867\nTitle: Title: Comparison of Neural and Statistical Classifiers| Theory and Practice  \nLabel: Neural Networks\n\nPaper id: 747\nTitle: Title: Cholinergic suppression of transmission may allow combined associative memory function and self-organization in the neocortex.  \n\nPaper id: 2670\nTitle: Title: A proposal for variable selection in the Cox model  \nLabel: Neural Networks\n\nPaper id: 1815\nTitle: Title: Submitted to Circuits, Systems and Signal Processing Neural Network Constructive Algorithms: Trading Generalization for Learning Efficiency?  \nLabel: Neural Networks\n\nPaper id: 193\nTitle: Title: Soft Classification, a.k.a. Risk Estimation, via Penalized Log Likelihood and Smoothing Spline Analysis of Variance  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2635\nTitle: Title: Utilising Explanation to Assist the Refinement of Knowledge-Based Systems  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2231\nTitle: Title: Explaining Anomalies as a Basis for Knowledge Base Refinement  \nLabel: Case Based\n\nPaper id: 136\nTitle: Title: Theory Refinement Combining Analytical and Empirical Methods  \nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 92\nTitle: Title: Learning Analytically and Inductively  \nLabel: Reinforcement Learning\n\nPaper id: 159\nTitle: Title: Bias-Driven Revision of Logical Domain Theories  \nLabel: Theory\n\nPaper id: 1413\nTitle: Title: References Automatic student modeling and bug library construction using theory refinement. Ph.D. ml/ Symbolic revision\nLabel: Case Based\n\nPaper id: 1102\nTitle: Title: Automated Refinement of First-Order Horn-Clause Domain Theories  \nLabel: Rule Learning\n\nPaper id: 479\nTitle: Title: Learning physical descriptions from functional definitions, examples, Learning from examples: The effect of different conceptual\nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1631\nTitle: Title: A Survey of Intron Research in Genetics  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2330\nTitle: Title: A comparison of the fixed and floating building block representation in the genetic algorithm  \nLabel: Genetic Algorithms\n\nPaper id: 2604\nTitle: Title: Empirical studies of the genetic algorithm with non-coding segments  \nLabel: Genetic Algorithms\n\nPaper id: 2407\nTitle: Title: Evolving Turing-Complete Programs for a Register Machine with Self-modifying Code  \nLabel: Genetic Algorithms\n\nPaper id: 934\nTitle: Title: Complexity Compression and Evolution  \nLabel: Genetic Algorithms\n\nPaper id: 2598\nTitle: Title: Duplication of Coding Segments in Genetic Programming  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 168\nTitle: Title: Dynamic Control of Genetic Algorithms using Fuzzy Logic Techniques  \nLabel: Genetic Algorithms\n\nPaper id: 1009\nTitle: Title: Induction of decision trees using RELIEFF  \nLabel: Genetic Algorithms\n\nPaper id: 860\nTitle: Title: A Study in Program Response and the Negative Effects of Introns in Genetic Programming  \n\nPaper id: 844\nTitle: Title: Evolving Compact Solutions in Genetic Programming: A Case Study  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 127\nTitle: Title: Self-Organization and Functional Role of Lateral Connections and Multisize Receptive Fields in the Primary Visual Cortex  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 18\nTitle: Title: Topography And Ocular Dominance: A Model Exploring Positive Correlations  \nLabel: Neural Networks\n\nPaper id: 122\nTitle: Title: Tilt Aftereffects in a Self-Organizing Model of the Primary Visual Cortex  \n\nPaper id: 2228\nTitle: Title: Modeling dynamic receptive field changes in primary visual cortex using inhibitory learning  \nLabel: Neural Networks\n\nPaper id: 124\nTitle: Title: Self-Organization and Segmentation in a Laterally Connected Orientation Map of Spiking Neurons  \nLabel: Neural Networks\n\nPaper id: 747\nTitle: Title: Cholinergic suppression of transmission may allow combined associative memory function and self-organization in the neocortex.  \n\nPaper id: 745\nTitle: Title: References \"Using Neural Networks to Identify Jets\", Kohonen, \"Self Organized Formation of Topologically Correct Feature\nLabel: Neural Networks\n\nPaper id: 2400\nTitle: Title: A Neural Network Model of Visual Tilt Aftereffects  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 336\nTitle: Title: PREENS Tutorial How to use tools and NN simulations  \nLabel: Neural Networks\n\nPaper id: 695\nTitle: Title: There is No Free Lunch but the Starter is Cheap: Generalisation from First Principles  \nLabel: Theory\n\nPaper id: 687\nTitle: Title: Growing Cell Structures A Self-organizing Network for Unsupervised and Supervised Learning  \nLabel: Neural Networks\n\nPaper id: 599\nTitle: Title: A Model of Visually Guided Plasticity of the Auditory Spatial Map in the Barn Owl  \nLabel: Neural Networks\n\nPaper id: 526\nTitle: Title: MML mixture modelling of multi-state, Poisson, von Mises circular and Gaussian distributions  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 876\nTitle: Title: Using and combining predictors that specialize  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1006\nTitle: Title: Learning Probabilistic Automata with Variable Memory Length  \nLabel: Theory\n\nPaper id: 1269\nTitle: Title: Context-sensitive learning methods for text categorization  \nLabel: Theory\n\nPaper id: 453\nTitle: Title: How to Use Expert Advice (Extended Abstract)  \nLabel: Theory\n\nPaper id: 1025\nTitle: Title: Machine Learning 27(1):51-68, 1997. Predicting nearly as well as the best pruning of a decision tree  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2098\nTitle: Title: Predicting a binary sequence almost as well as the optimal biased coin  \nLabel: Theory\n\nPaper id: 1260\nTitle: Title: Transferring and Retraining Learned Information Filters  \nLabel: Theory\n\nPaper id: 2059\nTitle: Title: Challenges in Evolving Controllers for Physical Robots  \nLabel: Theory\n\nPaper id: 1712\nTitle: Title: An Efficient Extension to Mixture Techniques for Prediction and Decision Trees  \nLabel: Theory\n\nPaper id: 1312\nTitle: Title: Learning Trees and Rules with Set-valued Features  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1327\nTitle: Title: On Biases in Estimating Multi-Valued Attributes  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 638\nTitle: Title: Learning a set of primitive actions with an Induction of decision trees. Machine Learning, 1(1):81-106,\nLabel: Theory\n\nPaper id: 1165\nTitle: Title: Discovering Compressive Partial Determinations in Mixed Numerical and Symbolic Domains  \nLabel: Rule Learning\n\nPaper id: 1569\nTitle: Title: Estimating Attributes: Analysis and Extensions of RELIEF  \nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1008\nTitle: Title: Induction of decision trees using RELIEFF  \n\nPaper id: 2146\nTitle: Title: On Learning Read-k-Satisfy-j DNF  \n\nPaper id: 2673\nTitle: Title: A genetic prototype learner  \nLabel: Genetic Algorithms\n\nPaper id: 521\nTitle: Title: Covering vs. Divide-and-Conquer for Top-Down Induction of Logic Programs  \nLabel: Rule Learning\n\nPaper id: 2409\nTitle: Title: Framework for Combining Symbolic and Neural Learning rule extraction from neural networks the KBANN algorithm\nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2294\nTitle: Title: Cooperative Bayesian and Case-Based Reasoning for Solving Multiagent Planning Tasks  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 649\nTitle: Title: Concept Learning and Heuristic Classification in Weak-Theory Domains 1  \nLabel: Case Based\n\nPaper id: 2529\nTitle: Title: Decision-Theoretic Case-Based Reasoning  \nLabel: Probabilistic Methods\n\nPaper id: 1140\nTitle: Title: LEARNING ROBOT BEHAVIORS USING GENETIC ALGORITHMS  \nLabel: Genetic Algorithms\n\nPaper id: 66\nTitle: Title: (1994); Case-Based Reasoning: Foundational Issues, Methodological Variations, and System Approaches. Case-Based Reasoning: Foundational Issues, Methodological\nLabel: Case Based\n\nPaper id: 2380\nTitle: Title: Massively Parallel Case-Based Reasoning with Probabilistic Similarity Metrics  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 981\nTitle: Title: AN ENHANCER FOR REACTIVE PLANS  \nLabel: Case Based\n\nPaper id: 910\nTitle: Title: Learning Sequential Decision Rules Using Simulation Models and Competition  \nLabel: Genetic Algorithms\n\nPaper id: 166\nTitle: Title: Rules and Precedents as Complementary Warrants Complementarity of Rules and Precedents for Classification In a\nLabel: Case Based\n\nPaper id: 2403\nTitle: Title: Reasoning with Portions of Precedents  \nLabel: Case Based\n\nPaper id: 2561\nTitle: Title: MDL Learning of Probabilistic Neural Networks for Discrete Problem Domains  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 452\nTitle: Title: Principal Curve Clustering With Noise  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 117\nTitle: Title: How Many Clusters? Which Clustering Method? Answers Via Model-Based Cluster Analysis 1  \nLabel: Probabilistic Methods\n\nPaper id: 347\nTitle: Title: A Reference Bayesian Test for Nested Hypotheses And its Relationship to the Schwarz Criterion  \nLabel: Probabilistic Methods\n\nPaper id: 513\nTitle: Title: Detecting Features in Spatial Point Processes with Clutter via Model-Based Clustering  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 84\nTitle: Title: Approximate Bayes Factors and Accounting for Model Uncertainty in Generalized Linear Models  \nLabel: Probabilistic Methods\n\nPaper id: 999\nTitle: Title: The out-of-bootstrap method for model averaging and selection  \nLabel: Probabilistic Methods\n\nPaper id: 345\nTitle: Title: On Convergence Properties of the EM Algorithm for Gaussian Mixtures  \nLabel: Probabilistic Methods\n\nPaper id: 713\nTitle: Title: FLEXIBLE PARAMETRIC MEASUREMENT ERROR MODELS  \n\nPaper id: 155\nTitle: Title: Inference in Model-Based Cluster Analysis  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 791\nTitle: Title: Asking Questions to Minimize Errors  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1003\nTitle: Title: Learning Conjunctions of Horn Clauses  \nLabel: Theory\n\nPaper id: 1661\nTitle: Title: Simulating Access to Hidden Information while Learning  \n\nPaper id: 1004\nTitle: Title: Learning Read-Once Formulas with Queries  \nLabel: Theory\n\nPaper id: 786\nTitle: Title: Learning Boolean Read-Once Formulas over Generalized Bases  \nLabel: Theory\n\nPaper id: 1560\nTitle: Title: DESIGN AND ANALYSIS OF EFFICIENT REINFORCEMENT LEARNING ALGORITHMS  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 453\nTitle: Title: How to Use Expert Advice (Extended Abstract)  \nLabel: Theory\n\nPaper id: 2350\nTitle: Title: Exact Learning of -DNF Formulas with Malicious Membership Queries  \nLabel: Theory\n\nPaper id: 2198\nTitle: Title: An Incremental Interactive Algorithm for Regular Grammar Inference  \n\nPaper id: 1161\nTitle: Title: Inductive Learning by Selection of Minimal Complexity Representations  \nLabel: Theory\n\nPaper id: 672\nTitle: Title: Cryptographic Limitations on Learning Boolean Formulae and Finite Automata  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 681\nTitle: Title: Guiding or Hiding: Explorations into the Effects of Learning on the Rate of Evolution.  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 402\nTitle: Title: The Evolutionary Cost of Learning  \nLabel: Genetic Algorithms\n\nPaper id: 712\nTitle: Title: Tracking the red queen: Measurements of adaptive progress in co-evolution ary simulations. In Third European\nLabel: Genetic Algorithms\n\nPaper id: 2309\nTitle: Title: EVOLVING SENSORS IN ENVIRONMENTS OF CONTROLLED COMPLEXITY  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 403\nTitle: Title: Landscapes, Learning Costs and Genetic Assimilation.  \n\nPaper id: 1969\nTitle: Title: Generalization and scaling in reinforcement learning  \n\nPaper id: 54\nTitle: Title: A Competitive Approach to Game Learning  \nLabel: Theory\n\nPaper id: 1965\nTitle: Title: Constructing Nominal Xof-N Attributes  \nLabel: Genetic Algorithms\n\nPaper id: 538\nTitle: Title: Learning and evolution in neural networks  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1150\nTitle: Title: Lessons in Neural Network Training: Overfitting Lessons in Neural Network Training: Overfitting May be Harder\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1149\nTitle: Title: What Size Neural Network Gives Optimal Generalization? Convergence Properties of Backpropagation  \nLabel: Neural Networks\n\nPaper id: 1323\nTitle: Title: On the Distribution of Performance from Multiple Neural Network Trials, On the Distribution of Performance\nLabel: Neural Networks\n\nPaper id: 912\nTitle: Title: Statistical Ideas for Selecting Network Architectures  \nLabel: Neural Networks\n\nPaper id: 1630\nTitle: Title: Averaging and Data Snooping  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1241\nTitle: Title: Bayesian Graphical Models for Discrete Data  \nLabel: Probabilistic Methods\n\nPaper id: 1062\nTitle: Title: Exponentially many local minima for single neurons  \n\nPaper id: 1203\nTitle: Title: A Quantitative Study of Experimental Evaluations of Neural Network Learning Algorithms: Current Research Practice  \nLabel: Neural Networks\n\nPaper id: 2044\nTitle: Title: Neural Networks and Statistical Models Proceedings of the Nineteenth Annual SAS Users Group International Conference,\nLabel: Neural Networks\n\nPaper id: 1145\nTitle: Title: A Unifying View of Some Training Algorithms for Multilayer Perceptrons with FIR Filter Synapses  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1496\nTitle: Title: Adaptive Similarity Assessment for Case-Based Explanation.*  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1125\nTitle: Title: Constructive Similarity Assessment: Using Stored Cases to Define New Situations  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 817\nTitle: Title: Case-Based Similarity Assessment: Estimating Adaptability from Experience  \nLabel: Case Based\n\nPaper id: 1483\nTitle: Title: Context-Based Similarity Applied to Retrieval of Relevant Cases  \nLabel: Case Based\n\nPaper id: 818\nTitle: Title: Learning to Integrate Multiple Knowledge Sources for Case-Based Reasoning  \nLabel: Case Based\n\nPaper id: 166\nTitle: Title: Rules and Precedents as Complementary Warrants Complementarity of Rules and Precedents for Classification In a\nLabel: Case Based\n\nPaper id: 857\nTitle: Title: How to Retrieve Relevant Information?  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1166\nTitle: Title: Assessment of candidate pfsa models induced from symbol datasets  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1160\nTitle: Title: PFSA Modelling of Behavioural Sequences by Evolutionary Programming Rockhampton, Queensland. (1994) \"PFSA Modelling of Behavioural\nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 763\nTitle: Title: PREENS, a Parallel Research Execution Environment for Neural Systems  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 747\nTitle: Title: Cholinergic suppression of transmission may allow combined associative memory function and self-organization in the neocortex.  \n\nPaper id: 2355\nTitle: Title: CONVIS: Action Oriented Control and Visualization of Neural Networks Introduction and Technical Description  \nLabel: Neural Networks\n\nPaper id: 241\nTitle: Title: Segmentation and Classification of Combined Optical and Radar Imagery  \n\nPaper id: 1879\nTitle: Title: Rochester Connectionist Simulator  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 73\nTitle: Title: LEARNING TO GENERATE ARTIFICIAL FOVEA TRAJECTORIES FOR TARGET DETECTION  \nLabel: Reinforcement Learning\n\nPaper id: 362\nTitle: Title: Learning Topology-Preserving Maps Using Self-Supervised Backpropagation  \nLabel: Neural Networks\n\nPaper id: 113\nTitle: Title: LU TP  Pattern Discrimination Using Feed-Forward Networks a Benchmark Study of Scaling Behaviour  \nLabel: Neural Networks\n\nPaper id: 18\nTitle: Title: Topography And Ocular Dominance: A Model Exploring Positive Correlations  \nLabel: Neural Networks\n\nPaper id: 527\nTitle: Title: VISIT: An Efficient Computational Model of Human Visual Attention  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 747\nTitle: Title: Cholinergic suppression of transmission may allow combined associative memory function and self-organization in the neocortex.  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 73\nTitle: Title: LEARNING TO GENERATE ARTIFICIAL FOVEA TRAJECTORIES FOR TARGET DETECTION  \nLabel: Reinforcement Learning\n\nPaper id: 696\nTitle: Title: GAL: Networks that grow when they learn and shrink when they forget  \nLabel: Neural Networks\n\nPaper id: 202\nTitle: Title: Dyslexic and Category-Specific Aphasic Impairments in a Self-Organizing Feature Map Model of the Lexicon  \n\nPaper id: 18\nTitle: Title: Topography And Ocular Dominance: A Model Exploring Positive Correlations  \nLabel: Neural Networks\n\nPaper id: 310\nTitle: Title: Forecasting electricity demand using nonlinear mixture of experts  \nLabel: Neural Networks\n\nPaper id: 779\nTitle: Title: Monte Carlo Comparison of Non-hierarchical Unsupervised Classifiers  \n\nPaper id: 113\nTitle: Title: LU TP  Pattern Discrimination Using Feed-Forward Networks a Benchmark Study of Scaling Behaviour  \nLabel: Neural Networks\n\nPaper id: 353\nTitle: Title: Application of Neural Networks for the Classification of Diffuse Liver Disease by Quantitative Echography  \nLabel: Neural Networks\n\nPaper id: 127\nTitle: Title: Self-Organization and Functional Role of Lateral Connections and Multisize Receptive Fields in the Primary Visual Cortex  \n\nPaper id: 610\nTitle: Title: Figure 1: The architecture of a Kohonen network. Each input neuron is fully connected with\nLabel: Neural Networks\n\nPaper id: 700\nTitle: Title: Is Transfer Inductive?  \nLabel: Theory\n\nPaper id: 330\nTitle: Title: Local Feature Analysis: A general statistical theory for object representation  \n\nPaper id: 112\nTitle: Title: Interpretable Neural Networks with BP-SOM  \nLabel: Neural Networks\n\nPaper id: 527\nTitle: Title: VISIT: An Efficient Computational Model of Human Visual Attention  \nLabel: Neural Networks\n\nPaper id: 83\nTitle: Title: A Neural Network Pole Balancer that Learns and Operates on a Real Robot in Real Time  \nLabel: Neural Networks\n\nPaper id: 207\nTitle: Title: LEARNING BY ERROR-DRIVEN DECOMPOSITION  \nLabel: Neural Networks\n\nPaper id: 628\nTitle: Title: Figure 8: time complexity of unit parallelism measured on MANNA theoretical prediction #nodes N time\nLabel: Neural Networks\n\nPaper id: 579\nTitle: Title: Comparison of Kernel Estimators, Perceptrons, and Radial-Basis Functions for OCR and Speech Classification  \nLabel: Neural Networks\n\nPaper id: 349\nTitle: Title: Measuring Organization and Asymmetry in Bihemispheric Topographic Maps  \nLabel: Neural Networks\n\nPaper id: 397\nTitle: Title: Truth-from-Trash Learning and the Mobot  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 659\nTitle: Title: Trading Spaces: Computation, Representation and the Limits of Uninformed Learning  \n\nPaper id: 15\nTitle: Title: Back Propagation is Sensitive to Initial Conditions  \nLabel: Neural Networks\n\nPaper id: 567\nTitle: Title: Generalization in Reinforcement Learning: Successful Examples Using Sparse Coarse Coding  \nLabel: Reinforcement Learning\n\nPaper id: 668\nTitle: Title: Nonlinear gated experts for time series: discovering regimes and avoiding overfitting  \nLabel: Neural Networks\n\nPaper id: 520\nTitle: Title: CANCER DIAGNOSIS AND PROGNOSIS VIA LINEAR-PROGRAMMING-BASED MACHINE LEARNING  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2237\nTitle: Title: Specialization under Social Conditions in Shared Environments  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2274\nTitle: Title: Specialization in Populations of Artificial Neural Networks  \n\nPaper id: 2170\nTitle: Title: Generalist and Specialist Behavior Due to Individual Energy Extracting Abilities.  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1325\nTitle: Title: Environmental Effects on Minimal Behaviors in the Minimat World  \nLabel: Genetic Algorithms\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1529\nTitle: Title: Explanation Based Learning: A Comparison of Symbolic and Neural Network Approaches  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n\nPaper id: 882\nTitle: Title: Learning To Play the Game of Chess  \nLabel: Reinforcement Learning\n\nPaper id: 1314\nTitle: Title: Quick 'n' Dirty Generalization For Mobile Robot Learning Content Areas: robotics, reinforcement learning, machine learning,\nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 82\nTitle: Title: A Reinforcement Learning Approach to Job-shop Scheduling  \nLabel: Reinforcement Learning\n\nPaper id: 601\nTitle: Title: Active Gesture Recognition using Partially Observable Markov Decision Processes  \nLabel: Reinforcement Learning\n\nPaper id: 173\nTitle: Title: An Upper Bound on the Loss from Approximate Optimal-Value Functions  \nLabel: Reinforcement Learning\n\nPaper id: 2\nTitle: Title: Submitted to NIPS96, Section: Applications. Preference: Oral presentation Reinforcement Learning for Dynamic Channel Allocation in\nLabel: Reinforcement Learning\n\nPaper id: 1012\nTitle: Title: TDLeaf(): Combining Temporal Difference learning with game-tree search.  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1705\nTitle: Title: Learning from Incomplete Boundary Queries Using Split Graphs and Hypergraphs (Extended Abstract)  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1364\nTitle: Title: Learning k-term DNF Formulas with an Incomplete Membership Oracle  \nLabel: Theory\n\nPaper id: 2356\nTitle: Title: Learning With Unreliable Boundary Queries  \nLabel: Theory\n\nPaper id: 459\nTitle: Title: Pac Learning, Noise, and Geometry  \n\nPaper id: 1469\nTitle: Title: Warning: missing six few referencesfixed in proceedings. Learning with Queries but Incomplete Information (Extended Abstract)  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1456\nTitle: Title: An Interactive Model of Teaching  \nLabel: Theory\n\nPaper id: 2246\nTitle: Title: Learning to model sequences generated by switching distributions  \nLabel: Theory\n\nPaper id: 109\nTitle: Title: A General Lower Bound on the Number of Examples Needed for Learning  \nLabel: Theory\n\nPaper id: 640\nTitle: Title: Learning in the Presence of Malicious Errors  \n\nPaper id: 1004\nTitle: Title: Learning Read-Once Formulas with Queries  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 64\nTitle: Title: Integrating Creativity and Reading: A Functional Approach  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 289\nTitle: Title: A theory of questions and question asking  \nLabel: Case Based\n\nPaper id: 583\nTitle: Title: Introspective reasoning using meta-explanations for multistrategy learning  \nLabel: Case Based\n\nPaper id: 284\nTitle: Title: Role of Ontology in Creative Understanding  \n\nPaper id: 486\nTitle: Title: CASE-BASED CREATIVE DESIGN  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 50\nTitle: Title: Abstract  \n\nPaper id: 231\nTitle: Title: Understanding Creativity: A Case-Based Approach  \nLabel: Case Based\n\nPaper id: 1278\nTitle: Title: A Functional Theory of Creative Reading  \nLabel: Case Based\n\nPaper id: 1126\nTitle: Title: Towards A Computer Model of Memory Search Strategy Learning  \n\nPaper id: 612\nTitle: Title: Indexing, Elaboration and Refinement: Incremental Learning of Explanatory Cases  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2612\nTitle: Title: Models of Parallel Adaptive Logic  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 724\nTitle: Title: ASOCS: A Multilayered Connectionist Network with Guaranteed Learning of Arbitrary Mappings  \nLabel: Neural Networks\n\nPaper id: 2625\nTitle: Title: Digital Neural Networks  \nLabel: Neural Networks\n\nPaper id: 26\nTitle: Title: Neural Network Applicability: Classifying the Problem Space  \nLabel: Neural Networks\n\nPaper id: 1903\nTitle: Title: DNA: A New ASOCS Model With Improved Implementation Potential  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1129\nTitle: Title: A Self-Organizing Binary Decision Tree For Incrementally Defined Rule Based  \n\nPaper id: 747\nTitle: Title: Cholinergic suppression of transmission may allow combined associative memory function and self-organization in the neocortex.  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2027\nTitle: Title: Coordinating Reactive Behaviors  keywords: reactive systems, planning and learning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n\nPaper id: 2409\nTitle: Title: Framework for Combining Symbolic and Neural Learning rule extraction from neural networks the KBANN algorithm\nLabel: Neural Networks\n\nPaper id: 465\nTitle: Title: Strategy Learning with Multilayer Connectionist Representations 1  \nLabel: Reinforcement Learning\n\nPaper id: 636\nTitle: Title: Robot Shaping: Developing Situated Agents through Learning  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1782\nTitle: Title: Least-Squares Temporal Difference Learning  \n\nPaper id: 910\nTitle: Title: Learning Sequential Decision Rules Using Simulation Models and Competition  \nLabel: Genetic Algorithms\n\nPaper id: 552\nTitle: Title: Learning to Act using Real-Time Dynamic Programming  \nLabel: Reinforcement Learning\n\nPaper id: 1316\nTitle: Title: KnightCap: A chess program that learns by combining TD() with minimax search  \nLabel: Reinforcement Learning\n\nPaper id: 1378\nTitle: Title: Generalization in Reinforcement Learning: Safely Approximating the Value Function  \nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2533\nTitle: Title: An Object-Based Neural Model of Serial Processing in Visual Multielement Tracking  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2517\nTitle: Title: Solving the Temporal Binding Problem: A Neural Theory for Constructing and Updating Object Files  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 606\nTitle: Title: Analysis of the Numerical Effects of Parallelism on a Parallel Genetic Algorithm  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 537\nTitle: Title: Adaptive Global Optimization with Local Search  \n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 395\nTitle: Title: Evolving Graphs and Networks with Edge Encoding: Preliminary Report  \n\nPaper id: 793\nTitle: Title: A Survey of Evolution Strategies  \nLabel: Genetic Algorithms\n\nPaper id: 2363\nTitle: Title: Modeling the Evolution of Motivation  \n\nPaper id: 1536\nTitle: Title: Representation and Evolution of Neural Networks  \nLabel: Genetic Algorithms\n\nPaper id: 2274\nTitle: Title: Specialization in Populations of Artificial Neural Networks  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 953\nTitle: Title: Behavior Hierarchy for Autonomous Mobile Robots: Fuzzy-behavior modulation and evolution  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 972\nTitle: Title: On Genetic Programming of Fuzzy Rule-Based Systems for Intelligent Control  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1478\nTitle: Title: Lazy Bayesian Trees  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1335\nTitle: Title: A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection  \nLabel: Probabilistic Methods\n\nPaper id: 1336\nTitle: Title: Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid  \nLabel: Probabilistic Methods\n\nPaper id: 2338\nTitle: Title: Beyond Independence: Conditions for the Optimality of the Simple Bayesian Classifier  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1337\nTitle: Title: MLC A Machine Learning Library in C  \nLabel: Theory\n\nPaper id: 2127\nTitle: Title: NAIVE BAYESIAN LEARNING  Adapted from  \nLabel: Probabilistic Methods\n\nPaper id: 1339\nTitle: Title: An Analysis of Bayesian Classifiers (1988), involves the formulation of average-case models for specific algorithms\nLabel: Theory\n\nPaper id: 1267\nTitle: Title: Estimating the Accuracy of Learned Concepts  \n\nPaper id: 885\nTitle: Title: Model selection using measure functions  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 417\nTitle: Title: Constructing Intermediate Concepts by Decomposition of Real Functions  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 508\nTitle: Title: Machine Learning by Function Decomposition  \nLabel: Theory\n\nPaper id: 317\nTitle: Title: A dataset decomposition approach to data mining and machine discovery  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 523\nTitle: Title: Some studies in machine learning using the game of checkers. IBM Journal, 3(3):211-229, 1959. Some\nLabel: Genetic Algorithms\n\nPaper id: 2326\nTitle: Title: Pattern Theoretic Feature Extraction and Constructive Induction  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1625\nTitle: Title: Reinforcement Learning by Probability Matching  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1580\nTitle: Title: MIMIC: Finding Optima by Estimating Probability Densities  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1577\nTitle: Title: Fast Probabilistic Modeling for Combinatorial Optimization  \nLabel: Genetic Algorithms\n\nPaper id: 689\nTitle: Title: Where Genetic Algorithms Excel  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1082\nTitle: Title: Specialization of Logic Programs by Pruning SLD-Trees  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1081\nTitle: Title: Specialization of Recursive Predicates  \n\nPaper id: 2312\nTitle: Title: Theory-Guided Induction of Logic Programs by Inference of Regular Languages recursive clauses. merlin on the\nLabel: Rule Learning\n\nPaper id: 521\nTitle: Title: Covering vs. Divide-and-Conquer for Top-Down Induction of Logic Programs  \nLabel: Rule Learning\n\nPaper id: 1259\nTitle: Title: Finding Accurate Frontiers: A Knowledge-Intensive Approach to Relational Learning  \nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 893\nTitle: Title: LEARNING LOGICAL EXCEPTIONS IN CHESS  \nLabel: Rule Learning\n\nPaper id: 92\nTitle: Title: Learning Analytically and Inductively  \nLabel: Reinforcement Learning\n\nPaper id: 344\nTitle: Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In\nLabel: Rule Learning\n\nPaper id: 1944\nTitle: Title: Knowledge Acquisition with a Knowledge-Intensive Machine Learning System  \nLabel: Rule Learning\n\nPaper id: 156\nTitle: Title: Structural Regression Trees  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2535\nTitle: Title: Adaptive Wavelet Control of Nonlinear Systems  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2176\nTitle: Title: An Analytical Framework for Local Feedforward Networks  \nLabel: Neural Networks\n\nPaper id: 1668\nTitle: Title: Space-Frequency Localized Basis Function Networks for Nonlinear System Estimation and Control  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1488\nTitle: Title: Identification and Control of Nonlinear Systems Using Neural Network Models: Design and Stability Analysis  \nLabel: Neural Networks\n\nPaper id: 2378\nTitle: Title: Priors, Stabilizers and Basis Functions: from regularization to radial, tensor and additive splines  \nLabel: Neural Networks\n\nPaper id: 1910\nTitle: Title: Minimax Estimation via Wavelet Shrinkage  a pleasure to acknowledge friendly conversations with Gerard Kerkyacharian,  \nLabel: Probabilistic Methods\n\nPaper id: 611\nTitle: Title: Learning networks for face analysis and synthesis  \nLabel: Neural Networks\n\nPaper id: 1914\nTitle: Title: Local Feedforward Networks  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1634\nTitle: Title: Combining Linear Discriminant Functions with Neural Networks for Supervised Learning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1252\nTitle: Title: Constructive Training Methods for Feedforward Neural Networks with Binary Weights  \nLabel: Neural Networks\n\nPaper id: 74\nTitle: Title: Hierarchical Mixtures of Experts and the EM Algorithm  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 975\nTitle: Title: State Reconstruction for Determining Predictability in Driven Nonlinear Acoustical Systems  \n\nPaper id: 2124\nTitle: Title: A Hierarchical Latent Variable Model for Data Visualization  \nLabel: Neural Networks\n\nPaper id: 949\nTitle: Title: Classifying Seismic Signals by Integrating Ensembles of Neural Networks  \nLabel: Neural Networks\n\nPaper id: 2390\nTitle: Title: A HIERARCHICAL COMMUNITY OF EXPERTS  \nLabel: Neural Networks\n\nPaper id: 907\nTitle: Title: Visual Tracking of Moving Objects using a Neural Network Controller  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 835\nTitle: Title: Case-Based Acquisition of Place Knowledge  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1248\nTitle: Title: Lazy Acquisition of Place Knowledge  \nLabel: Case Based\n\nPaper id: 688\nTitle: Title: Exploration and Model Building in Mobile Robot Domains  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 60\nTitle: Title: The Efficient Learning of Multiple Task Sequences  \nLabel: Reinforcement Learning\n\nPaper id: 66\nTitle: Title: (1994); Case-Based Reasoning: Foundational Issues, Methodological Variations, and System Approaches. Case-Based Reasoning: Foundational Issues, Methodological\nLabel: Case Based\n\nPaper id: 552\nTitle: Title: Learning to Act using Real-Time Dynamic Programming  \nLabel: Reinforcement Learning\n\nPaper id: 207\nTitle: Title: LEARNING BY ERROR-DRIVEN DECOMPOSITION  \nLabel: Neural Networks\n\nPaper id: 412\nTitle: Title: The Influence of Domain Properties on the Performance of Real-Time Search Algorithms  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2056\nTitle: Title: PREDICTION WITH GAUSSIAN PROCESSES: FROM LINEAR REGRESSION TO LINEAR PREDICTION AND BEYOND To appear in\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2095\nTitle: Title: A Practical Monte Carlo Implementation of Bayesian Learning  \nLabel: Neural Networks\n\nPaper id: 271\nTitle: Title: Bayesian Regression Filters and the Issue of Priors  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 718\nTitle: Title: Gaussian Regression and Optimal Finite Dimensional Linear Models  \nLabel: Neural Networks\n\nPaper id: 2230\nTitle: Title: In Advances in Neural Information Processing Systems 8  Gaussian Processes for Regression  \nLabel: Neural Networks\n\nPaper id: 157\nTitle: Title: A Practical Bayesian Framework for Backprop Networks  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1986\nTitle: Title: BOOSTING AND NAIVE BAYESIAN LEARNING  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 569\nTitle: Title: A decision-theoretic generalization of on-line learning and an application to boosting how the weight-update rule\n\nPaper id: 2462\nTitle: Title: Building Classifiers using Bayesian Networks  \nLabel: Probabilistic Methods\n\nPaper id: 1329\nTitle: Title: Supervised and Unsupervised Discretization of Continuous Features  \nLabel: Theory\n\nPaper id: 70\nTitle: Title: Boosting the Margin: A New Explanation for the Effectiveness of Voting Methods  \nLabel: Theory\n\nPaper id: 2338\nTitle: Title: Beyond Independence: Conditions for the Optimality of the Simple Bayesian Classifier  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1273\nTitle: Title: The Sources of Increased Accuracy for Two Proposed Boosting Algorithms  \nLabel: Theory\n\nPaper id: 1020\nTitle: Title: Error-Based and Entropy-Based Discretization of Continuous Features  \n\nPaper id: 931\nTitle: Title: MAJORITY VOTE CLASSIFIERS: THEORY AND APPLICATIONS  \nLabel: Theory\n\nPaper id: 1025\nTitle: Title: Machine Learning 27(1):51-68, 1997. Predicting nearly as well as the best pruning of a decision tree  \nLabel: Theory\n\nPaper id: 1692\nTitle: Title: Boosting Trees for Cost-Sensitive Classifications  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2197\nTitle: Title: MLC Tutorial A Machine Learning library of C classes.  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2342\nTitle: Title: The Power of Decision Tables  \nLabel: Theory\n\nPaper id: 430\nTitle: Title: Irrelevant Features and the Subset Selection Problem  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2343\nTitle: Title: Feature Subset Selection Using the Wrapper Method: Overfitting and Dynamic Search Space Topology  \n\nPaper id: 2577\nTitle: Title: Targeting Business Users with Decision Table Classifiers  \nLabel: Probabilistic Methods\n\nPaper id: 177\nTitle: Title: Evaluation and Selection of Biases in Machine Learning  \nLabel: Theory\n\nPaper id: 632\nTitle: Title: Toward Optimal Feature Selection  \nLabel: Probabilistic Methods\n\nPaper id: 2033\nTitle: Title: Improving RBF Networks by the Feature Selection Approach EUBAFES  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 635\nTitle: Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 89\nTitle: Title: NP-Completeness of Searches for Smallest Possible Feature Sets a subset of the set of all\n\nPaper id: 660\nTitle: Title: Efficient Algorithms for Identifying Relevant Features  \nLabel: Theory\n\nPaper id: 640\nTitle: Title: Learning in the Presence of Malicious Errors  \n\nPaper id: 109\nTitle: Title: A General Lower Bound on the Number of Examples Needed for Learning  \nLabel: Theory\n\nPaper id: 381\nTitle: Title: Compression-Based Feature Subset Selection  Keywords: Minimum Description Length Principle, Cross Validation, Noise  \nLabel: Theory\n\nPaper id: 256\nTitle: Title: Using Decision Trees to Improve Case-Based Learning  \nLabel: Case Based\n\nPaper id: 442\nTitle: Title: Searching for dependencies in Bayesian classifiers j A n V n j If the attributes\nLabel: Probabilistic Methods\n\nPaper id: 177\nTitle: Title: Evaluation and Selection of Biases in Machine Learning  \nLabel: Theory\n\nPaper id: 683\nTitle: Title: On the Greediness of Feature Selection Algorithms  \n\nPaper id: 651\nTitle: Title: A Monotonic Measure for Optimal Feature Selection  \nLabel: Neural Networks\n\nPaper id: 632\nTitle: Title: Toward Optimal Feature Selection  \nLabel: Probabilistic Methods\n\nPaper id: 172\nTitle: Title: Efficient Feature Selection in Conceptual Clustering  \n\nPaper id: 430\nTitle: Title: Irrelevant Features and the Subset Selection Problem  \nLabel: Theory\n\nPaper id: 722\nTitle: Title: A Study of Maximal-Coverage Learning Algorithms  \nLabel: Theory\n\nPaper id: 208\nTitle: Title: Feature Subset Selection as Search with Probabilistic Estimates  \nLabel: Theory\n\nPaper id: 474\nTitle: Title: Protein Structure Prediction: Selecting Salient Features from Large Candidate Pools  \n\nPaper id: 375\nTitle: Title: Constructive Induction Using a Non-Greedy Strategy for Feature Selection  \nLabel: Theory\n\nPaper id: 436\nTitle: Title: Pattern Theoretic Knowledge Discovery  \nLabel: Theory\n\nPaper id: 634\nTitle: Title: Oblivious Decision Trees and Abstract Cases  \nLabel: Case Based\n\nPaper id: 686\nTitle: Title: Prototype and Feature Selection by Sampling and Random Mutation Hill Climbing Algorithms  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2475\nTitle: Title: Learning polynomials with queries: The highly noisy case  task for the case when F  \nLabel: Theory\n\nPaper id: 225\nTitle: Title: on Inductive Logic Programming (ILP-95) Inducing Logic Programs without Explicit Negative Examples  \n\nPaper id: 116\nTitle: Title: Rate of Convergence of the Gibbs Sampler by Gaussian Approximation  SUMMARY  \n\nPaper id: 884\nTitle: Title: PAC Learning of One-Dimensional Patterns  \n\nPaper id: 1908\nTitle: Title: Induction of Selective Bayesian Classifiers  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2238\nTitle: Title: Where Does the Good Stuff Go, and Why? How contextual semantics influences program structure in\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2271\nTitle: Title: How Fitness Structure Affects Subsolution Acquisition in Genetic Programming  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2259\nTitle: Title: An Experimental Analysis of Schema Creation, Propagation and Disruption in Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 2252\nTitle: Title: Neural Programming and an Internal Reinforcement Policy  \nLabel: Genetic Algorithms\n\nPaper id: 2249\nTitle: Title: Using a Distance Metric on Genetic Programs to Understand Genetic Operators  \nLabel: Genetic Algorithms\n\nPaper id: 2250\nTitle: Title: The Impact of External Dependency in Genetic Programming Primitives  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2277\nTitle: Title: Discovery of Symbolic, Neuro-Symbolic and Neural Networks with Parallel Distributed Genetic Programming  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1931\nTitle: Title: AUTOMATED TOPOLOGY AND SIZING OF ANALOG CIRCUITS AUTOMATED DESIGN OF BOTH THE TOPOLOGY AND SIZING\n\nPaper id: 2624\nTitle: Title: A Comparison between Cellular Encoding and Direct Encoding for Genetic Neural Networks  \nLabel: Genetic Algorithms\n\nPaper id: 2252\nTitle: Title: Neural Programming and an Internal Reinforcement Policy  \nLabel: Genetic Algorithms\n\nPaper id: 1277\nTitle: Title: Evolution of Pseudo-colouring Algorithms for Image Enhancement with Interactive Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 2269\nTitle: Title: Some Steps Towards a Form of Parallel Distributed Genetic Programming  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 1533\nTitle: Title: Evolving Visual Routines  \nLabel: Genetic Algorithms\n\nPaper id: 2317\nTitle: Title: Cellular Encoding Applied to Neurocontrol  \n\nPaper id: 523\nTitle: Title: Some studies in machine learning using the game of checkers. IBM Journal, 3(3):211-229, 1959. Some\nLabel: Genetic Algorithms\n\nPaper id: 2152\nTitle: Title: Cellular Encoding for Interactive Evolutionary Robotics  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 550\nTitle: Title: LEARNING BY USING DYNAMIC FEATURE COMBINATION AND SELECTION  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 569\nTitle: Title: A decision-theoretic generalization of on-line learning and an application to boosting how the weight-update rule\n\nPaper id: 2423\nTitle: Title: Error-Correcting Output Codes: A General Method for Improving Multiclass Inductive Learning Programs  \nLabel: Theory\n\nPaper id: 438\nTitle: Title: A System for Induction of Oblique Decision Trees  \nLabel: Theory\n\nPaper id: 1422\nTitle: Title: Generating Accurate and Diverse Members of a Neural-Network Ensemble  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2099\nTitle: Title: Game Theory, On-line Prediction and Boosting  \nLabel: Theory\n\nPaper id: 1191\nTitle: Title: Machine Learning Bias, Statistical Bias, and Statistical Variance of Decision Tree Algorithms  \n\nPaper id: 1223\nTitle: Title: A New Metric-Based Approach to Model Selection  \nLabel: Theory\n\nPaper id: 1269\nTitle: Title: Context-sensitive learning methods for text categorization  \nLabel: Theory\n\nPaper id: 1657\nTitle: Title: Using Neural Networks to Automatically Refine Expert System Knowledge Bases: Experiments in the NYNEX MAX Domain  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1863\nTitle: Title: Effects of Different Types of New Attribute on Constructive Induction  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1644\nTitle: Title: A Comparative Study of ID3 and Backpropagation for English Text-to-Speech Mapping  \nLabel: Neural Networks\n\nPaper id: 1964\nTitle: Title: Constructing Nominal Xof-N Attributes  \nLabel: Theory\n\nPaper id: 1595\nTitle: Title: ID2-of-3: Constructive Induction of M of-N Concepts for Discriminators in Decision Trees  \n\nPaper id: 1862\nTitle: Title: Continuous-valued Xof-N Attributes Versus Nominal Xof-N Attributes for Constructive Induction: A Case Study  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1576\nTitle: Title: What do Constructive Learners Really Learn?  \nLabel: Theory\n\nPaper id: 1601\nTitle: Title: Learning the Past Tense of English Verbs: The Symbolic Pattern Associator vs. Connectionist Models  \nLabel: Neural Networks\n\nPaper id: 2484\nTitle: Title: The evaluation of Anapron: A case study in evaluating a case-based system  \nLabel: Case Based\n\nPaper id: 1732\nTitle: Title: Improving the Performance of Radial Basis Function Networks by Learning Center Locations  \nLabel: Neural Networks\n\nPaper id: 836\nTitle: Title: Unsupervised Constructive Learning  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 659\nTitle: Title: Trading Spaces: Computation, Representation and the Limits of Uninformed Learning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 11\nTitle: Title: Simple Genetic Programming for Supervised Learning Problems  \n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 695\nTitle: Title: There is No Free Lunch but the Starter is Cheap: Generalisation from First Principles  \nLabel: Theory\n\nPaper id: 397\nTitle: Title: Truth-from-Trash Learning and the Mobot  \n\nPaper id: 625\nTitle: Title: Statistical Biases in Backpropagation Learning  Keywords: Cognitive Science, Pattern recognition  \n\nPaper id: 624\nTitle: Title: Measuring the Difficulty of Specific Learning Problems  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 395\nTitle: Title: Evolving Graphs and Networks with Edge Encoding: Preliminary Report  \n\nPaper id: 800\nTitle: Title: Vector Quantizer Design Using Genetic Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 2196\nTitle: Title: Effects of Occam's Razor in Evolving Sigma-Pi Neural Nets  \nLabel: Genetic Algorithms\n\nPaper id: 606\nTitle: Title: Analysis of the Numerical Effects of Parallelism on a Parallel Genetic Algorithm  \n\nPaper id: 1130\nTitle: Title: Dynamic Hill Climbing: Overcoming the limita- tions of optimization techniques  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1367\nTitle: Title: Learning to Refine Indexing by Introspective Reasoning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 817\nTitle: Title: Case-Based Similarity Assessment: Estimating Adaptability from Experience  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 819\nTitle: Title: A Case Study of Case-Based CBR  \nLabel: Case Based\n\nPaper id: 1212\nTitle: Title: Acquiring Case Adaptation Knowledge: A Hybrid Approach  \n\nPaper id: 818\nTitle: Title: Learning to Integrate Multiple Knowledge Sources for Case-Based Reasoning  \nLabel: Case Based\n\nPaper id: 1125\nTitle: Title: Constructive Similarity Assessment: Using Stored Cases to Define New Situations  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1495\nTitle: Title: Clique Detection via Genetic Programming  Topics in Combinatorial Optimization  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1231\nTitle: Title: Type Inheritance in Strongly Typed Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 995\nTitle: Title: Evolving a Team  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2673\nTitle: Title: A genetic prototype learner  \nLabel: Genetic Algorithms\n\nPaper id: 2086\nTitle: Title: ABSTRACT In general, the machine learning process can be accelerated through the use of additional\nLabel: Genetic Algorithms\n\nPaper id: 415\nTitle: Title: Competitive Environments Evolve Better Solutions for Complex Tasks  \nLabel: Genetic Algorithms\n\nPaper id: 1985\nTitle: Title: ABSTRACT  \nLabel: Genetic Algorithms\n\nPaper id: 1232\nTitle: Title: Augmenting Collective Adaptation with Simple Process Agents  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2182\nTitle: Title: Weakly Learning DNF and Characterizing Statistical Query Learning Using Fourier Analysis  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1003\nTitle: Title: Learning Conjunctions of Horn Clauses  \nLabel: Theory\n\nPaper id: 2011\nTitle: Title: An O(n log log n Learning Algorithm for DNF under the Uniform Distribution  \nLabel: Theory\n\nPaper id: 591\nTitle: Title: Toward Efficient Agnostic Learning  \nLabel: Theory\n\nPaper id: 2633\nTitle: Title: Learning Using Group Representations (Extended Abstract)  \n\nPaper id: 1748\nTitle: Title: A Quantum Computational Learning Algorithm  \nLabel: Theory\n\nPaper id: 1897\nTitle: Title: On Learning Visual Concepts and DNF Formulae  \nLabel: Theory\n\nPaper id: 1835\nTitle: Title: Implementation Issues in the Fourier Transform Algorithm  \nLabel: Theory\n\nPaper id: 2146\nTitle: Title: On Learning Read-k-Satisfy-j DNF  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 25\nTitle: Title: General Bounds on Statistical Query Learning and PAC Learning with Noise via Hypothesis Boosting  \nLabel: Theory\n\nPaper id: 488\nTitle: Title: Prediction, Learning, Uniform Convergence, and Scale-sensitive Dimensions  \n\nPaper id: 1364\nTitle: Title: Learning k-term DNF Formulas with an Incomplete Membership Oracle  \nLabel: Theory\n\nPaper id: 848\nTitle: Title: An Experimental and Theoretical Comparison of Model Selection Methods on simple model selection problems, the\nLabel: Theory\n\nPaper id: 1358\nTitle: Title: On the Complexity of Function Learning  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 627\nTitle: Title: Learning Symbolic Rules Using Artificial Neural Networks  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1057\nTitle: Title: Submitted to the Future Generation Computer Systems special issue on Data Mining. Using Neural Networks\nLabel: Neural Networks\n\nPaper id: 1679\nTitle: Title: Machine learning in prognosis of the femoral neck fracture recovery examples, estimating attributes, explanation ability,\n\nPaper id: 1270\nTitle: Title: Automatic Parameter Selection by Minimizing Estimated Error  \nLabel: Theory\n\nPaper id: 338\nTitle: Title: Knowledge Integration and Rule Extraction in Neural Networks Ph.D. Proposal  \nLabel: Neural Networks\n\nPaper id: 1562\nTitle: Title: Using Sampling and Queries to Extract Rules from Trained Neural Networks  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1569\nTitle: Title: Estimating Attributes: Analysis and Extensions of RELIEF  \nLabel: Rule Learning\n\nPaper id: 1726\nTitle: Title: Prognosing the Survival Time of the Patients with the Anaplastic Thyroid Carcinoma with Machine Learning  \nLabel: Rule Learning\n\nPaper id: 208\nTitle: Title: Feature Subset Selection as Search with Probabilistic Estimates  \nLabel: Theory\n\nPaper id: 2342\nTitle: Title: The Power of Decision Tables  \nLabel: Theory\n\nPaper id: 1307\nTitle: Title: Extracting Tree-Structured Representations of Trained Networks  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2141\nTitle: Title: Fast and Simple Algorithms for Perfect Phylogeny and Triangulating Colored Graphs  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2511\nTitle: Title: A Faster Algorithm for the Perfect Phylogeny Problem when the number of Characters is Fixed TR94-05  \nLabel: Theory\n\nPaper id: 2418\nTitle: Title: A Fast Algorithm for the Computation and Enumeration of Perfect Phylogenies  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2320\nTitle: Title: Inserting the best known bounds for weighted bipar tite matching [11], with 1=2 p polynomial-time\nLabel: Theory\n\nPaper id: 2345\nTitle: Title: The Hardness of Problems on Thin Colored Graphs  \nLabel: Theory\n\nPaper id: 2083\nTitle: Title: TREE CONTRACTIONS AND EVOLUTIONARY TREES  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 623\nTitle: Title: State-Space Abstraction for Anytime Evaluation of Probabilistic Networks  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 637\nTitle: Title: Computational complexity reduction for BN2O networks using similarity of states  \nLabel: Probabilistic Methods\n\nPaper id: 1064\nTitle: Title: Incremental Tradeoff Resolution in Qualitative Probabilistic Networks  \nLabel: Probabilistic Methods\n\nPaper id: 2341\nTitle: Title: Dynamic Belief Networks for Discrete Monitoring  \nLabel: Probabilistic Methods\n\nPaper id: 1172\nTitle: Title: Introduction to the Special Section on Knowledge-Based Construction of Probabilistic and Decision Models (IEEE Transactions\nLabel: Probabilistic Methods\n\nPaper id: 2140\nTitle: Title: Sonderforschungsbereich 314 K unstliche Intelligenz Wissensbasierte Systeme KI-Labor am Lehrstuhl f ur Informatik IV Numerical\nLabel: Probabilistic Methods\n\nPaper id: 1937\nTitle: Title: Using Qualitative Relationships for Bounding Probability Distributions  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 107\nTitle: Title: Computing upper and lower bounds on likelihoods in intractable networks  \nLabel: Probabilistic Methods\n\nPaper id: 788\nTitle: Title: Stochastic simulation algorithms for dynamic probabilistic networks  \nLabel: Probabilistic Methods\n\nPaper id: 1842\nTitle: Title: Fall Diagnosis using Dynamic Belief Networks  \nLabel: Probabilistic Methods\n\nPaper id: 332\nTitle: Title: Exploiting Causal Independence in Bayesian Network Inference  \nLabel: Probabilistic Methods\n\nPaper id: 1141\nTitle: Title: Bayesian Graphical Modeling for Intelligent Tutoring Systems  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2160\nTitle: Title: group, and despite having just 337 subjects, the study strongly supports Identification of causal effects\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2434\nTitle: Title: Causal Inference from Indirect Experiments  \nLabel: Probabilistic Methods\n\nPaper id: 1747\nTitle: Title: FROM BAYESIAN NETWORKS TO CAUSAL NETWORKS  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 419\nTitle: Title: On the Testability of Causal Models with Latent and Instrumental Variables  \nLabel: Probabilistic Methods\n\nPaper id: 2069\nTitle: Title: A Note on Testing Exogeneity of Instrumental Variables (DRAFT PAPER)  \nLabel: Probabilistic Methods\n\nPaper id: 105\nTitle: Title: The New Challenge: From a Century of Statistics to an Age of Causation  \nLabel: Probabilistic Methods\n\nPaper id: 2559\nTitle: Title: \"Linear Dependencies Represented by Chain Graphs,\" \"Graphical Modelling With MIM,\" Manual. \"Identifying Independence in Bayesian\n\nPaper id: 1324\nTitle: Title: [6] D. Geiger. Graphoids: a qualitative framework for probabilistic inference. An introduction to algorithms for\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1238\nTitle: Title: On Pruning and Averaging Decision Trees  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1025\nTitle: Title: Machine Learning 27(1):51-68, 1997. Predicting nearly as well as the best pruning of a decision tree  \nLabel: Theory\n\nPaper id: 1550\nTitle: Title: MDL and MML Similarities and Differences (Introduction to Minimum Encoding Inference Part III)  \nLabel: Theory\n\nPaper id: 1290\nTitle: Title: A THEORY OF LEARNING CLASSIFICATION RULES  \nLabel: Theory\n\nPaper id: 378\nTitle: Title: Mingers, 1989 J. Mingers. An empirical comparison of pruning methods for decision tree induction. Machine\n\nPaper id: 1500\nTitle: Title: On the Induction of Intelligible Ensembles  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 84\nTitle: Title: Approximate Bayes Factors and Accounting for Model Uncertainty in Generalized Linear Models  \nLabel: Probabilistic Methods\n\nPaper id: 286\nTitle: Title: The Estimation of Probabilities in Attribute Selection Measures for Decision Tree Induction  \nLabel: Rule Learning\n\nPaper id: 1427\nTitle: Title: SINGLE FACTOR ANALYSIS BY MML ESTIMATION  \nLabel: Probabilistic Methods\n\nPaper id: 684\nTitle: Title: Finding Overlapping Distributions with MML  \n\nPaper id: 1019\nTitle: Title: Bibliography \"SMART: Support Management Automated Reasoning Technology for COMPAQ Customer Service,\" \"Instance-Based Learning Algorithms,\" Machine\nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 709\nTitle: Title: Convergence and new operations in SDM new method for converging in the SDM memory, utilizing\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 340\nTitle: Title: Best Probability of Activation and Performance Comparisons for Several Designs of Sparse Distributed Memory  \nLabel: Neural Networks\n\nPaper id: 341\nTitle: Title: Some Comments on the Information Stored in Sparse Distributed Memory  \nLabel: Neural Networks\n\nPaper id: 529\nTitle: Title: Capacity of SDM  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 200\nTitle: Title: Sample Complexity for Learning Recurrent Perceptron Mappings  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 536\nTitle: Title: Dimension of Recurrent Neural Networks  \nLabel: Neural Networks\n\nPaper id: 1464\nTitle: Title: LINEAR SYSTEMS WITH SIGN-OBSERVATIONS  \nLabel: Neural Networks\n\nPaper id: 1891\nTitle: Title: Vapnik-Chervonenkis Dimension of Recurrent Neural Networks  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1021\nTitle: Title: Lemma 2.3 The system is reachable and observable and realizes the same input/output behavior as\n\nPaper id: 1875\nTitle: Title: On the Effect of Analog Noise in Discrete-Time Analog Computations  \nLabel: Theory\n\nPaper id: 58\nTitle: Title: Neural Networks with Quadratic VC Dimension  \nLabel: Neural Networks\n\nPaper id: 1774\nTitle: Title: Networks of Spiking Neurons: The Third Generation of Neural Network Models  \nLabel: Neural Networks\n\nPaper id: 1149\nTitle: Title: What Size Neural Network Gives Optimal Generalization? Convergence Properties of Backpropagation  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1081\nTitle: Title: Specialization of Recursive Predicates  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 521\nTitle: Title: Covering vs. Divide-and-Conquer for Top-Down Induction of Logic Programs  \nLabel: Rule Learning\n\nPaper id: 1082\nTitle: Title: Specialization of Logic Programs by Pruning SLD-Trees  \n\nPaper id: 1259\nTitle: Title: Finding Accurate Frontiers: A Knowledge-Intensive Approach to Relational Learning  \nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 893\nTitle: Title: LEARNING LOGICAL EXCEPTIONS IN CHESS  \nLabel: Rule Learning\n\nPaper id: 92\nTitle: Title: Learning Analytically and Inductively  \nLabel: Reinforcement Learning\n\nPaper id: 344\nTitle: Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In\nLabel: Rule Learning\n\nPaper id: 1944\nTitle: Title: Knowledge Acquisition with a Knowledge-Intensive Machine Learning System  \nLabel: Rule Learning\n\nPaper id: 156\nTitle: Title: Structural Regression Trees  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1060\nTitle: Title: An Overview of Genetic Algorithms Part 1, Fundamentals  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 237\nTitle: Title: A Sequential Niche Technique for Multimodal Function Optimization  \nLabel: Genetic Algorithms\n\nPaper id: 1890\nTitle: Title: Genetic Algorithms for Adaptive Planning of Path and Trajectory of a Mobile Robot in 2D Terrains  \n\nPaper id: 965\nTitle: Title: Improving Tactical Plans with Genetic Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 1523\nTitle: Title: A Generalized Permutation Approach to Job Shop Scheduling with Genetic Algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 1136\nTitle: Title: Using Neural Networks and Genetic Algorithms as Heuristics for NP-Complete Problems  \n\nPaper id: 2039\nTitle: Title: A Case Study on Tuning of Genetic Algorithms by Using Performance Evaluation Based on Experimental Design  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 329\nTitle: Title: Simple Subpopulation Schemes  \nLabel: Genetic Algorithms\n\nPaper id: 189\nTitle: Title: An Evolutionary Algorithm that Constructs Recurrent Neural Networks  \n\nPaper id: 1575\nTitle: Title: A Comparative Study of Genetic Search  \nLabel: Genetic Algorithms\n\nPaper id: 1159\nTitle: Title: An evolutionary tabu search algorithm and the NHL scheduling problem  \nLabel: Genetic Algorithms\n\nPaper id: 1098\nTitle: Title: Scheduling Maintenance of Electrical Power Transmission Networks Using Genetic Programming  \nLabel: Genetic Algorithms\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1678\nTitle: Title: Induction of One-Level Decision Trees  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 861\nTitle: Title: In Defense of C4.5: Notes on Learning One-Level Decision Trees  \nLabel: Theory\n\nPaper id: 1570\nTitle: Title: Average-Case Analysis of a Nearest Neighbor Algorithm  \n\nPaper id: 378\nTitle: Title: Mingers, 1989 J. Mingers. An empirical comparison of pruning methods for decision tree induction. Machine\n\nPaper id: 1339\nTitle: Title: An Analysis of Bayesian Classifiers (1988), involves the formulation of average-case models for specific algorithms\nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2012\nTitle: Title: Multivariate Decision Trees  \nLabel: Theory\n\nPaper id: 1109\nTitle: Title: Inductive Bias in Case-Based Reasoning Systems  \nLabel: Theory\n\nPaper id: 1644\nTitle: Title: A Comparative Study of ID3 and Backpropagation for English Text-to-Speech Mapping  \nLabel: Neural Networks\n\nPaper id: 1335\nTitle: Title: A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection  \nLabel: Probabilistic Methods\n\nPaper id: 1164\nTitle: Title: PAC Analyses of a `Similarity Learning' IBL Algorithm  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 933\nTitle: Title: Learning an Optimally Accurate Representational System  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 875\nTitle: Title: LEARNING TO SOLVE MARKOVIAN DECISION PROCESSES  \nLabel: Reinforcement Learning\n\nPaper id: 483\nTitle: Title: The Parti-game Algorithm for Variable Resolution Reinforcement Learning in Multidimensional State-spaces  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 749\nTitle: Title: On the Complexity of Solving Markov Decision Problems  \nLabel: Reinforcement Learning\n\nPaper id: 1192\nTitle: Title: Roles of Macro-Actions in Accelerating Reinforcement Learning  \nLabel: Reinforcement Learning\n\nPaper id: 277\nTitle: Title: Applying Online Search Techniques to Continuous-State Reinforcement Learning key to the success of the local\nLabel: Reinforcement Learning\n\nPaper id: 370\nTitle: Title: Robust Reinforcement Learning in Motion Planning  \nLabel: Reinforcement Learning\n\nPaper id: 552\nTitle: Title: Learning to Act using Real-Time Dynamic Programming  \nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 877\nTitle: Title: Naive Bayesian classifier within ILP-R  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1569\nTitle: Title: Estimating Attributes: Analysis and Extensions of RELIEF  \nLabel: Rule Learning\n\nPaper id: 1651\nTitle: Title: An application of ILP in a musical database: learning to compose the two-voice counterpoint  \nLabel: Rule Learning\n\nPaper id: 1010\nTitle: Title: Linear Space Induction in First Order Logic with RELIEFF  \nLabel: Rule Learning\n\nPaper id: 1578\nTitle: Title: SFOIL: Stochastic Approach to Inductive Logic Programming  \nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 208\nTitle: Title: Feature Subset Selection as Search with Probabilistic Estimates  \nLabel: Theory\n\nPaper id: 430\nTitle: Title: Irrelevant Features and the Subset Selection Problem  \nLabel: Theory\n\nPaper id: 1486\nTitle: Title: Induction of decision trees and Bayesian classification applied to diagnosis of sport injuries  \nLabel: Rule Learning\n\nPaper id: 1073\nTitle: Title: An adaptation of Relief for attribute estimation in regression  \nLabel: Rule Learning\n\nPaper id: 1011\nTitle: Title: Discretization of continuous attributes using ReliefF  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1906\nTitle: Title: Bayesian Estimation and Model Choice in Item Response Models  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2421\nTitle: Title: On Convergence of the EM Algorithm and the Gibbs Sampler  SUMMARY  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1856\nTitle: Title: Identifiability, Improper Priors and Gibbs Sampling for Generalized Linear Models  \n\nPaper id: 74\nTitle: Title: Hierarchical Mixtures of Experts and the EM Algorithm  \nLabel: Probabilistic Methods\n\nPaper id: 2590\nTitle: Title: Backfitting in Smoothing Spline ANOVA  \nLabel: Probabilistic Methods\n\nPaper id: 2654\nTitle: Title: On the Sample Complexity of Weakly Learning  \nLabel: Probabilistic Methods\n\nPaper id: 263\nTitle: Title: Non-linear Models for Time Series Using Mixtures of Experts  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1484\nTitle: Title: Experiments with a New Boosting Algorithm  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1522\nTitle: Title: Improving Bagging Performance by Increasing Decision Tree Diversity  \n\nPaper id: 1500\nTitle: Title: On the Induction of Intelligible Ensembles  \n\nPaper id: 822\nTitle: Title: Achieving High-Accuracy Text-to-Speech with Machine Learning  \nLabel: Theory\n\nPaper id: 1482\nTitle: Title: Generalizations of the Bias/Variance Decomposition for Prediction Error  \n\nPaper id: 1220\nTitle: Title: A Method of Combining Multiple Probabilistic Classifiers through Soft Competition on Different Feature Sets  \nLabel: Neural Networks\n\nPaper id: 1057\nTitle: Title: Submitted to the Future Generation Computer Systems special issue on Data Mining. Using Neural Networks\nLabel: Neural Networks\n\nPaper id: 931\nTitle: Title: MAJORITY VOTE CLASSIFIERS: THEORY AND APPLICATIONS  \nLabel: Theory\n\nPaper id: 1692\nTitle: Title: Boosting Trees for Cost-Sensitive Classifications  \nLabel: Theory\n\nPaper id: 1197\nTitle: Title: Why Does Bagging Work? A Bayesian Account and its Implications bagging's success, both in a\n\nPaper id: 1430\nTitle: Title: Adaptive Boosting of Neural Networks for Character Recognition  \nLabel: Neural Networks\n\nPaper id: 1521\nTitle: Title: Improving Bagging Performance by Increasing Decision Tree Diversity  \nLabel: Theory\n\nPaper id: 1092\nTitle: Title: Pruning Adaptive Boosting ICML-97 Final Draft  \n\nPaper id: 1237\nTitle: Title: An Empirical Evaluation of Bagging and Boosting  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1053\nTitle: Title: Bias Plus Variance Decomposition for Zero-One Loss Functions  \nLabel: Theory\n\nPaper id: 1422\nTitle: Title: Generating Accurate and Diverse Members of a Neural-Network Ensemble  \nLabel: Neural Networks\n\nPaper id: 70\nTitle: Title: Boosting the Margin: A New Explanation for the Effectiveness of Voting Methods  \nLabel: Theory\n\nPaper id: 1608\nTitle: Title: Combining estimates in regression and classification  \nLabel: Probabilistic Methods\n\nPaper id: 1267\nTitle: Title: Estimating the Accuracy of Learned Concepts  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1500\nTitle: Title: On the Induction of Intelligible Ensembles  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1267\nTitle: Title: Estimating the Accuracy of Learned Concepts  \n\nPaper id: 2180\nTitle: Title: Oblivious Decision Trees, Graphs, and Top-Down Pruning  \nLabel: Theory\n\nPaper id: 1238\nTitle: Title: On Pruning and Averaging Decision Trees  \n\nPaper id: 1484\nTitle: Title: Experiments with a New Boosting Algorithm  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1521\nTitle: Title: Improving Bagging Performance by Increasing Decision Tree Diversity  \nLabel: Theory\n\nPaper id: 1237\nTitle: Title: An Empirical Evaluation of Bagging and Boosting  \nLabel: Theory\n\nPaper id: 344\nTitle: Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In\nLabel: Rule Learning\n\nPaper id: 1220\nTitle: Title: A Method of Combining Multiple Probabilistic Classifiers through Soft Competition on Different Feature Sets  \nLabel: Neural Networks\n\nPaper id: 1550\nTitle: Title: MDL and MML Similarities and Differences (Introduction to Minimum Encoding Inference Part III)  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 143\nTitle: Title: RESONANCE AND THE PERCEPTION OF MUSICAL METER  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 201\nTitle: Title: Neural net architectures for temporal sequence processing  \n\nPaper id: 363\nTitle: Title: Representing Rhythmic Patterns in a Network of Oscillators  \nLabel: Neural Networks\n\nPaper id: 337\nTitle: Title: Meter as Mechanism: A Neural Network that Learns Metrical Patterns  \n\nPaper id: 180\nTitle: Title: REDUCED MEMORY REPRESENTATIONS FOR MUSIC  \n\nPaper id: 346\nTitle: Title: PERCEPTION OF TIME AS PHASE: TOWARD AN ADAPTIVE-OSCILLATOR MODEL OF RHYTHMIC PATTERN PROCESSING 1  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 350\nTitle: Title: Induction of Multiscale Temporal Structure  \nLabel: Neural Networks\n\nPaper id: 77\nTitle: Title: Synchronization and Desynchronization in a Network of Locally Coupled Wilson-Cowan Oscillators  \nLabel: Neural Networks\n\nPaper id: 132\nTitle: Title: TOWARDS PLANNING: INCREMENTAL INVESTIGATIONS INTO ADAPTIVE ROBOT CONTROL  \nLabel: Reinforcement Learning\n\nPaper id: 1990\nTitle: Title: A FIXED SIZE STORAGE O(n 3 TIME COMPLEXITY LEARNING ALGORITHM FOR FULLY RECURRENT CONTINUALLY RUNNING\nLabel: Neural Networks\n\nPaper id: 1718\nTitle: Title: PREDICTING SUNSPOTS AND EXCHANGE RATES WITH CONNECTIONIST NETWORKS  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1531\nTitle: Title: NACODAE: Navy Conversational Decision Aids Environment  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 887\nTitle: Title: Simplifying Decision Trees: A Survey  \nLabel: Theory\n\nPaper id: 1154\nTitle: Title: Case-Based Learning: Beyond Classification of Feature Vectors  \n\nPaper id: 66\nTitle: Title: (1994); Case-Based Reasoning: Foundational Issues, Methodological Variations, and System Approaches. Case-Based Reasoning: Foundational Issues, Methodological\nLabel: Case Based\n\nPaper id: 983\nTitle: Title: Refining Conversational Case Libraries  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2310\nTitle: Title: Machine Learning: An Annotated Bibliography for the 1995 AI Statistics Tutorial on Machine Learning (Version 1)  \nLabel: Case Based\n\nPaper id: 1248\nTitle: Title: Lazy Acquisition of Place Knowledge  \nLabel: Case Based\n\nPaper id: 819\nTitle: Title: A Case Study of Case-Based CBR  \nLabel: Case Based\n\nPaper id: 1636\nTitle: Title: Context-Sensitive Feature Selection for Lazy Learners  \n\nPaper id: 2520\nTitle: Title: Cooperative Case-Based Reasoning  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1589\nTitle: Title: Learning to Sense Selectively in Physical Domains  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 910\nTitle: Title: Learning Sequential Decision Rules Using Simulation Models and Competition  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 1481\nTitle: Title: An Evolutionary Approach to Learning in Robots  \nLabel: Genetic Algorithms\n\nPaper id: 1311\nTitle: Title: ROBO-SHEPHERD: LEARNING COMPLEX ROBOTIC BEHAVIORS  \nLabel: Genetic Algorithms\n\nPaper id: 523\nTitle: Title: Some studies in machine learning using the game of checkers. IBM Journal, 3(3):211-229, 1959. Some\nLabel: Genetic Algorithms\n\nPaper id: 981\nTitle: Title: AN ENHANCER FOR REACTIVE PLANS  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2135\nTitle: Title: Learning Polynomial Functions by Feature Construction  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2012\nTitle: Title: Multivariate Decision Trees  \nLabel: Theory\n\nPaper id: 2583\nTitle: Title: Dynamic Automatic Model Selection  \n\nPaper id: 2023\nTitle: Title: Classification of EEG Signals Using a Sparse Polynomial Builder  \nLabel: Neural Networks\n\nPaper id: 134\nTitle: Title: Gain Adaptation Beats Least Squares?  \nLabel: Neural Networks\n\nPaper id: 2333\nTitle: Title: Recursive Automatic Algorithm Selection for Inductive Learning  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1782\nTitle: Title: Least-Squares Temporal Difference Learning  \n\nPaper id: 318\nTitle: Title: Generalizing from Case Studies: A Case Study  \nLabel: Case Based\n\nPaper id: 1173\nTitle: Title: Dynamical Selection of Learning Algorithms  \nLabel: Theory\n\nPaper id: 102\nTitle: Title: Multivariate versus Univariate Decision Trees  \nLabel: Neural Networks\n\nPaper id: 2310\nTitle: Title: Machine Learning: An Annotated Bibliography for the 1995 AI Statistics Tutorial on Machine Learning (Version 1)  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1212\nTitle: Title: Acquiring Case Adaptation Knowledge: A Hybrid Approach  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 580\nTitle: Title: Learning to Improve Case Adaptation by Introspective Reasoning and CBR  \n\nPaper id: 817\nTitle: Title: Case-Based Similarity Assessment: Estimating Adaptability from Experience  \nLabel: Case Based\n\nPaper id: 1497\nTitle: Title: Combining Rules and Cases to Learn Case Adaptation  \nLabel: Case Based\n\nPaper id: 818\nTitle: Title: Learning to Integrate Multiple Knowledge Sources for Case-Based Reasoning  \nLabel: Case Based\n\nPaper id: 1126\nTitle: Title: Towards A Computer Model of Memory Search Strategy Learning  \n\nPaper id: 819\nTitle: Title: A Case Study of Case-Based CBR  \nLabel: Case Based\n\nPaper id: 1552\nTitle: Title: on Case-Based Reasoning Integrations Case-Based Seeding for an Interactive Crisis Response Assistant  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 581\nTitle: Title: Representing Self-knowledge for Introspection about Memory Search  \nLabel: Case Based\n\nPaper id: 1367\nTitle: Title: Learning to Refine Indexing by Introspective Reasoning  \n\nPaper id: 2489\nTitle: Title: BECOMING AN EXPERT CASE-BASED REASONER: LEARNING TO ADAPT PRIOR CASES  \n\nPaper id: 582\nTitle: Title: In Machine Learning: A Multistrategy Approach, Vol. IV  Macro and Micro Perspectives of Multistrategy Learning  \nLabel: Case Based\n\nPaper id: 1163\nTitle: Title: Case-Based Planning to Learn  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 639\nTitle: Title: Bayesian Unsupervised Learning of Higher Order Structure  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 250\nTitle: Title: Mean Field Theory for Sigmoid Belief Networks  \nLabel: Probabilistic Methods\n\nPaper id: 584\nTitle: Title: A MEAN FIELD LEARNING ALGORITHM FOR UNSUPERVISED NEURAL NETWORKS  \nLabel: Probabilistic Methods\n\nPaper id: 1763\nTitle: Title: A Brief History of Connectionism  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 31\nTitle: Title: GIBBS-MARKOV MODELS  \nLabel: Neural Networks\n\nPaper id: 33\nTitle: Title: Learning Generative Models with the Up-Propagation Algorithm  \nLabel: Neural Networks\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n\nPaper id: 170\nTitle: Title: Large Deviation Methods for Approximate Probabilistic Inference, with Rates of Convergence a free parameter. The\nLabel: Probabilistic Methods\n\nPaper id: 107\nTitle: Title: Computing upper and lower bounds on likelihoods in intractable networks  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2561\nTitle: Title: MDL Learning of Probabilistic Neural Networks for Discrete Problem Domains  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 719\nTitle: Title: Parzen. On estimation of a probability density function and mode. Annual Mathematical Statistics, 33:1065-1076, 1962.\nLabel: Neural Networks\n\nPaper id: 2380\nTitle: Title: Massively Parallel Case-Based Reasoning with Probabilistic Similarity Metrics  \nLabel: Probabilistic Methods\n\nPaper id: 1527\nTitle: Title: A THEORY OF INFERRED CAUSATION perceive causal relationships in uncon trolled observations. 2. the task\n\nPaper id: 485\nTitle: Title: Bayesian Case-Based Reasoning with Neural Networks  \nLabel: Probabilistic Methods\n\nPaper id: 1908\nTitle: Title: Induction of Selective Bayesian Classifiers  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2525\nTitle: Title: Bayesian Networks  \nLabel: Probabilistic Methods\n\nPaper id: 909\nTitle: Title: Regression Can Build Predictive Causal Models  \nLabel: Probabilistic Methods\n\nPaper id: 1894\nTitle: Title: Causal inference, path analysis, and recursive struc-tural equations models. In C. Clogg, editor, Sociological Methodology,\nLabel: Probabilistic Methods\n\nPaper id: 2221\nTitle: Title: Reasoning about Time and Probability  \nLabel: Probabilistic Methods\n\nPaper id: 1112\nTitle: Title: Flexible Metric Nearest Neighbor Classiflcation  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1297\nTitle: Title: The Origins of Inductive Logic Programming: A Prehistoric Tale  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1174\nTitle: Title: LEARNING CONCEPTS BY ASKING QUESTIONS  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 414\nTitle: Title: Acquiring Recursive and Iterative Concepts with Explanation-Based Learning explanation-based generalization, generalizing explanation structures, generalizing to\nLabel: Case Based\n\nPaper id: 1074\nTitle: Title: Inductive Logic Programming  \nLabel: Theory\n\nPaper id: 303\nTitle: Title: Relating Relational Learning Algorithms  \nLabel: Case Based\n\nPaper id: 1135\nTitle: Title: Learning First-Order Acyclic Horn Programs from Entailment  \nLabel: Theory\n\nPaper id: 893\nTitle: Title: LEARNING LOGICAL EXCEPTIONS IN CHESS  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1698\nTitle: Title: CBET: a Case Base Exploration Tool  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 430\nTitle: Title: Irrelevant Features and the Subset Selection Problem  \nLabel: Theory\n\nPaper id: 2597\nTitle: Title: Improved Heterogeneous Distance Functions  \n\nPaper id: 686\nTitle: Title: Prototype and Feature Selection by Sampling and Random Mutation Hill Climbing Algorithms  \nLabel: Case Based\n\nPaper id: 66\nTitle: Title: (1994); Case-Based Reasoning: Foundational Issues, Methodological Variations, and System Approaches. Case-Based Reasoning: Foundational Issues, Methodological\nLabel: Case Based\n\nPaper id: 1626\nTitle: Title: A Review and Empirical Evaluation of Feature Weighting Methods for a Class of Lazy Learning Algorithms  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2343\nTitle: Title: Feature Subset Selection Using the Wrapper Method: Overfitting and Dynamic Search Space Topology  \n\nPaper id: 2593\nTitle: Title: Induction of Condensed Determinations  \nLabel: Case Based\n\nPaper id: 34\nTitle: Title: Using a Case Base of Surfaces to Speed-Up Reinforcement Learning  \n\nPaper id: 2033\nTitle: Title: Improving RBF Networks by the Feature Selection Approach EUBAFES  \nLabel: Neural Networks\n\nPaper id: 116\nTitle: Title: Rate of Convergence of the Gibbs Sampler by Gaussian Approximation  SUMMARY  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 95\nTitle: Title: Bayesian Detection of Clusters and Discontinuities in Disease Maps  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 358\nTitle: Title: Hierarchical Spatio-Temporal Mapping of Disease Rates  \nLabel: Probabilistic Methods\n\nPaper id: 1255\nTitle: Title: Modelling Risk from a Disease in Time and Space  \nLabel: Probabilistic Methods\n\nPaper id: 161\nTitle: Title: On Bayesian analysis of mixtures with an unknown number of components  Summary  \n\nPaper id: 759\nTitle: Title: BAYESIAN STATISTICS 6, pp. 000--000  Exact sampling for Bayesian inference: towards general purpose algorithms  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 23\nTitle: Title: Applications and extensions of MCMC in IRT: Multiple item types, missing data, and rated responses  \nLabel: Probabilistic Methods\n\nPaper id: 93\nTitle: Title: Blocking Gibbs Sampling for Linkage Analysis in Large Pedigrees with Many Loops  \nLabel: Probabilistic Methods\n\nPaper id: 1147\nTitle: Title: Decomposable graphical Gaussian model determination  \n\nPaper id: 713\nTitle: Title: FLEXIBLE PARAMETRIC MEASUREMENT ERROR MODELS  \n\nPaper id: 292\nTitle: Title: An Approach to Diagnosing Total Variation Convergence of MCMC Algorithms  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 35\nTitle: Title: A Teaching Strategy for Memory-Based Control  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 34\nTitle: Title: Using a Case Base of Surfaces to Speed-Up Reinforcement Learning  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 559\nTitle: Title: Scaling Up Average Reward Reinforcement Learning by Approximating the Domain Models and the Value Function  \n\nPaper id: 566\nTitle: Title: Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming  \nLabel: Reinforcement Learning\n\nPaper id: 66\nTitle: Title: (1994); Case-Based Reasoning: Foundational Issues, Methodological Variations, and System Approaches. Case-Based Reasoning: Foundational Issues, Methodological\nLabel: Case Based\n\nPaper id: 565\nTitle: Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,\nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2239\nTitle: Title: Predicting Conditional Probability Distributions: A Connectionist Approach  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 587\nTitle: Title: NONPARAMETRIC SELECTION OF INPUT VARIABLES FOR CONNECTIONIST LEARNING  \nLabel: Neural Networks\n\nPaper id: 1366\nTitle: Title: ``Learning Local Error Bars for Nonlinear Regression.''  Learning Local Error Bars for Nonlinear Regression  \nLabel: Neural Networks\n\nPaper id: 2513\nTitle: Title: Avoiding overfitting by locally matching the noise level of the data gating network discovers the\n\nPaper id: 2413\nTitle: Title: On-Line Adaptation of a Signal Predistorter through Dual Reinforcement Learning  \nLabel: Neural Networks\n\nPaper id: 2507\nTitle: Title: The Observer-Observation Dilemma in Neuro-Forecasting: Reliable Models From Unreliable Data Through CLEARNING  \n\nPaper id: 2414\nTitle: Title: On-Line Adaptation of a Signal Predistorter through Dual Reinforcement Learning  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 74\nTitle: Title: Hierarchical Mixtures of Experts and the EM Algorithm  \nLabel: Probabilistic Methods\n\nPaper id: 88\nTitle: Title: Hoeffding Races: Accelerating Model Selection Search for Classification and Function Approximation  \nLabel: Theory\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n\nPaper id: 310\nTitle: Title: Forecasting electricity demand using nonlinear mixture of experts  \nLabel: Neural Networks\n\nPaper id: 2562\nTitle: Title: NONLINEAR TRADING MODELS THROUGH SHARPE RATIO MAXIMIZATION  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 872\nTitle: Title: A Blind Identification and Separation Technique via Multi-layer Neural Networks  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 59\nTitle: Title: SELF-ADAPTIVE NEURAL NETWORKS FOR BLIND SEPARATION OF SOURCES  \nLabel: Neural Networks\n\nPaper id: 570\nTitle: Title: A New Learning Algorithm for Blind Signal Separation  \nLabel: Neural Networks\n\nPaper id: 1520\nTitle: Title: Equivariant adaptive source separation  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 920\nTitle: Title: Maximum likelihood source separation for discrete sources  \n\nPaper id: 1258\nTitle: Title: Independent Component Analysis of Simulated EEG Using a Three-Shell Spherical Head Model 1  \nLabel: Neural Networks\n\nPaper id: 169\nTitle: Title: LEARNING LINEAR, SPARSE, FACTORIAL CODES  \nLabel: Neural Networks\n\nPaper id: 1526\nTitle: Title: Working Paper IS-97-22 (Information Systems) A First Application of Independent Component Analysis to Extracting Structure\nLabel: Neural Networks\n\nPaper id: 1200\nTitle: Title: Edges are the `Independent Components' of Natural Scenes.  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1696\nTitle: Title: The Royal Road for Genetic Algorithms: Fitness Landscapes and GA Performance  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1872\nTitle: Title: Modeling Building-Block Interdependency  Dynamical and Evolutionary Machine Organization Group  \nLabel: Genetic Algorithms\n\nPaper id: 163\nTitle: Title: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning. Reading, MA: Addison-Wesley.  \nLabel: Genetic Algorithms\n\nPaper id: 2250\nTitle: Title: The Impact of External Dependency in Genetic Programming Primitives  \nLabel: Genetic Algorithms\n\nPaper id: 2330\nTitle: Title: A comparison of the fixed and floating building block representation in the genetic algorithm  \nLabel: Genetic Algorithms\n\nPaper id: 1334\nTitle: Title: THE OPTIONS DESIGN EXPLORATION SYSTEM Reference Manual and User Guide Version B2.1  \nLabel: Genetic Algorithms\n\nPaper id: 1114\nTitle: Title: Using Genetic Algorithms to Explore Pattern Recognition in the Immune System  COMMENTS WELCOME  \nLabel: Genetic Algorithms\n\nPaper id: 2175\nTitle: Title: The Troubling Aspects of a Building Block Hypothesis for Genetic Programming  \nLabel: Genetic Algorithms\n\nPaper id: 1771\nTitle: Title: When Will a Genetic Algorithm Outperform Hill Climbing?  \nLabel: Genetic Algorithms\n\nPaper id: 1971\nTitle: Title: Voting for Schemata  \nLabel: Genetic Algorithms\n\nPaper id: 1769\nTitle: Title: Testing the Robustness of the Genetic Algorithm on the Floating Building Block Representation.  \nLabel: Genetic Algorithms\n\nPaper id: 1943\nTitle: Title: Distributed Collective Adaptation Applied to a Hard Combinatorial Optimization Problem  \nLabel: Genetic Algorithms\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 523\nTitle: Title: Some studies in machine learning using the game of checkers. IBM Journal, 3(3):211-229, 1959. Some\nLabel: Genetic Algorithms\n\nPaper id: 145\nTitle: Title: LIBGA: A USER-FRIENDLY WORKBENCH FOR ORDER-BASED GENETIC ALGORITHM RESEARCH  \nLabel: Genetic Algorithms\n\nPaper id: 2249\nTitle: Title: Using a Distance Metric on Genetic Programs to Understand Genetic Operators  \nLabel: Genetic Algorithms\n\nPaper id: 1060\nTitle: Title: An Overview of Genetic Algorithms Part 1, Fundamentals  \n\nPaper id: 1573\nTitle: Title: Genetics-based Machine Learning and Behaviour Based Robotics: A New Synthesis complexity grows, the learning task\nLabel: Reinforcement Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Genetic Algorithms"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 369\nTitle: Title: Limitations of self-organizing maps for vector quantization and multidimensional scaling  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 747\nTitle: Title: Cholinergic suppression of transmission may allow combined associative memory function and self-organization in the neocortex.  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 73\nTitle: Title: LEARNING TO GENERATE ARTIFICIAL FOVEA TRAJECTORIES FOR TARGET DETECTION  \nLabel: Reinforcement Learning\n\nPaper id: 699\nTitle: Title: Adaptive state space quantisation for reinforcement learning of collision-free navigation  \n\nPaper id: 202\nTitle: Title: Dyslexic and Category-Specific Aphasic Impairments in a Self-Organizing Feature Map Model of the Lexicon  \n\nPaper id: 18\nTitle: Title: Topography And Ocular Dominance: A Model Exploring Positive Correlations  \nLabel: Neural Networks\n\nPaper id: 310\nTitle: Title: Forecasting electricity demand using nonlinear mixture of experts  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 878\nTitle: Title: Nonsmooth Dynamic Simulation With Linear Programming Based Methods  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1472\nTitle: Title: A SUCCESSIVE LINEAR PROGRAMMING APPROACH FOR INITIALIZATION AND REINITIALIZATION AFTER DISCONTINUITIES OF DIFFERENTIAL ALGEBRAIC EQUATIONS  \nLabel: Neural Networks\n\nPaper id: 1023\nTitle: Title: Data Reconciliation and Gross Error Detection for Dynamic Systems  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1090\nTitle: Title: Inference in Dynamic Error-in-Variable-Measurement Problems  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1686\nTitle: Title: Learning with Abduction  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 837\nTitle: Title: Inductive Database Design  \n\nPaper id: 2282\nTitle: Title: The ILP description learning problem: Towards a general model-level definition of data mining in ILP  \nLabel: Rule Learning\n\nPaper id: 2426\nTitle: Title: Inductive Constraint Logic  \nLabel: Rule Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2126\nTitle: Title: Applying ILP to Diterpene Structure Elucidation from 13 C NMR Spectra  \nLabel: Rule Learning\n\nPaper id: 344\nTitle: Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In\nLabel: Rule Learning\n\nPaper id: 1489\nTitle: Title: Dlab: A Declarative Language Bias Formalism  \nLabel: Rule Learning\n\nPaper id: 2217\nTitle: Title: Application of Clausal Discovery to Temporal Databases  \nLabel: Rule Learning\n\nPaper id: 1007\nTitle: Title: Applications of a logical discovery engine  \nLabel: Rule Learning\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2675\nTitle: Title: CONSTRUCTING CONJUNCTIVE TESTS FOR DECISION TREES  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1595\nTitle: Title: ID2-of-3: Constructive Induction of M of-N Concepts for Discriminators in Decision Trees  \n\nPaper id: 1964\nTitle: Title: Constructing Nominal Xof-N Attributes  \nLabel: Theory\n\nPaper id: 1824\nTitle: Title: Constructing Conjunctions using Systematic Search on Decision Trees  \nLabel: Theory\n\nPaper id: 1256\nTitle: Title: A BENCHMARK FOR CLASSIFIER LEARNING  \nLabel: Rule Learning\n\nPaper id: 1862\nTitle: Title: Continuous-valued Xof-N Attributes Versus Nominal Xof-N Attributes for Constructive Induction: A Case Study  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2346\nTitle: Title: Parity: The Problem that Won't Go Away  \nLabel: Theory\n\nPaper id: 1863\nTitle: Title: Effects of Different Types of New Attribute on Constructive Induction  \n\nPaper id: 1576\nTitle: Title: What do Constructive Learners Really Learn?  \nLabel: Theory\n\nPaper id: 1019\nTitle: Title: Bibliography \"SMART: Support Management Automated Reasoning Technology for COMPAQ Customer Service,\" \"Instance-Based Learning Algorithms,\" Machine\nLabel: Theory\n\nPaper id: 881\nTitle: Title: Proben1 A Set of Neural Network Benchmark Problems and Benchmarking Rules  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 740\nTitle: Title: Information-based objective functions for active data selection  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1683\nTitle: Title: An Algorithm for Active Data Collection for Learning Feasibility Study with Neural Networks.  \n\nPaper id: 164\nTitle: Title: Improving Generalization with Active Learning  \nLabel: Theory\n\nPaper id: 1559\nTitle: Title: In  Active Learning with Statistical Models  \nLabel: Neural Networks\n\nPaper id: 157\nTitle: Title: A Practical Bayesian Framework for Backprop Networks  \nLabel: Theory\n\nPaper id: 1667\nTitle: Title: Advances in Neural Information Processing Systems 8 Active Learning in Multilayer Perceptrons  \nLabel: Neural Networks\n\nPaper id: 418\nTitle: Title: Heterogeneous Uncertainty Sampling for Supervised Learning  \n\nPaper id: 1703\nTitle: Title: REINFORCEMENT DRIVEN INFORMATION ACQUISITION IN NON-DETERMINISTIC ENVIRONMENTS  \nLabel: Reinforcement Learning\n\nPaper id: 929\nTitle: Title: In:  A Mixture Model System for Medical and Machine Diagnosis  \nLabel: Probabilistic Methods\n\nPaper id: 560\nTitle: Title: Bayesian Methods for Adaptive Models  \nLabel: Theory\n\nPaper id: 1664\nTitle: Title: \"What is the best thing to do right now?\": getting beyond greedy exploration  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 897\nTitle: Title: Parallel Markov chain Monte Carlo sampling.  \nLabel: Probabilistic Methods\n\nPaper id: 2442\nTitle: Title: Using Temporal-Difference Reinforcement Learning to Improve Decision-Theoretic Utilities for Diagnosis  \nLabel: Reinforcement Learning\n\nPaper id: 1697\nTitle: Title: Neural Network Exploration Using Optimal Experiment Design  \nLabel: Neural Networks\n\nPaper id: 393\nTitle: Title: Density Networks and their Application to Protein Modelling  \nLabel: Neural Networks\n\nPaper id: 979\nTitle: Title: FLAT MINIMA Neural Computation 9(1):1-42 (1997)  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1076\nTitle: Title: Learning Belief Networks from Data: An Information Theory Based Approach  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1078\nTitle: Title: An Algorithm for Bayesian Belief Network Construction from Data  \nLabel: Probabilistic Methods\n\nPaper id: 1086\nTitle: Title: An Algorithm for the Construction of Bayesian Network Structures from Data  \nLabel: Probabilistic Methods\n\nPaper id: 2461\nTitle: Title: A guide to the literature on learning probabilistic networks from data  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1240\nTitle: Title: Model Selection and Accounting for Model Uncertainty in Linear Regression Models  \nLabel: Probabilistic Methods\n\nPaper id: 1527\nTitle: Title: A THEORY OF INFERRED CAUSATION perceive causal relationships in uncon trolled observations. 2. the task\n\nPaper id: 2492\nTitle: Title: Robust Parameter Learning in Bayesian Networks with Missing Data  \nLabel: Probabilistic Methods\n\nPaper id: 1545\nTitle: Title: Learning Goal Oriented Bayesian Networks for Telecommunications Risk Management  \nLabel: Probabilistic Methods\n\nPaper id: 1641\nTitle: Title: Learning Bayesian Networks from Incomplete Data  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 119\nTitle: Title: Cost-sensitive feature reduction applied to a hybrid genetic algorithm  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 228\nTitle: Title: Cost-Sensitive Classification: Empirical Evaluation of a Hybrid Genetic Decision Tree Induction Algorithm  \nLabel: Genetic Algorithms\n\nPaper id: 430\nTitle: Title: Irrelevant Features and the Subset Selection Problem  \nLabel: Theory\n\nPaper id: 686\nTitle: Title: Prototype and Feature Selection by Sampling and Random Mutation Hill Climbing Algorithms  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1270\nTitle: Title: Automatic Parameter Selection by Minimizing Estimated Error  \nLabel: Theory\n\nPaper id: 2343\nTitle: Title: Feature Subset Selection Using the Wrapper Method: Overfitting and Dynamic Search Space Topology  \n\nPaper id: 1207\nTitle: Title: Data Analyses Using Simulated Breeding and Inductive Learning Methods  \nLabel: Genetic Algorithms\n\nPaper id: 2541\nTitle: Title: PLEASE: A prototype learning system using genetic algorithms  \nLabel: Genetic Algorithms\n\nPaper id: 1020\nTitle: Title: Error-Based and Entropy-Based Discretization of Continuous Features  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Rule Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 775\nTitle: Title: Asynchronous Modified Policy Iteration with Single-sided Updates  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 162\nTitle: Title: Analysis of Some Incremental Variants of Policy Iteration: First Steps Toward Understanding Actor-Critic Learning Systems  \nLabel: Reinforcement Learning\n\nPaper id: 875\nTitle: Title: LEARNING TO SOLVE MARKOVIAN DECISION PROCESSES  \nLabel: Reinforcement Learning\n\nPaper id: 1459\nTitle: Title: Generalized Markov Decision Processes: Dynamic-programming and Reinforcement-learning Algorithms  \nLabel: Reinforcement Learning\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1192\nTitle: Title: Roles of Macro-Actions in Accelerating Reinforcement Learning  \nLabel: Reinforcement Learning\n\nPaper id: 633\nTitle: Title: Chapter 1 Reinforcement Learning for Planning and Control  \n\nPaper id: 45\nTitle: Title: Acting under Uncertainty: Discrete Bayesian Models for Mobile-Robot Navigation  \nLabel: Reinforcement Learning\n\nPaper id: 566\nTitle: Title: Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming  \nLabel: Reinforcement Learning\n\nPaper id: 1687\nTitle: Title: Markov games as a framework for multi-agent reinforcement learning  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Reinforcement Learning"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 202\nTitle: Title: Dyslexic and Category-Specific Aphasic Impairments in a Self-Organizing Feature Map Model of the Lexicon  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 204\nTitle: Title: Natural Language Processing with Subsymbolic Neural Networks  \nLabel: Neural Networks\n\nPaper id: 771\nTitle: Title: SELF-ORGANIZING PROCESS BASED ON LATERAL INHIBITION AND SYNAPTIC RESOURCE REDISTRIBUTION  \nLabel: Neural Networks\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n\nPaper id: 72\nTitle: Title: SCRIPT RECOGNITION WITH HIERARCHICAL FEATURE MAPS  \nLabel: Neural Networks\n\nPaper id: 747\nTitle: Title: Cholinergic suppression of transmission may allow combined associative memory function and self-organization in the neocortex.  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2295\nTitle: Title: Diplomarbeit A Genetic Algorithm for the Topological Optimization of Neural Networks  \nLabel: Genetic Algorithms\n\nPaper id: 205\nTitle: Title: Beyond the Cognitive Map: Contributions to a Computational Neuroscience Theory of Rodent Navigation for the\nLabel: Neural Networks\n\nPaper id: 703\nTitle: Title: VECTOR ASSOCIATIVE MAPS: UNSUPERVISED REAL-TIME ERROR-BASED LEARNING AND CONTROL OF MOVEMENT TRAJECTORIES  \n\nPaper id: 1283\nTitle: Title: Bilinear Separation of Two Sets in n-Space  \nLabel: Neural Networks\n\nPaper id: 542\nTitle: Title: Comparison of Bayesian and Neural Net Unsupervised Classification Techniques  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1126\nTitle: Title: Towards A Computer Model of Memory Search Strategy Learning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 583\nTitle: Title: Introspective reasoning using meta-explanations for multistrategy learning  \nLabel: Case Based\n\nPaper id: 2371\nTitle: Title: Learning Adaptation Strategies by Introspective Reasoning about Memory Search  \nLabel: Case Based\n\nPaper id: 580\nTitle: Title: Learning to Improve Case Adaptation by Introspective Reasoning and CBR  \n\nPaper id: 2489\nTitle: Title: BECOMING AN EXPERT CASE-BASED REASONER: LEARNING TO ADAPT PRIOR CASES  \n\nPaper id: 923\nTitle: Title: Dynamic Constraint Satisfaction using Case-Based Reasoning Techniques  \nLabel: Case Based\n\nPaper id: 1497\nTitle: Title: Combining Rules and Cases to Learn Case Adaptation  \nLabel: Case Based\n\nPaper id: 1212\nTitle: Title: Acquiring Case Adaptation Knowledge: A Hybrid Approach  \n\nPaper id: 2372\nTitle: Title: Goal-Driven Learning: Fundamental Issues (A Symposium Report)  \nLabel: Case Based\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 50\nTitle: Title: Abstract  \n\nPaper id: 2398\nTitle: Title: Issues in Goal-Driven Explanation  \nLabel: Case Based\n\nPaper id: 1416\nTitle: Title: Synergy and Commonality in Case-Based and Constraint-Based Reasoning  \n\nPaper id: 64\nTitle: Title: Integrating Creativity and Reading: A Functional Approach  \n\nPaper id: 901\nTitle: Title: Evaluating Computational Assistance for Crisis Response  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2006\nTitle: Title: Constructing New Attributes for Decision Tree Learning  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1824\nTitle: Title: Constructing Conjunctions using Systematic Search on Decision Trees  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1595\nTitle: Title: ID2-of-3: Constructive Induction of M of-N Concepts for Discriminators in Decision Trees  \n\nPaper id: 2675\nTitle: Title: CONSTRUCTING CONJUNCTIVE TESTS FOR DECISION TREES  \n\nPaper id: 102\nTitle: Title: Multivariate versus Univariate Decision Trees  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 992\nTitle: Title: Adapting Abstract Knowledge  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1354\nTitle: Title: The Structure-Mapping Engine: Algorithm and Examples  \n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 75\nTitle: Title: A Memory Model for Case Retrieval by Activation Passing  \n\nPaper id: 1188\nTitle: Title: In  Estimating analogical similarity by dot-products of Holographic Reduced Representations.  \nLabel: Neural Networks\n\nPaper id: 1040\nTitle: Title: Learning from Examples: Reminding or Heuristic Switching?  \nLabel: Case Based\n\nPaper id: 313\nTitle: Title: The Case for Graph-Structured Representations  \nLabel: Case Based\n\nPaper id: 1317\nTitle: Title: Use of Analogy in Automated Theorem Proving  \nLabel: Case Based\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Case Based"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1757\nTitle: Title: A case study in dynamic belief networks: monitoring walking, fall prediction and detection  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1842\nTitle: Title: Fall Diagnosis using Dynamic Belief Networks  \nLabel: Probabilistic Methods\n\nPaper id: 2341\nTitle: Title: Dynamic Belief Networks for Discrete Monitoring  \nLabel: Probabilistic Methods\n\nPaper id: 1268\nTitle: Title: The BATmobile: Towards a Bayesian Automated Taxi  \nLabel: Probabilistic Methods\n\nPaper id: 2221\nTitle: Title: Reasoning about Time and Probability  \nLabel: Probabilistic Methods\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 559\nTitle: Title: Scaling Up Average Reward Reinforcement Learning by Approximating the Domain Models and the Value Function  \n\nPaper id: 566\nTitle: Title: Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming  \nLabel: Reinforcement Learning\n\nPaper id: 1459\nTitle: Title: Generalized Markov Decision Processes: Dynamic-programming and Reinforcement-learning Algorithms  \nLabel: Reinforcement Learning\n\nPaper id: 1172\nTitle: Title: Introduction to the Special Section on Knowledge-Based Construction of Probabilistic and Decision Models (IEEE Transactions\nLabel: Probabilistic Methods\n\nPaper id: 788\nTitle: Title: Stochastic simulation algorithms for dynamic probabilistic networks  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1020\nTitle: Title: Error-Based and Entropy-Based Discretization of Continuous Features  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 1329\nTitle: Title: Supervised and Unsupervised Discretization of Continuous Features  \nLabel: Theory\n\nPaper id: 430\nTitle: Title: Irrelevant Features and the Subset Selection Problem  \nLabel: Theory\n\nPaper id: 1322\nTitle: Title: Theory and Applications of Agnostic PAC-Learning with Small Decision Trees  \nLabel: Theory\n\nPaper id: 1328\nTitle: Title: A Weighted Nearest Neighbor Algorithm for Learning with Symbolic Features  \nLabel: Neural Networks\n\nPaper id: 2577\nTitle: Title: Targeting Business Users with Decision Table Classifiers  \nLabel: Probabilistic Methods\n\nPaper id: 1337\nTitle: Title: MLC A Machine Learning Library in C  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1109\nTitle: Title: Inductive Bias in Case-Based Reasoning Systems  \nLabel: Theory\n\nPaper id: 1173\nTitle: Title: Dynamical Selection of Learning Algorithms  \nLabel: Theory\n\nPaper id: 1412\nTitle: Title: EXPLORING A FRAMEWORK FOR INSTANCE BASED LEARNING AND NAIVE BAYESIAN CLASSIFIERS  \nLabel: Case Based\n\nPaper id: 1698\nTitle: Title: CBET: a Case Base Exploration Tool  \n\nPaper id: 2539\nTitle: Title: Mining for Causes of Cancer: Machine Learning Experiments at Various Levels of Detail  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2169\nTitle: Title: Theory Refinement on Bayesian Networks  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2420\nTitle: Title: A Parallel Learning Algorithm for Bayesian Inference Networks  \n\nPaper id: 1290\nTitle: Title: A THEORY OF LEARNING CLASSIFICATION RULES  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 218\nTitle: Title: Learning Classification Trees  \nLabel: Probabilistic Methods\n\nPaper id: 378\nTitle: Title: Mingers, 1989 J. Mingers. An empirical comparison of pruning methods for decision tree induction. Machine\n\nPaper id: 1197\nTitle: Title: Why Does Bagging Work? A Bayesian Account and its Implications bagging's success, both in a\n\nPaper id: 1019\nTitle: Title: Bibliography \"SMART: Support Management Automated Reasoning Technology for COMPAQ Customer Service,\" \"Instance-Based Learning Algorithms,\" Machine\nLabel: Theory\n\nPaper id: 429\nTitle: Title: Classifiers: A Theoretical and Empirical Study  \nLabel: Probabilistic Methods\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2311\nTitle: Title: Bayesian MARS  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 161\nTitle: Title: On Bayesian analysis of mixtures with an unknown number of components  Summary  \n\nPaper id: 2285\nTitle: Title: Simulation Based Bayesian Nonparametric Regression Methods  \nLabel: Probabilistic Methods\n\nPaper id: 2448\nTitle: Title: Automatic Smoothing Spline Projection Pursuit  Automatic Smoothing Spline Projection Pursuit.  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 2138\nTitle: Title: A Nonparametric Bayesian Approach to Modelling Nonlinear Time Series  \nLabel: Probabilistic Methods\n\nPaper id: 427\nTitle: Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  \nLabel: Neural Networks\n\nPaper id: 759\nTitle: Title: BAYESIAN STATISTICS 6, pp. 000--000  Exact sampling for Bayesian inference: towards general purpose algorithms  \nLabel: Probabilistic Methods\n\nPaper id: 95\nTitle: Title: Bayesian Detection of Clusters and Discontinuities in Disease Maps  \n\nPaper id: 1147\nTitle: Title: Decomposable graphical Gaussian model determination  \n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Probabilistic Methods"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 1895\nTitle: Title: Generating Neural Networks Through the Induction of Threshold Logic Unit Trees (Extended Abstract)  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 102\nTitle: Title: Multivariate versus Univariate Decision Trees  \nLabel: Neural Networks\n\nPaper id: 638\nTitle: Title: Learning a set of primitive actions with an Induction of decision trees. Machine Learning, 1(1):81-106,\nLabel: Theory\n\nPaper id: 1893\nTitle: Title: Learning NonLinearly Separable Boolean Functions With Linear Threshold Unit Trees and Madaline-Style Networks  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1808\nTitle: Title: Where Do SE-trees Perform? (Part I)  \nLabel: Theory\n\nPaper id: 701\nTitle: Title: Experiments on the Transfer of Knowledge between Neural Networks Reprinted from: Computational Learning Theory and\nLabel: Neural Networks\n\nPaper id: 404\nTitle: Title: EE380L:Neural Networks for Pattern Recognition  POp Trees  under the guidance of  \nLabel: Neural Networks\n\nPaper id: 1824\nTitle: Title: Constructing Conjunctions using Systematic Search on Decision Trees  \nLabel: Theory\n\nPaper id: 296\nTitle: Title: Lookahead and Pathology in Decision Tree Induction  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 569\nTitle: Title: A decision-theoretic generalization of on-line learning and an application to boosting how the weight-update rule\n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 255\nTitle: Title: An Efficient Boosting Algorithm for Combining Preferences  \nLabel: Theory\n\nPaper id: 456\nTitle: Title: Boosting a weak learning algorithm by majority To be published in Information and Computation  \nLabel: Theory\n\nPaper id: 1092\nTitle: Title: Pruning Adaptive Boosting ICML-97 Final Draft  \n\nPaper id: 767\nTitle: Title: Learning to Order Things  \nLabel: Theory\n\nPaper id: 550\nTitle: Title: LEARNING BY USING DYNAMIC FEATURE COMBINATION AND SELECTION  \n\nPaper id: 1457\nTitle: Title: Actively Searching for an Effective Neural-Network Ensemble  \nLabel: Neural Networks\n\nPaper id: 1986\nTitle: Title: BOOSTING AND NAIVE BAYESIAN LEARNING  \n\nPaper id: 1712\nTitle: Title: An Efficient Extension to Mixture Techniques for Prediction and Decision Trees  \nLabel: Theory\n\nPaper id: 1273\nTitle: Title: The Sources of Increased Accuracy for Two Proposed Boosting Algorithms  \nLabel: Theory\n\nPaper id: 514\nTitle: Title: Gambling in a rigged casino: The adversarial multi-armed bandit problem  \nLabel: Theory\n\nPaper id: 1181\nTitle: Title: Learning Sparse Perceptrons  \nLabel: Theory\n\nPaper id: 2099\nTitle: Title: Game Theory, On-line Prediction and Boosting  \nLabel: Theory\n\nPaper id: 710\nTitle: Title: Improving Regressors using Boosting Techniques  \nLabel: Theory\n\nPaper id: 1430\nTitle: Title: Adaptive Boosting of Neural Networks for Character Recognition  \nLabel: Neural Networks\n\nPaper id: 1025\nTitle: Title: Machine Learning 27(1):51-68, 1997. Predicting nearly as well as the best pruning of a decision tree  \nLabel: Theory\n\nPaper id: 1269\nTitle: Title: Context-sensitive learning methods for text categorization  \nLabel: Theory\n\nPaper id: 1522\nTitle: Title: Improving Bagging Performance by Increasing Decision Tree Diversity  \n\nPaper id: 1000\nTitle: Title: PREDICTION GAMES AND ARCING ALGORITHMS  \nLabel: Theory\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 1237\nTitle: Title: An Empirical Evaluation of Bagging and Boosting  \nLabel: Theory\n\nPaper id: 672\nTitle: Title: Cryptographic Limitations on Learning Boolean Formulae and Finite Automata  \nLabel: Theory\n\nPaper id: 453\nTitle: Title: How to Use Expert Advice (Extended Abstract)  \nLabel: Theory\n\nPaper id: 826\nTitle: Title: Combining the Predictions of Multiple Classifiers: Using Competitive Learning to Initialize Neural Networks  \nLabel: Neural Networks\n\nPaper id: 1290\nTitle: Title: A THEORY OF LEARNING CLASSIFICATION RULES  \nLabel: Theory\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Theory"}
{"Context": "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question.\n\n## Target node:\nPaper id: 2278\nTitle: Title: Routing in Optical Multistage Interconnection Networks: a Neural Network Solution  \n\nKnown neighbor papers at hop 1 (partial, may be incomplete):\n\nPaper id: 2284\nTitle: Title: Performance of On-Line Learning Methods in Predicting Multiprocessor Memory Access Patterns  \nLabel: Neural Networks\n\nKnown neighbor papers at hop 2 (partial, may be incomplete):\n\nPaper id: 74\nTitle: Title: Hierarchical Mixtures of Experts and the EM Algorithm  \nLabel: Probabilistic Methods\n\nPaper id: 1293\nTitle: Title: Using Recurrent Neural Networks to Learn the Structure of Interconnection Networks  \nLabel: Neural Networks\n\nPaper id: 2283\nTitle: Title: Predictive Control of Opto-Electronic Reconfigurable Interconnection Networks Using Neural Networks  \nLabel: Neural Networks\n", "Question": "Please predict the most appropriate category for the Target node. Choose from the following categories:\nRule Learning\nNeural Networks\nCase Based\nGenetic Algorithms\nTheory\nReinforcement Learning\nProbabilistic Methods\nAnswer: \n\n Let's think step by step.", "Answer": "Neural Networks"}
